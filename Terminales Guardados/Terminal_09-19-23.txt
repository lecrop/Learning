     +--------------------------------------------------------------------+
     ¦                • MobaXterm Personal Edition v23.2 •                ¦
     ¦              (X server, SSH client and network tools)              ¦
     ¦                                                                    ¦
     ¦ ? Your computer drives are accessible through the /drives path     ¦
     ¦ ? Your DISPLAY is set to 172.33.0.61:0.0                           ¦
     ¦ ? When using SSH, your remote DISPLAY is automatically forwarded   ¦
     ¦ ? Each command status is specified by a special symbol (? or ?)    ¦
     ¦                                                                    ¦
     ¦ • Important:                                                       ¦
     ¦ This is MobaXterm Personal Edition. The Professional edition       ¦
     ¦ allows you to customize MobaXterm for your company: you can add    ¦
     ¦ your own logo, your parameters, your welcome message and generate  ¦
     ¦ either an MSI installation package or a portable executable.       ¦
     ¦ We can also modify MobaXterm or develop the plugins you need.      ¦
     ¦ For more information: https://mobaxterm.mobatek.net/download.html  ¦
     +--------------------------------------------------------------------+

 ? 19/09/2023 ? ? 09:14.00 ? ? /home/mobaxterm ? ssh raul@192.168.150.119 -p 49161
raul@192.168.150.119's password:
X11 forwarding request failed on channel 0
Welcome to Ubuntu 18.04.4 LTS (GNU/Linux 5.3.0-62-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

This system has been minimized by removing packages and content that are
not required on a system that users do not log into.

To restore this content, you can run the 'unminimize' command.
Last login: Mon Sep 18 19:03:04 2023 from 192.168.151.182
(base) raul@119cb66ee7b2:~$ top
top - 09:16:07 up 1162 days, 21:59,  5 users,  load average: 1.39, 1.25, 1.39
Tasks:  28 total,   2 running,  26 sleeping,   0 stopped,   0 zombie
%Cpu(s):  1.7 us,  0.1 sy,  0.1 ni, 98.1 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem : 79227392+total, 11080629+free, 10669404+used, 57477356+buff/cache
KiB Swap: 38583292 total,        4 free, 38583288 used. 67944089+avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 3954 raul      20   0 5943980 5.351g  13116 R 100.3  0.7 848:29.78 conda
    1 root      20   0   72296   3840   3100 S   0.0  0.0   0:00.24 sshd
    6 root      20   0   18496   2372   1924 S   0.0  0.0   0:00.02 bash
   40 rstudio+  20   0 1255844 616912   5188 S   0.0  0.1 122:51.33 rserver
 3936 raul      20   0   28768   2932   2340 S   0.0  0.0   0:32.55 screen
 3937 raul      20   0   18744   3644   3004 S   0.0  0.0   0:00.04 bash
 3956 raul      20   0   26224  11536   6060 S   0.0  0.0   0:00.05 python
11915 root      20   0  101552   7016   6052 S   0.0  0.0   0:00.03 sshd
11930 raul      20   0  104188   6300   5112 S   0.0  0.0   0:00.04 sshd
11931 root      20   0  101552   7012   6052 S   0.0  0.0   0:00.02 sshd
11933 raul      20   0   18636   3468   3000 S   0.0  0.0   0:00.00 bash
11958 raul      20   0  103848   5328   4352 S   0.0  0.0   0:00.00 sshd
11959 raul      20   0   13056   2160   2004 S   0.0  0.0   0:00.00 sftp-server
11967 raul      20   0   36640   3248   2716 R   0.0  0.0   0:00.11 top
11968 root      20   0  101552   6964   6004 S   0.0  0.0   0:00.03 sshd
11983 raul      20   0  104188   6280   5192 S   0.0  0.0   0:00.14 sshd
11984 root      20   0  101552   6976   6012 S   0.0  0.0   0:00.02 sshd
11986 raul      20   0   18636   3620   3024 S   0.0  0.0   0:00.01 bash
12011 raul      20   0  103848   5344   4364 S   0.0  0.0   0:00.00 sshd
12012 raul      20   0   13056   2192   2032 S   0.0  0.0   0:00.00 sftp-server
12021 raul      20   0   28488   2732   2476 S   0.0  0.0   0:00.00 screen
12023 root      20   0  101552   6976   6012 S   0.0  0.0   0:00.03 sshd
12038 raul      20   0  104188   6068   4968 S   0.0  0.0   0:00.04 sshd
12039 root      20   0  101552   6968   6004 S   0.0  0.0   0:00.03 sshd
12041 raul      20   0   18636   3452   2988 S   0.0  0.0   0:00.00 bash
12066 raul      20   0  103848   5524   4544 S   0.0  0.0   0:00.00 sshd
12067 raul      20   0   13056   2008   1852 S   0.0  0.0   0:00.00 sftp-server
12075 raul      20   0   36640   3172   2688 S   0.0  0.0   0:00.01 top




















(base) raul@119cb66ee7b2:~$
(base) raul@119cb66ee7b2:~$
(base) raul@119cb66ee7b2:~$
(base) raul@119cb66ee7b2:~$
(base) raul@119cb66ee7b2:~$ wget https://repo.anaconda.com/archive/Anaconda3-2023.07-2-Linux-x86_64.sh
--2023-09-19 09:36:17--  https://repo.anaconda.com/archive/Anaconda3-2023.07-2-Linux-x86_64.sh
Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8303, ...
Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1064920017 (1016M) [application/x-sh]
Saving to: 'Anaconda3-2023.07-2-Linux-x86_64.sh'

Anaconda3-2023.07-2-Linux-x86_6 100%[=====================================================>]   1016M  68.7MB/s    in

2023-09-19 09:36:32 (69.1 MB/s) - 'Anaconda3-2023.07-2-Linux-x86_64.sh' saved [1064920017/1064920017]

(base) raul@119cb66ee7b2:~$ bash Anaconda3-2023.07-2-Linux-x86_64.sh

Welcome to Anaconda3 2023.07-2

In order to continue the installation process, please review the license
agreement.
Please, press ENTER to continue
>>>
==================================================
End User License Agreement - Anaconda Distribution
==================================================

Copyright 2015-2023, Anaconda, Inc.

All rights reserved under the 3-clause BSD License:

This End User License Agreement (the "Agreement") is a legal agreement between you and Anaconda, Inc. ("Anaconda") a
 your use of Anaconda Distribution (which was formerly known as Anaconda Individual Edition).

Subject to the terms of this Agreement, Anaconda hereby grants you a non-exclusive, non-transferable license to:

  * Install and use the Anaconda Distribution (which was formerly known as Anaconda Individual Edition),
  * Modify and create derivative works of sample source code delivered in Anaconda Distribution from Anaconda's repo
d;
  * Redistribute code files in source (if provided to you by Anaconda as source) and binary forms, with or without m
n subject to the requirements set forth below, and;

Anaconda may, at its option, make available patches, workarounds or other updates to Anaconda Distribution. Unless t
 are provided with their separate governing terms, they are deemed part of Anaconda Distribution licensed to you as
n this Agreement.  This Agreement does not entitle you to any support for Anaconda Distribution.

Anaconda reserves all rights not expressly granted to you in this Agreement.

Redistribution and use in source and binary forms, with or without modification, are permitted provided that the fol
ditions are met:

  * Redistributions of source code must retain the above copyright notice, this list of conditions and the following
r.
  * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the follow
imer in the documentation and/or other materials provided with the distribution.
  * Neither the name of Anaconda nor the names of its contributors may be used to endorse or promote products derive
s software without specific prior written permission.
  * The purpose of the redistribution is not part of a commercial product for resale. Please contact the Anaconda te
hird party redistribution commercial license
  * Commercial usage of the repository is non-compliant with our Terms of Service . Please contact us to learn more
commercial offerings.

You acknowledge that, as between you and Anaconda, Anaconda owns all right, title, and interest, including all intel
operty rights, in and to Anaconda Distribution and, with respect to third-party products distributed with or through
Distribution, the applicable third-party licensors own all right, title and interest, including all intellectual pro
ts, in and to such products.  If you send or transmit any communications or materials to Anaconda suggesting or reco
hanges to the software or documentation, including without limitation, new features or functionality relating theret
comments, questions, suggestions or the like ("Feedback"), Anaconda is free to use such Feedback. You hereby assign
a all right, title, and interest in, and Anaconda is free to use, without any attribution or compensation to any par
eas, know-how, concepts, techniques or other intellectual property rights contained in the Feedback, for any purpose
r, although Anaconda is not required to use any Feedback.

THIS SOFTWARE IS PROVIDED BY ANACONDA AND ITS CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
IMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVEN
ACONDA BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
D TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARIS
 WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

TO THE MAXIMUM EXTENT PERMITTED BY LAW, ANACONDA AND ITS AFFILIATES SHALL NOT BE LIABLE FOR ANY SPECIAL, INCIDENTAL,
OR CONSEQUENTIAL DAMAGES, OR ANY LOST PROFITS, LOSS OF USE, LOSS OF DATA OR LOSS OF GOODWILL, OR THE COSTS OF PROCUR
TUTE PRODUCTS, ARISING OUT OF OR IN CONNECTION WITH THIS AGREEMENT OR THE USE OR PERFORMANCE OF ANACONDA DISTRIBUTIO
 SUCH LIABILITY ARISES FROM ANY CLAIM BASED UPON BREACH OF CONTRACT, BREACH OF WARRANTY, TORT (INCLUDING NEGLIGENCE)
LIABILITY OR ANY OTHER CAUSE OF ACTION OR THEORY OF LIABILITY. IN NO EVENT WILL THE TOTAL CUMULATIVE LIABILITY OF AN
 ITS AFFILIATES UNDER OR ARISING OUT OF THIS AGREEMENT EXCEED 10.00 U.S. DOLLARS.

If you want to terminate this Agreement, you may do so by discontinuing use of Anaconda Distribution.  Anaconda may,
me, terminate this Agreement and the license granted hereunder if you fail to comply with any term of this Agreement
ny termination of this Agreement, you agree to promptly discontinue use of the Anaconda Distribution and destroy all
 your possession or control. Upon any termination of this Agreement all provisions survive except for the licenses g
you.

This Agreement is governed by and construed in accordance with the internal laws of the State of Texas without givin
o any choice or conflict of law provision or rule that would require or permit the application of the laws of any ju
 other than those of the State of Texas. Any legal suit, action, or proceeding arising out of or related to this Agr
the licenses granted hereunder by you must be instituted exclusively in the federal courts of the United States or t
of the State of Texas in each case located in Travis County, Texas, and you irrevocably submit to the jurisdiction o
rts in any such suit, action, or proceeding.

Notice of Third Party Software Licenses
=======================================

Anaconda Distribution provides access to a repository which contains software packages or tools licensed on an open
is from third parties and binary packages of these third party tools. These third party software packages or tools a
d on an "as is" basis and are subject to their respective license agreements as well as this Agreement and the Terms
e for the Repository located at https://know.anaconda.com/TOS.html; provided, however, no restriction contained in t
f Service shall be construed so as to limit Your ability to download the packages contained in Anaconda Distribution
you comply with the license for each such package.  These licenses may be accessed from within the Anaconda Distribu
are or https://www.anaconda.com/legal. Information regarding which license is applicable is available from within ma
third party software packages and tools and at https://repo.anaconda.com/pkgs/main/ and https://repo.anaconda.com/pk
conda reserves the right, in its sole discretion, to change which third party tools are included in the repository a
through Anaconda Distribution.

Intel Math Kernel Library
-------------------------

Anaconda Distribution provides access to re-distributable, run-time, shared-library files from the Intel Math Kernel
"MKL binaries").

Copyright 2018 Intel Corporation.  License available at https://software.intel.com/en-us/license/intel-simplified-so
ense (the "MKL License").

You may use and redistribute the MKL binaries, without modification, provided the following conditions are met:

  * Redistributions must reproduce the above copyright notice and the following terms of use in the MKL binaries and
cumentation and/or other materials provided with the distribution.
  * Neither the name of Intel nor the names of its suppliers may be used to endorse or promote products derived from
inaries without specific prior written permission.
  * No reverse engineering, decompilation, or disassembly of the MKL binaries is permitted.

You are specifically authorized to use and redistribute the MKL binaries with your installation of Anaconda Distribu
ct to the terms set forth in the MKL License. You are also authorized to redistribute the MKL binaries with Anaconda
ion or in the Anaconda package that contains the MKL binaries. If needed, instructions for removing the MKL binaries
tallation of Anaconda Distribution are available at https://docs.anaconda.com.

cuDNN Software
--------------

Anaconda Distribution also provides access to cuDNN software binaries ("cuDNN binaries") from NVIDIA Corporation. Yo
ifically authorized to use the cuDNN binaries with your installation of Anaconda Distribution subject to your compli
the license agreement located at https://docs.nvidia.com/deeplearning/sdk/cudnn-sla/index.html. You are also authori
istribute the cuDNN binaries with an Anaconda Distribution package that contains the cuDNN binaries. You can add or
 cuDNN binaries utilizing the install and uninstall features in Anaconda Distribution.

cuDNN binaries contain source code provided by NVIDIA Corporation.

Arm Performance Libraries
-------------------------

Arm Performance Libraries (Free Version): Anaconda provides access to software and related documentation from the Ar
nce Libraries ("Arm PL") provided by Arm Limited. By installing or otherwise accessing the Arm PL, you acknowledge a
hat use and distribution of the Arm PL is subject to your compliance with the Arm PL end user license agreement loca
tps://developer.arm.com/tools-and-software/server-and-hpc/downloads/arm-performance-libraries/eula.

Export; Cryptography Notice
===========================

You must comply with all domestic and international export laws and regulations that apply to the software, which in
rictions on destinations, end users, and end use.  Anaconda Distribution includes cryptographic software. The countr
 you currently reside may have restrictions on the import, possession, use, and/or re-export to another country, of
 software. BEFORE using any encryption software, please check your country's laws, regulations and policies concerni
ort, possession, or use, and re-export of encryption software, to see if this is permitted. See the Wassenaar Arrang
://www.wassenaar.org/ for more information.

Anaconda has self-classified this software as Export Commodity Control Number (ECCN) EAR99 which includes mass marke
ion security software using or performing cryptographic functions with asymmetric algorithms. No license is required
t of this software to non-embargoed countries.

The Intel Math Kernel Library contained in Anaconda Distribution is classified by Intel as ECCN 5D992.c with no lice
ed for export to non-embargoed countries.

The following packages listed on https://www.anaconda.com/cryptography are included in the repository accessible thr
nda Distribution that relate to cryptography.

Last updated February 25, 2022


Do you accept the license terms? [yes|no]
[no] >>> yes

Anaconda3 will now be installed into this location:
/home/raul/anaconda3

  - Press ENTER to confirm the location
  - Press CTRL-C to abort the installation
  - Or specify a different location below

[/home/raul/anaconda3] >>>
ERROR: File or directory already exists: '/home/raul/anaconda3'
If you want to update an existing installation, use the -u option.
(base) raul@119cb66ee7b2:~$ bash Anaconda3-2023.07-2-Linux-x86_64.sh -u

Welcome to Anaconda3 2023.07-2

In order to continue the installation process, please review the license
agreement.
Please, press ENTER to continue
>>>
==================================================
End User License Agreement - Anaconda Distribution
==================================================

Copyright 2015-2023, Anaconda, Inc.

All rights reserved under the 3-clause BSD License:

This End User License Agreement (the "Agreement") is a legal agreement between you and Anaconda, Inc. ("Anaconda") a
 your use of Anaconda Distribution (which was formerly known as Anaconda Individual Edition).

Subject to the terms of this Agreement, Anaconda hereby grants you a non-exclusive, non-transferable license to:

  * Install and use the Anaconda Distribution (which was formerly known as Anaconda Individual Edition),
  * Modify and create derivative works of sample source code delivered in Anaconda Distribution from Anaconda's repo
d;
  * Redistribute code files in source (if provided to you by Anaconda as source) and binary forms, with or without m
n subject to the requirements set forth below, and;

Anaconda may, at its option, make available patches, workarounds or other updates to Anaconda Distribution. Unless t
 are provided with their separate governing terms, they are deemed part of Anaconda Distribution licensed to you as
n this Agreement.  This Agreement does not entitle you to any support for Anaconda Distribution.

Anaconda reserves all rights not expressly granted to you in this Agreement.

Redistribution and use in source and binary forms, with or without modification, are permitted provided that the fol
ditions are met:

  * Redistributions of source code must retain the above copyright notice, this list of conditions and the following
r.
  * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the follow
imer in the documentation and/or other materials provided with the distribution.
  * Neither the name of Anaconda nor the names of its contributors may be used to endorse or promote products derive
s software without specific prior written permission.
  * The purpose of the redistribution is not part of a commercial product for resale. Please contact the Anaconda te
hird party redistribution commercial license
  * Commercial usage of the repository is non-compliant with our Terms of Service . Please contact us to learn more
commercial offerings.

You acknowledge that, as between you and Anaconda, Anaconda owns all right, title, and interest, including all intel
operty rights, in and to Anaconda Distribution and, with respect to third-party products distributed with or through
Distribution, the applicable third-party licensors own all right, title and interest, including all intellectual pro
ts, in and to such products.  If you send or transmit any communications or materials to Anaconda suggesting or reco
hanges to the software or documentation, including without limitation, new features or functionality relating theret
comments, questions, suggestions or the like ("Feedback"), Anaconda is free to use such Feedback. You hereby assign
a all right, title, and interest in, and Anaconda is free to use, without any attribution or compensation to any par
eas, know-how, concepts, techniques or other intellectual property rights contained in the Feedback, for any purpose
r, although Anaconda is not required to use any Feedback.

THIS SOFTWARE IS PROVIDED BY ANACONDA AND ITS CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
IMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVEN
ACONDA BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
D TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARIS
 WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

TO THE MAXIMUM EXTENT PERMITTED BY LAW, ANACONDA AND ITS AFFILIATES SHALL NOT BE LIABLE FOR ANY SPECIAL, INCIDENTAL,
OR CONSEQUENTIAL DAMAGES, OR ANY LOST PROFITS, LOSS OF USE, LOSS OF DATA OR LOSS OF GOODWILL, OR THE COSTS OF PROCUR
TUTE PRODUCTS, ARISING OUT OF OR IN CONNECTION WITH THIS AGREEMENT OR THE USE OR PERFORMANCE OF ANACONDA DISTRIBUTIO
 SUCH LIABILITY ARISES FROM ANY CLAIM BASED UPON BREACH OF CONTRACT, BREACH OF WARRANTY, TORT (INCLUDING NEGLIGENCE)
LIABILITY OR ANY OTHER CAUSE OF ACTION OR THEORY OF LIABILITY. IN NO EVENT WILL THE TOTAL CUMULATIVE LIABILITY OF AN
 ITS AFFILIATES UNDER OR ARISING OUT OF THIS AGREEMENT EXCEED 10.00 U.S. DOLLARS.

If you want to terminate this Agreement, you may do so by discontinuing use of Anaconda Distribution.  Anaconda may,
me, terminate this Agreement and the license granted hereunder if you fail to comply with any term of this Agreement
ny termination of this Agreement, you agree to promptly discontinue use of the Anaconda Distribution and destroy all
 your possession or control. Upon any termination of this Agreement all provisions survive except for the licenses g
you.

This Agreement is governed by and construed in accordance with the internal laws of the State of Texas without givin
o any choice or conflict of law provision or rule that would require or permit the application of the laws of any ju
 other than those of the State of Texas. Any legal suit, action, or proceeding arising out of or related to this Agr
the licenses granted hereunder by you must be instituted exclusively in the federal courts of the United States or t
of the State of Texas in each case located in Travis County, Texas, and you irrevocably submit to the jurisdiction o
rts in any such suit, action, or proceeding.

Notice of Third Party Software Licenses
=======================================

Anaconda Distribution provides access to a repository which contains software packages or tools licensed on an open
is from third parties and binary packages of these third party tools. These third party software packages or tools a
d on an "as is" basis and are subject to their respective license agreements as well as this Agreement and the Terms
e for the Repository located at https://know.anaconda.com/TOS.html; provided, however, no restriction contained in t
f Service shall be construed so as to limit Your ability to download the packages contained in Anaconda Distribution
you comply with the license for each such package.  These licenses may be accessed from within the Anaconda Distribu
are or https://www.anaconda.com/legal. Information regarding which license is applicable is available from within ma
third party software packages and tools and at https://repo.anaconda.com/pkgs/main/ and https://repo.anaconda.com/pk
conda reserves the right, in its sole discretion, to change which third party tools are included in the repository a
through Anaconda Distribution.

Intel Math Kernel Library
-------------------------

Anaconda Distribution provides access to re-distributable, run-time, shared-library files from the Intel Math Kernel
"MKL binaries").

Copyright 2018 Intel Corporation.  License available at https://software.intel.com/en-us/license/intel-simplified-so
ense (the "MKL License").

You may use and redistribute the MKL binaries, without modification, provided the following conditions are met:

  * Redistributions must reproduce the above copyright notice and the following terms of use in the MKL binaries and
cumentation and/or other materials provided with the distribution.
  * Neither the name of Intel nor the names of its suppliers may be used to endorse or promote products derived from
inaries without specific prior written permission.
  * No reverse engineering, decompilation, or disassembly of the MKL binaries is permitted.

You are specifically authorized to use and redistribute the MKL binaries with your installation of Anaconda Distribu
ct to the terms set forth in the MKL License. You are also authorized to redistribute the MKL binaries with Anaconda
ion or in the Anaconda package that contains the MKL binaries. If needed, instructions for removing the MKL binaries
tallation of Anaconda Distribution are available at https://docs.anaconda.com.

cuDNN Software
--------------

Anaconda Distribution also provides access to cuDNN software binaries ("cuDNN binaries") from NVIDIA Corporation. Yo
ifically authorized to use the cuDNN binaries with your installation of Anaconda Distribution subject to your compli
the license agreement located at https://docs.nvidia.com/deeplearning/sdk/cudnn-sla/index.html. You are also authori
istribute the cuDNN binaries with an Anaconda Distribution package that contains the cuDNN binaries. You can add or
 cuDNN binaries utilizing the install and uninstall features in Anaconda Distribution.

cuDNN binaries contain source code provided by NVIDIA Corporation.

Arm Performance Libraries
-------------------------

Arm Performance Libraries (Free Version): Anaconda provides access to software and related documentation from the Ar
nce Libraries ("Arm PL") provided by Arm Limited. By installing or otherwise accessing the Arm PL, you acknowledge a
hat use and distribution of the Arm PL is subject to your compliance with the Arm PL end user license agreement loca
tps://developer.arm.com/tools-and-software/server-and-hpc/downloads/arm-performance-libraries/eula.

Export; Cryptography Notice
===========================

You must comply with all domestic and international export laws and regulations that apply to the software, which in
rictions on destinations, end users, and end use.  Anaconda Distribution includes cryptographic software. The countr
 you currently reside may have restrictions on the import, possession, use, and/or re-export to another country, of
 software. BEFORE using any encryption software, please check your country's laws, regulations and policies concerni
ort, possession, or use, and re-export of encryption software, to see if this is permitted. See the Wassenaar Arrang
://www.wassenaar.org/ for more information.

Anaconda has self-classified this software as Export Commodity Control Number (ECCN) EAR99 which includes mass marke
ion security software using or performing cryptographic functions with asymmetric algorithms. No license is required
t of this software to non-embargoed countries.

The Intel Math Kernel Library contained in Anaconda Distribution is classified by Intel as ECCN 5D992.c with no lice
ed for export to non-embargoed countries.

The following packages listed on https://www.anaconda.com/cryptography are included in the repository accessible thr
nda Distribution that relate to cryptography.

Last updated February 25, 2022


Do you accept the license terms? [yes|no]
[no] >>>  yes

Anaconda3 will now be installed into this location:
/home/raul/anaconda3

  - Press ENTER to confirm the location
  - Press CTRL-C to abort the installation
  - Or specify a different location below

[/home/raul/anaconda3] >>>
PREFIX=/home/raul/anaconda3
Unpacking payload ...
concurrent.futures.process._RemoteTraceback:
'''
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 387, in wait_result_broken_or_wakeup
  File "multiprocessing/connection.py", line 256, in recv
TypeError: __init__() missing 1 required positional argument: 'msg'
'''

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "entry_point.py", line 69, in <module>
  File "concurrent/futures/process.py", line 562, in _chain_from_iterable_of_lists
  File "concurrent/futures/_base.py", line 609, in result_iterator
  File "concurrent/futures/_base.py", line 446, in result
  File "concurrent/futures/_base.py", line 391, in __get_result
concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the futureng or pending.
[12138] Failed to execute script 'entry_point' due to unhandled exception!
(base) raul@119cb66ee7b2:~$ pyt
pytest            python2           python3           python3.6         python3.9         python3m
python            python2.7         python3-config    python3.6m        python3.9-config
(base) raul@119cb66ee7b2:~$ python
Python 3.9.12 (main, Apr  5 2022, 06:56:58)
[GCC 7.5.0] :: Anaconda, Inc. on linux
Type "help", "copyright", "credits" or "license" for more information.
>>>
(base) raul@119cb66ee7b2:~$ pk
pkg-config  pkgdata     pkginfo     pkill
(base) raul@119cb66ee7b2:~$ pkill -U raul
Connection to 192.168.150.119 closed by remote host.
Connection to 192.168.150.119 closed.


 ? 19/09/2023 ? ? 09:41.41 ? ? /home/mobaxterm ? ssh raul@192.168.150.119 -p 49161
raul@192.168.150.119's password:
X11 forwarding request failed on channel 0
Welcome to Ubuntu 18.04.4 LTS (GNU/Linux 5.3.0-62-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

This system has been minimized by removing packages and content that are
not required on a system that users do not log into.

To restore this content, you can run the 'unminimize' command.
Last login: Tue Sep 19 09:15:42 2023 from 192.168.151.182
raul@119cb66ee7b2:~$ top
top - 09:42:20 up 1162 days, 22:26,  2 users,  load average: 0.24, 1.25, 1.35
Tasks:  10 total,   1 running,   9 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.2 us,  0.0 sy,  0.0 ni, 99.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem : 79227392+total, 11140198+free, 10107831+used, 57979360+buff/cache
KiB Swap: 38583292 total,        4 free, 38583288 used. 68505664+avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
    1 root      20   0   72296   3840   3100 S   0.0  0.0   0:00.24 sshd
    6 root      20   0   18496   2372   1924 S   0.0  0.0   0:00.02 bash
   40 rstudio+  20   0 1255844 616912   5188 S   0.0  0.1 122:51.72 rserver
12208 root      20   0  101552   7012   6048 S   0.0  0.0   0:00.03 sshd
12223 raul      20   0  104188   6112   5020 S   0.0  0.0   0:00.03 sshd
12224 root      20   0  101552   6936   5980 S   0.0  0.0   0:00.03 sshd
12226 raul      20   0   18620   3648   3068 S   0.0  0.0   0:00.00 bash
12255 raul      20   0  103848   5488   4516 S   0.0  0.0   0:00.00 sshd
12256 raul      20   0   13056   2088   1964 S   0.0  0.0   0:00.00 sftp-server
12257 raul      20   0   36640   3240   2760 R   0.0  0.0   0:00.01 top






































raul@119cb66ee7b2:~$ bash Anaconda3-2023.07-2-Linux-x86_64.sh -u

Welcome to Anaconda3 2023.07-2

In order to continue the installation process, please review the license
agreement.
Please, press ENTER to continue
>>>
==================================================
End User License Agreement - Anaconda Distribution
==================================================

Copyright 2015-2023, Anaconda, Inc.

All rights reserved under the 3-clause BSD License:

This End User License Agreement (the "Agreement") is a legal agreement between you and Anaconda, Inc. ("Anaconda") a
 your use of Anaconda Distribution (which was formerly known as Anaconda Individual Edition).

Subject to the terms of this Agreement, Anaconda hereby grants you a non-exclusive, non-transferable license to:

  * Install and use the Anaconda Distribution (which was formerly known as Anaconda Individual Edition),
  * Modify and create derivative works of sample source code delivered in Anaconda Distribution from Anaconda's repo
d;
  * Redistribute code files in source (if provided to you by Anaconda as source) and binary forms, with or without m
n subject to the requirements set forth below, and;

Anaconda may, at its option, make available patches, workarounds or other updates to Anaconda Distribution. Unless t
 are provided with their separate governing terms, they are deemed part of Anaconda Distribution licensed to you as
n this Agreement.  This Agreement does not entitle you to any support for Anaconda Distribution.

Anaconda reserves all rights not expressly granted to you in this Agreement.

Redistribution and use in source and binary forms, with or without modification, are permitted provided that the fol
ditions are met:

  * Redistributions of source code must retain the above copyright notice, this list of conditions and the following
r.
  * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the follow
imer in the documentation and/or other materials provided with the distribution.
  * Neither the name of Anaconda nor the names of its contributors may be used to endorse or promote products derive
s software without specific prior written permission.
  * The purpose of the redistribution is not part of a commercial product for resale. Please contact the Anaconda te
hird party redistribution commercial license
  * Commercial usage of the repository is non-compliant with our Terms of Service . Please contact us to learn more
commercial offerings.

You acknowledge that, as between you and Anaconda, Anaconda owns all right, title, and interest, including all intel
operty rights, in and to Anaconda Distribution and, with respect to third-party products distributed with or through
Distribution, the applicable third-party licensors own all right, title and interest, including all intellectual pro
ts, in and to such products.  If you send or transmit any communications or materials to Anaconda suggesting or reco
hanges to the software or documentation, including without limitation, new features or functionality relating theret
comments, questions, suggestions or the like ("Feedback"), Anaconda is free to use such Feedback. You hereby assign
a all right, title, and interest in, and Anaconda is free to use, without any attribution or compensation to any par
eas, know-how, concepts, techniques or other intellectual property rights contained in the Feedback, for any purpose
r, although Anaconda is not required to use any Feedback.

THIS SOFTWARE IS PROVIDED BY ANACONDA AND ITS CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
IMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVEN
ACONDA BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
D TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARIS
 WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

TO THE MAXIMUM EXTENT PERMITTED BY LAW, ANACONDA AND ITS AFFILIATES SHALL NOT BE LIABLE FOR ANY SPECIAL, INCIDENTAL,
OR CONSEQUENTIAL DAMAGES, OR ANY LOST PROFITS, LOSS OF USE, LOSS OF DATA OR LOSS OF GOODWILL, OR THE COSTS OF PROCUR
TUTE PRODUCTS, ARISING OUT OF OR IN CONNECTION WITH THIS AGREEMENT OR THE USE OR PERFORMANCE OF ANACONDA DISTRIBUTIO
 SUCH LIABILITY ARISES FROM ANY CLAIM BASED UPON BREACH OF CONTRACT, BREACH OF WARRANTY, TORT (INCLUDING NEGLIGENCE)
LIABILITY OR ANY OTHER CAUSE OF ACTION OR THEORY OF LIABILITY. IN NO EVENT WILL THE TOTAL CUMULATIVE LIABILITY OF AN
 ITS AFFILIATES UNDER OR ARISING OUT OF THIS AGREEMENT EXCEED 10.00 U.S. DOLLARS.

If you want to terminate this Agreement, you may do so by discontinuing use of Anaconda Distribution.  Anaconda may,
me, terminate this Agreement and the license granted hereunder if you fail to comply with any term of this Agreement
ny termination of this Agreement, you agree to promptly discontinue use of the Anaconda Distribution and destroy all
 your possession or control. Upon any termination of this Agreement all provisions survive except for the licenses g
you.

This Agreement is governed by and construed in accordance with the internal laws of the State of Texas without givin
o any choice or conflict of law provision or rule that would require or permit the application of the laws of any ju
 other than those of the State of Texas. Any legal suit, action, or proceeding arising out of or related to this Agr
the licenses granted hereunder by you must be instituted exclusively in the federal courts of the United States or t
of the State of Texas in each case located in Travis County, Texas, and you irrevocably submit to the jurisdiction o
rts in any such suit, action, or proceeding.

Notice of Third Party Software Licenses
=======================================

Anaconda Distribution provides access to a repository which contains software packages or tools licensed on an open
is from third parties and binary packages of these third party tools. These third party software packages or tools a
d on an "as is" basis and are subject to their respective license agreements as well as this Agreement and the Terms
e for the Repository located at https://know.anaconda.com/TOS.html; provided, however, no restriction contained in t
f Service shall be construed so as to limit Your ability to download the packages contained in Anaconda Distribution
you comply with the license for each such package.  These licenses may be accessed from within the Anaconda Distribu
are or https://www.anaconda.com/legal. Information regarding which license is applicable is available from within ma
third party software packages and tools and at https://repo.anaconda.com/pkgs/main/ and https://repo.anaconda.com/pk
conda reserves the right, in its sole discretion, to change which third party tools are included in the repository a
through Anaconda Distribution.

Intel Math Kernel Library
-------------------------

Anaconda Distribution provides access to re-distributable, run-time, shared-library files from the Intel Math Kernel
"MKL binaries").

Copyright 2018 Intel Corporation.  License available at https://software.intel.com/en-us/license/intel-simplified-so
ense (the "MKL License").

You may use and redistribute the MKL binaries, without modification, provided the following conditions are met:

  * Redistributions must reproduce the above copyright notice and the following terms of use in the MKL binaries and
cumentation and/or other materials provided with the distribution.
  * Neither the name of Intel nor the names of its suppliers may be used to endorse or promote products derived from
inaries without specific prior written permission.
  * No reverse engineering, decompilation, or disassembly of the MKL binaries is permitted.

You are specifically authorized to use and redistribute the MKL binaries with your installation of Anaconda Distribu
ct to the terms set forth in the MKL License. You are also authorized to redistribute the MKL binaries with Anaconda
ion or in the Anaconda package that contains the MKL binaries. If needed, instructions for removing the MKL binaries
tallation of Anaconda Distribution are available at https://docs.anaconda.com.

cuDNN Software
--------------

Anaconda Distribution also provides access to cuDNN software binaries ("cuDNN binaries") from NVIDIA Corporation. Yo
ifically authorized to use the cuDNN binaries with your installation of Anaconda Distribution subject to your compli
the license agreement located at https://docs.nvidia.com/deeplearning/sdk/cudnn-sla/index.html. You are also authori
istribute the cuDNN binaries with an Anaconda Distribution package that contains the cuDNN binaries. You can add or
 cuDNN binaries utilizing the install and uninstall features in Anaconda Distribution.

cuDNN binaries contain source code provided by NVIDIA Corporation.

Arm Performance Libraries
-------------------------

Arm Performance Libraries (Free Version): Anaconda provides access to software and related documentation from the Ar
nce Libraries ("Arm PL") provided by Arm Limited. By installing or otherwise accessing the Arm PL, you acknowledge a
hat use and distribution of the Arm PL is subject to your compliance with the Arm PL end user license agreement loca
tps://developer.arm.com/tools-and-software/server-and-hpc/downloads/arm-performance-libraries/eula.

Export; Cryptography Notice
===========================

You must comply with all domestic and international export laws and regulations that apply to the software, which in
rictions on destinations, end users, and end use.  Anaconda Distribution includes cryptographic software. The countr
 you currently reside may have restrictions on the import, possession, use, and/or re-export to another country, of
 software. BEFORE using any encryption software, please check your country's laws, regulations and policies concerni
ort, possession, or use, and re-export of encryption software, to see if this is permitted. See the Wassenaar Arrang
://www.wassenaar.org/ for more information.

Anaconda has self-classified this software as Export Commodity Control Number (ECCN) EAR99 which includes mass marke
ion security software using or performing cryptographic functions with asymmetric algorithms. No license is required
t of this software to non-embargoed countries.

The Intel Math Kernel Library contained in Anaconda Distribution is classified by Intel as ECCN 5D992.c with no lice
ed for export to non-embargoed countries.

The following packages listed on https://www.anaconda.com/cryptography are included in the repository accessible thr
nda Distribution that relate to cryptography.

Last updated February 25, 2022


Do you accept the license terms? [yes|no]
[no] >>> yes

Anaconda3 will now be installed into this location:
/home/raul/anaconda3

  - Press ENTER to confirm the location
  - Press CTRL-C to abort the installation
  - Or specify a different location below

[/home/raul/anaconda3] >>>
PREFIX=/home/raul/anaconda3
Unpacking payload ...
Extracting : beautifulsoup4-4.12.2-py311h06a4308_0.conda:   1%|?                             | 14/976 [00:00<01:27, Exception in thread Thread-2:
                                                                                                                    Traceback (most recent call last):
  File "threading.py", line 980, in _bootstrap_inner
concurrent.futures.process._RemoteTraceback:
'''
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 387, in wait_result_broken_or_wakeup
  File "multiprocessing/connection.py", line 256, in recv
TypeError: __init__() missing 1 required positional argument: 'msg'
'''

The above exception was the direct cause of the following exception:

  File "concurrent/futures/process.py", line 323, in run
Traceback (most recent call last):
  File "entry_point.py", line 69, in <module>
  File "concurrent/futures/process.py", line 458, in terminate_broken
  File "concurrent/futures/_base.py", line 549, in set_exception
  File "concurrent/futures/process.py", line 562, in _chain_from_iterable_of_lists
concurrent.futures._base.InvalidStateError: CANCELLED: <Future at 0x7fa6fdfc5fa0 state=cancelled>
  File "concurrent/futures/_base.py", line 609, in result_iterator
  File "concurrent/futures/_base.py", line 446, in result
  File "concurrent/futures/_base.py", line 391, in __get_result
concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the futureng or pending.
[12305] Failed to execute script 'entry_point' due to unhandled exception!

Process ForkProcess-61:
Process ForkProcess-54:
Process ForkProcess-55:
Process ForkProcess-62:
Process ForkProcess-27:
Process ForkProcess-60:
Process ForkProcess-15:
Process ForkProcess-53:
Process ForkProcess-57:
Process ForkProcess-56:
Process ForkProcess-31:
Process ForkProcess-50:
Process ForkProcess-64:
Process ForkProcess-47:
Process ForkProcess-52:
Process ForkProcess-63:
Process ForkProcess-44:
Process ForkProcess-48:
Process ForkProcess-42:
Process ForkProcess-45:
Process ForkProcess-37:
Process ForkProcess-51:
Process ForkProcess-30:
Process ForkProcess-46:
Process ForkProcess-41:
Process ForkProcess-28:
Process ForkProcess-7:
Process ForkProcess-35:
Process ForkProcess-24:
Process ForkProcess-39:
Process ForkProcess-43:
Process ForkProcess-29:
Process ForkProcess-40:
Process ForkProcess-23:
Process ForkProcess-33:
Process ForkProcess-20:
Process ForkProcess-17:
Process ForkProcess-26:
Process ForkProcess-19:
Process ForkProcess-22:
Process ForkProcess-32:
Process ForkProcess-36:
Process ForkProcess-11:
Process ForkProcess-13:
Process ForkProcess-25:
Process ForkProcess-16:
Process ForkProcess-21:
Error in atexit._run_exitfuncs:
Process ForkProcess-4:
Process ForkProcess-14:
Process ForkProcess-10:
Process ForkProcess-9:
Process ForkProcess-3:
Traceback (most recent call last):
  File "multiprocessing/popen_fork.py", line 27, in poll
Process ForkProcess-5:
Process ForkProcess-2:
Process ForkProcess-1:
Process ForkProcess-8:
Process ForkProcess-34:
Process ForkProcess-38:

Process ForkProcess-59:
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
KeyboardInterrupt
Process ForkProcess-18:
Traceback (most recent call last):
Process ForkProcess-58:
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "concurrent/futures/process.py", line 240, in _process_worker
KeyboardInterrupt
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/queues.py", line 102, in get
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
Traceback (most recent call last):
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 315, in _bootstrap
KeyboardInterrupt
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
KeyboardInterrupt
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/queues.py", line 102, in get
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 240, in _process_worker
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
  File "multiprocessing/synchronize.py", line 95, in __enter__
Traceback (most recent call last):
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
Traceback (most recent call last):
KeyboardInterrupt
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/queues.py", line 102, in get
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
KeyboardInterrupt
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "concurrent/futures/process.py", line 240, in _process_worker
Traceback (most recent call last):
  File "multiprocessing/synchronize.py", line 95, in __enter__
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Process ForkProcess-12:
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/queues.py", line 102, in get
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
KeyboardInterrupt
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/queues.py", line 102, in get
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/queues.py", line 102, in get
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
KeyboardInterrupt
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/queues.py", line 102, in get
  File "concurrent/futures/process.py", line 240, in _process_worker
Traceback (most recent call last):
  File "multiprocessing/queues.py", line 102, in get
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/queues.py", line 102, in get
Traceback (most recent call last):
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/queues.py", line 102, in get
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 315, in _bootstrap
KeyboardInterrupt
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/process.py", line 108, in run
Process ForkProcess-6:
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/queues.py", line 102, in get
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/process.py", line 108, in run
Process ForkProcess-49:
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/queues.py", line 102, in get
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "concurrent/futures/process.py", line 240, in _process_worker
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
KeyboardInterrupt
  File "concurrent/futures/process.py", line 240, in _process_worker
KeyboardInterrupt
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/queues.py", line 102, in get
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/queues.py", line 102, in get
  File "concurrent/futures/process.py", line 240, in _process_worker
KeyboardInterrupt
KeyboardInterrupt
  File "multiprocessing/queues.py", line 102, in get
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/queues.py", line 102, in get
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
  File "concurrent/futures/process.py", line 240, in _process_worker
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/queues.py", line 102, in get
KeyboardInterrupt
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/queues.py", line 102, in get
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/queues.py", line 102, in get
KeyboardInterrupt
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
Traceback (most recent call last):
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
KeyboardInterrupt
  File "multiprocessing/queues.py", line 102, in get
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
Traceback (most recent call last):
  File "multiprocessing/queues.py", line 102, in get
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 240, in _process_worker
KeyboardInterrupt
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/queues.py", line 102, in get
KeyboardInterrupt
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
KeyboardInterrupt
KeyboardInterrupt
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/queues.py", line 103, in get
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/connection.py", line 221, in recv_bytes
KeyboardInterrupt
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
  File "multiprocessing/queues.py", line 102, in get
KeyboardInterrupt
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/connection.py", line 419, in _recv_bytes
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/queues.py", line 102, in get
KeyboardInterrupt
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "concurrent/futures/process.py", line 240, in _process_worker
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
  File "multiprocessing/queues.py", line 102, in get
KeyboardInterrupt
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
  File "concurrent/futures/process.py", line 240, in _process_worker
KeyboardInterrupt
KeyboardInterrupt
KeyboardInterrupt
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "concurrent/futures/process.py", line 240, in _process_worker
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/connection.py", line 384, in _recv
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
  File "multiprocessing/queues.py", line 102, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
KeyboardInterrupt
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
raul@119cb66ee7b2:~$
raul@119cb66ee7b2:~$
raul@119cb66ee7b2:~$ ll -h anaconda3/
total 12M
drwxrwxr-x  30 raul raul 4.0K Sep 19 09:42 ./
drwxr-xr-x  21 raul raul 4.0K Sep 19 09:38 ../
-rw-rw-r--   1 raul raul    0 Sep 13 20:18 .messages.txt
-rw-r--r--   1 raul raul  12K Aug  4 00:40 LICENSE.txt
drwxrwxr-x   2 raul raul  20K Sep 13 20:18 bin/
drwxrwxr-x   2 raul raul 4.0K Oct  6  2022 compiler_compat/
drwxrwxr-x   2 raul raul  36K Sep 13 20:18 conda-meta/
-rwxrwxr-x   1 raul raul  12M Sep 19 09:42 conda.exe*
drwxrwxr-x   2 raul raul 4.0K Sep 13 20:18 condabin/
drwxrwxr-x   3 raul raul 4.0K Oct  6  2022 doc/
drwxrwxr-x   6 raul raul 4.0K Sep 14 17:29 envs/
drwxrwxr-x   8 raul raul 4.0K Sep 14 16:16 etc/
drwxrwxr-x  47 raul raul  12K Sep 13 20:18 include/
drwxrwxr-x   2 raul raul 4.0K Sep 19 09:45 install_tmp/
drwxrwxr-x  23 raul raul  40K Oct  6  2022 lib/
drwxrwxr-x   4 raul raul 4.0K Oct  6  2022 libexec/
drwxrwxr-x   3 raul raul 4.0K Oct  6  2022 licensing/
drwxrwxr-x   3 raul raul 4.0K Oct  6  2022 man/
drwxrwxr-x  65 raul raul 4.0K Oct  6  2022 mkspecs/
drwxrwxr-x   2 raul raul 4.0K Oct  6  2022 phrasebooks/
drwxrwxr-x 980 raul raul 128K Sep 19 09:37 pkgs/
drwxrwxr-x  27 raul raul 4.0K Oct  6  2022 plugins/
-rw-r--r--   1 raul raul 5.0K Aug  4 00:42 postconda.tar.bz2
-rw-rw-r--   2 raul raul  13K Mar 16  2022 pyodbc.pyi
drwxrwxr-x   2 raul raul 4.0K Sep 13 20:18 python-scripts/
drwxrwxr-x  25 raul raul 4.0K Oct  6  2022 qml/
drwxrwxr-x   2 raul raul 4.0K Oct  6  2022 resources/
drwxrwxr-x   2 raul raul 4.0K Oct  6  2022 sbin/
drwxrwxr-x  28 raul raul 4.0K Sep 13 20:18 share/
drwxrwxr-x   3 raul raul 4.0K Oct  6  2022 shell/
drwxrwxr-x   3 raul raul 4.0K Oct  6  2022 ssl/
drwxrwxr-x   3 raul raul  12K Oct  6  2022 translations/
drwxrwxr-x   3 raul raul 4.0K Oct  6  2022 var/
drwxrwxr-x   3 raul raul 4.0K Oct  6  2022 x86_64-conda-linux-gnu/
drwxrwxr-x   3 raul raul 4.0K Oct  6  2022 x86_64-conda_cos6-linux-gnu/
raul@119cb66ee7b2:~$ pwd
/home/raul
raul@119cb66ee7b2:~$ ll -h
total 2.3G
drwxr-xr-x 21 raul     raul      4.0K Sep 19 09:38 ./
drwxrwxr-x  3 sventura sventura  4.0K Oct  4  2022 ../
-rw-------  1 raul     raul       24K Sep 19 09:41 .bash_history
-rw-r--r--  1 raul     raul       220 Oct  4  2022 .bash_logout
-rw-r--r--  1 raul     raul      4.2K Sep 15 10:11 .bashrc
drwx------  5 raul     raul      4.0K Sep 14 16:16 .cache/
drwxrwxr-x  2 raul     raul      4.0K Sep 14 16:16 .conda/
-rw-rw-r--  1 raul     raul        77 Sep 14 17:27 .condarc
drwxr-xr-x  3 raul     raul      4.0K Oct  6  2022 .config/
drwxrwxr-x  3 raul     raul      4.0K Sep 14 19:31 .java/
drwxrwxr-x  4 raul     raul      4.0K Oct 18  2022 .local/
drwx------  2 raul     raul      4.0K Sep 13 20:19 .ncbi/
-rw-r--r--  1 raul     raul       807 Oct  4  2022 .profile
-rw-------  1 raul     raul        32 Sep 19 09:38 .python_history
drwxr-xr-x 15 raul     raul      4.0K Sep 18 20:41 .rstudio/
-rw-r--r--  1 raul     raul         0 Oct  6  2022 .sudo_as_admin_successful
-rw-rw-r--  1 raul     raul       382 Sep 14 18:51 .wget-hsts
-rw-rw-r--  1 raul     raul     1016M Aug  4 17:59 Anaconda3-2023.07-2-Linux-x86_64.sh
drwxrwxr-x  7 raul     raul      4.0K Sep 13 15:13 Fran/
drwxr-xr-x  2 raul     raul      4.0K Feb 26  2023 NormFinder/
drwxr-xr-x  2 raul     raul      4.0K Nov  2  2022 PCa/
drwxr-xr-x  3 raul     raul      4.0K Oct  4  2022 R/
drwxrwxr-x  2 raul     raul      4.0K Oct 18  2022 RNASeqLiver/
drwxrwxr-x  3 raul     raul      4.0K Sep 13 20:18 SRA-ToolKit/
drwxr-xr-x  2 raul     raul      4.0K Oct 14  2022 Scripts/
-rw-r--r--  1 raul     raul      1.3G Nov  2  2022 Workspace.RData
drwxrwxr-x 30 raul     raul      4.0K Sep 19 09:42 anaconda3/
drwxrwxr-x 10 raul     raul      4.0K Sep 13 19:00 matt/
drwxrwxr-x 16 raul     raul      4.0K Oct  6  2022 miniconda3/
-rw-rw-r--  1 raul     raul         2 Sep 15 16:08 out.out
-rw-rw-r--  1 raul     raul         2 Sep 15 16:17 out_2.out
drwxrwxr-x  3 raul     raul      4.0K Oct 18  2022 packages/
-rw-------  1 raul     raul      1.6K Oct 18  2022 poetry-installer-error-fmsyos43.log
-rw-------  1 raul     raul      1.6K Oct 18  2022 poetry-installer-error-s1m55vfa.log
-rw-------  1 raul     raul      1.6K Oct 18  2022 poetry-installer-error-z7x1blsd.log
-rw-r--r--  1 raul     raul       56M Oct 18  2022 resultadosTraspuestos.csv
drwxrwxr-x  9 raul     raul      4.0K Sep 14 16:39 vast-tools/
-rw-rw-r--  1 raul     raul        85 Sep 14 09:56 your_requests_to_matt.txt
raul@119cb66ee7b2:~$ bash Anaconda3-2023.07-2-Linux-x86_64.sh -u

Welcome to Anaconda3 2023.07-2

In order to continue the installation process, please review the license
agreement.
Please, press ENTER to continue
>>>
==================================================
End User License Agreement - Anaconda Distribution
==================================================

Copyright 2015-2023, Anaconda, Inc.

All rights reserved under the 3-clause BSD License:

This End User License Agreement (the "Agreement") is a legal agreement between you and Anaconda, Inc. ("Anaconda") a
 your use of Anaconda Distribution (which was formerly known as Anaconda Individual Edition).

Subject to the terms of this Agreement, Anaconda hereby grants you a non-exclusive, non-transferable license to:

  * Install and use the Anaconda Distribution (which was formerly known as Anaconda Individual Edition),
  * Modify and create derivative works of sample source code delivered in Anaconda Distribution from Anaconda's repo
d;
  * Redistribute code files in source (if provided to you by Anaconda as source) and binary forms, with or without m
n subject to the requirements set forth below, and;

Anaconda may, at its option, make available patches, workarounds or other updates to Anaconda Distribution. Unless t
 are provided with their separate governing terms, they are deemed part of Anaconda Distribution licensed to you as
n this Agreement.  This Agreement does not entitle you to any support for Anaconda Distribution.

Anaconda reserves all rights not expressly granted to you in this Agreement.

Redistribution and use in source and binary forms, with or without modification, are permitted provided that the fol
ditions are met:

  * Redistributions of source code must retain the above copyright notice, this list of conditions and the following
r.
  * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the follow
imer in the documentation and/or other materials provided with the distribution.
  * Neither the name of Anaconda nor the names of its contributors may be used to endorse or promote products derive
s software without specific prior written permission.
  * The purpose of the redistribution is not part of a commercial product for resale. Please contact the Anaconda te
hird party redistribution commercial license
  * Commercial usage of the repository is non-compliant with our Terms of Service . Please contact us to learn more
commercial offerings.

You acknowledge that, as between you and Anaconda, Anaconda owns all right, title, and interest, including all intel
operty rights, in and to Anaconda Distribution and, with respect to third-party products distributed with or through
Distribution, the applicable third-party licensors own all right, title and interest, including all intellectual pro
ts, in and to such products.  If you send or transmit any communications or materials to Anaconda suggesting or reco
hanges to the software or documentation, including without limitation, new features or functionality relating theret
comments, questions, suggestions or the like ("Feedback"), Anaconda is free to use such Feedback. You hereby assign
a all right, title, and interest in, and Anaconda is free to use, without any attribution or compensation to any par
eas, know-how, concepts, techniques or other intellectual property rights contained in the Feedback, for any purpose
r, although Anaconda is not required to use any Feedback.

THIS SOFTWARE IS PROVIDED BY ANACONDA AND ITS CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
IMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVEN
ACONDA BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
D TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARIS
 WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

TO THE MAXIMUM EXTENT PERMITTED BY LAW, ANACONDA AND ITS AFFILIATES SHALL NOT BE LIABLE FOR ANY SPECIAL, INCIDENTAL,
OR CONSEQUENTIAL DAMAGES, OR ANY LOST PROFITS, LOSS OF USE, LOSS OF DATA OR LOSS OF GOODWILL, OR THE COSTS OF PROCUR
TUTE PRODUCTS, ARISING OUT OF OR IN CONNECTION WITH THIS AGREEMENT OR THE USE OR PERFORMANCE OF ANACONDA DISTRIBUTIO
 SUCH LIABILITY ARISES FROM ANY CLAIM BASED UPON BREACH OF CONTRACT, BREACH OF WARRANTY, TORT (INCLUDING NEGLIGENCE)
LIABILITY OR ANY OTHER CAUSE OF ACTION OR THEORY OF LIABILITY. IN NO EVENT WILL THE TOTAL CUMULATIVE LIABILITY OF AN
 ITS AFFILIATES UNDER OR ARISING OUT OF THIS AGREEMENT EXCEED 10.00 U.S. DOLLARS.

If you want to terminate this Agreement, you may do so by discontinuing use of Anaconda Distribution.  Anaconda may,
me, terminate this Agreement and the license granted hereunder if you fail to comply with any term of this Agreement
ny termination of this Agreement, you agree to promptly discontinue use of the Anaconda Distribution and destroy all
 your possession or control. Upon any termination of this Agreement all provisions survive except for the licenses g
you.

This Agreement is governed by and construed in accordance with the internal laws of the State of Texas without givin
o any choice or conflict of law provision or rule that would require or permit the application of the laws of any ju
 other than those of the State of Texas. Any legal suit, action, or proceeding arising out of or related to this Agr
the licenses granted hereunder by you must be instituted exclusively in the federal courts of the United States or t
of the State of Texas in each case located in Travis County, Texas, and you irrevocably submit to the jurisdiction o
rts in any such suit, action, or proceeding.

Notice of Third Party Software Licenses
=======================================

Anaconda Distribution provides access to a repository which contains software packages or tools licensed on an open
is from third parties and binary packages of these third party tools. These third party software packages or tools a
d on an "as is" basis and are subject to their respective license agreements as well as this Agreement and the Terms
e for the Repository located at https://know.anaconda.com/TOS.html; provided, however, no restriction contained in t
f Service shall be construed so as to limit Your ability to download the packages contained in Anaconda Distribution
you comply with the license for each such package.  These licenses may be accessed from within the Anaconda Distribu
are or https://www.anaconda.com/legal. Information regarding which license is applicable is available from within ma
third party software packages and tools and at https://repo.anaconda.com/pkgs/main/ and https://repo.anaconda.com/pk
conda reserves the right, in its sole discretion, to change which third party tools are included in the repository a
through Anaconda Distribution.

Intel Math Kernel Library
-------------------------

Anaconda Distribution provides access to re-distributable, run-time, shared-library files from the Intel Math Kernel
"MKL binaries").

Copyright 2018 Intel Corporation.  License available at https://software.intel.com/en-us/license/intel-simplified-so
ense (the "MKL License").

You may use and redistribute the MKL binaries, without modification, provided the following conditions are met:

  * Redistributions must reproduce the above copyright notice and the following terms of use in the MKL binaries and
cumentation and/or other materials provided with the distribution.
  * Neither the name of Intel nor the names of its suppliers may be used to endorse or promote products derived from
inaries without specific prior written permission.
  * No reverse engineering, decompilation, or disassembly of the MKL binaries is permitted.

You are specifically authorized to use and redistribute the MKL binaries with your installation of Anaconda Distribu
ct to the terms set forth in the MKL License. You are also authorized to redistribute the MKL binaries with Anaconda
ion or in the Anaconda package that contains the MKL binaries. If needed, instructions for removing the MKL binaries
tallation of Anaconda Distribution are available at https://docs.anaconda.com.

cuDNN Software
--------------

Anaconda Distribution also provides access to cuDNN software binaries ("cuDNN binaries") from NVIDIA Corporation. Yo
ifically authorized to use the cuDNN binaries with your installation of Anaconda Distribution subject to your compli
the license agreement located at https://docs.nvidia.com/deeplearning/sdk/cudnn-sla/index.html. You are also authori
istribute the cuDNN binaries with an Anaconda Distribution package that contains the cuDNN binaries. You can add or
 cuDNN binaries utilizing the install and uninstall features in Anaconda Distribution.

cuDNN binaries contain source code provided by NVIDIA Corporation.

Arm Performance Libraries
-------------------------

Arm Performance Libraries (Free Version): Anaconda provides access to software and related documentation from the Ar
nce Libraries ("Arm PL") provided by Arm Limited. By installing or otherwise accessing the Arm PL, you acknowledge a
hat use and distribution of the Arm PL is subject to your compliance with the Arm PL end user license agreement loca
tps://developer.arm.com/tools-and-software/server-and-hpc/downloads/arm-performance-libraries/eula.

Export; Cryptography Notice
===========================

You must comply with all domestic and international export laws and regulations that apply to the software, which in
rictions on destinations, end users, and end use.  Anaconda Distribution includes cryptographic software. The countr
 you currently reside may have restrictions on the import, possession, use, and/or re-export to another country, of
 software. BEFORE using any encryption software, please check your country's laws, regulations and policies concerni
ort, possession, or use, and re-export of encryption software, to see if this is permitted. See the Wassenaar Arrang
://www.wassenaar.org/ for more information.

Anaconda has self-classified this software as Export Commodity Control Number (ECCN) EAR99 which includes mass marke
ion security software using or performing cryptographic functions with asymmetric algorithms. No license is required
t of this software to non-embargoed countries.

The Intel Math Kernel Library contained in Anaconda Distribution is classified by Intel as ECCN 5D992.c with no lice
ed for export to non-embargoed countries.

The following packages listed on https://www.anaconda.com/cryptography are included in the repository accessible thr
nda Distribution that relate to cryptography.

Last updated February 25, 2022


Do you accept the license terms? [yes|no]
[no] >>>  y
Please answer 'yes' or 'no':'
>>> yes

Anaconda3 will now be installed into this location:
/home/raul/anaconda3

  - Press ENTER to confirm the location
  - Press CTRL-C to abort the installation
  - Or specify a different location below

[/home/raul/anaconda3] >>>
PREFIX=/home/raul/anaconda3
Unpacking payload ...
concurrent.futures.process._RemoteTraceback:
'''
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 387, in wait_result_broken_or_wakeup
  File "multiprocessing/connection.py", line 256, in recv
TypeError: __init__() missing 1 required positional argument: 'msg'
'''

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "entry_point.py", line 69, in <module>
  File "concurrent/futures/process.py", line 562, in _chain_from_iterable_of_lists
  File "concurrent/futures/_base.py", line 609, in result_iterator
  File "concurrent/futures/_base.py", line 446, in result
  File "concurrent/futures/_base.py", line 391, in __get_result
concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the futureng or pending.
[12425] Failed to execute script 'entry_point' due to unhandled exception!
raul@119cb66ee7b2:~$
raul@119cb66ee7b2:~$
raul@119cb66ee7b2:~$ which conda
/home/raul/anaconda3/condabin/conda
raul@119cb66ee7b2:~$ conda install anaconda-clean
Collecting package metadata (current_repodata.json): / WARNING conda.models.version:get_matcher(546): Using .* with  operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, butignoring the .* and treating it as 1.7.1                                                                            ne
Solving environment: failed with initial frozen solve. Retrying with flexible solve.

CondaError: KeyboardInterrupt


raul@119cb66ee7b2:~$
raul@119cb66ee7b2:~$
raul@119cb66ee7b2:~$
raul@119cb66ee7b2:~$
raul@119cb66ee7b2:~$
raul@119cb66ee7b2:~$
raul@119cb66ee7b2:~$ rm -rf anaconda3/
raul@119cb66ee7b2:~$ apt-get install libgl1-mesa-glx libegl1-mesa libxrandr2 libxrandr2 libxss1 libxcursor1 libxcompasound2 libxi6 libxtst6
E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)
E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?
raul@119cb66ee7b2:~$ sudo apt-get install libgl1-mesa-glx libegl1-mesa libxrandr2 libxrandr2 libxss1 libxcursor1 lib1 libasound2 libxi6 libxtst6
[sudo] password for raul:
Reading package lists... Done
Building dependency tree
Reading state information... Done
libxcomposite1 is already the newest version (1:0.4.4-2).
libxcomposite1 set to manually installed.
libxcursor1 is already the newest version (1:1.1.15-1).
libxcursor1 set to manually installed.
libxi6 is already the newest version (2:1.7.9-1).
libxi6 set to manually installed.
libxrandr2 is already the newest version (2:1.5.1-1).
libxrandr2 set to manually installed.
libxss1 is already the newest version (1:1.2.2-1).
libxss1 set to manually installed.
libxtst6 is already the newest version (2:1.2.3-1).
libxtst6 set to manually installed.
libasound2 is already the newest version (1.1.3-5ubuntu0.6).
libasound2 set to manually installed.
The following additional packages will be installed:
  libegl-mesa0 libegl1 libgbm1 libglapi-mesa libglx-mesa0 libwayland-client0 libwayland-server0 libxcb-xfixes0
The following NEW packages will be installed:
  libegl-mesa0 libegl1 libegl1-mesa libgbm1 libwayland-client0 libwayland-server0 libxcb-xfixes0
The following packages will be upgraded:
  libgl1-mesa-glx libglapi-mesa libglx-mesa0
3 upgraded, 7 newly installed, 0 to remove and 198 not upgraded.
Need to get 396 kB of archives.
After this operation, 947 kB of additional disk space will be used.
Do you want to continue? [Y/n] Y
Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwayland-server0 amd64 1.16.0-1ubuntu1.1~18.04.4
Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgbm1 amd64 20.0.8-0ubuntu1~18.04.1 [27.6 kB]
Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglx-mesa0 amd64 20.0.8-0ubuntu1~18.04.1 [139 kB]
Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglapi-mesa amd64 20.0.8-0ubuntu1~18.04.1 [26.6 k
Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwayland-client0 amd64 1.16.0-1ubuntu1.1~18.04.4
Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-xfixes0 amd64 1.13-2~ubuntu18.04 [9352 B]
Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libegl-mesa0 amd64 20.0.8-0ubuntu1~18.04.1 [96.3 kB
Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libegl1 amd64 1.0.0-2ubuntu2.3 [32.0 kB]
Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libegl1-mesa amd64 20.0.8-0ubuntu1~18.04.1 [6416 B]
Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgl1-mesa-glx amd64 20.0.8-0ubuntu1~18.04.1 [553
Fetched 396 kB in 0s (895 kB/s)
debconf: delaying package configuration, since apt-utils is not installed
Selecting previously unselected package libwayland-server0:amd64.
(Reading database ... 36054 files and directories currently installed.)
Preparing to unpack .../0-libwayland-server0_1.16.0-1ubuntu1.1~18.04.4_amd64.deb ...
Unpacking libwayland-server0:amd64 (1.16.0-1ubuntu1.1~18.04.4) ...
Selecting previously unselected package libgbm1:amd64.
Preparing to unpack .../1-libgbm1_20.0.8-0ubuntu1~18.04.1_amd64.deb ...
Unpacking libgbm1:amd64 (20.0.8-0ubuntu1~18.04.1) ...
Preparing to unpack .../2-libglx-mesa0_20.0.8-0ubuntu1~18.04.1_amd64.deb ...
Unpacking libglx-mesa0:amd64 (20.0.8-0ubuntu1~18.04.1) over (19.2.8-0ubuntu0~18.04.3) ...
Preparing to unpack .../3-libglapi-mesa_20.0.8-0ubuntu1~18.04.1_amd64.deb ...
Unpacking libglapi-mesa:amd64 (20.0.8-0ubuntu1~18.04.1) over (19.2.8-0ubuntu0~18.04.3) ...
Selecting previously unselected package libwayland-client0:amd64.
Preparing to unpack .../4-libwayland-client0_1.16.0-1ubuntu1.1~18.04.4_amd64.deb ...
Unpacking libwayland-client0:amd64 (1.16.0-1ubuntu1.1~18.04.4) ...
Selecting previously unselected package libxcb-xfixes0:amd64.
Preparing to unpack .../5-libxcb-xfixes0_1.13-2~ubuntu18.04_amd64.deb ...
Unpacking libxcb-xfixes0:amd64 (1.13-2~ubuntu18.04) ...
Selecting previously unselected package libegl-mesa0:amd64.
Preparing to unpack .../6-libegl-mesa0_20.0.8-0ubuntu1~18.04.1_amd64.deb ...
Unpacking libegl-mesa0:amd64 (20.0.8-0ubuntu1~18.04.1) ...
Selecting previously unselected package libegl1:amd64.
Preparing to unpack .../7-libegl1_1.0.0-2ubuntu2.3_amd64.deb ...
Unpacking libegl1:amd64 (1.0.0-2ubuntu2.3) ...
Selecting previously unselected package libegl1-mesa:amd64.
Preparing to unpack .../8-libegl1-mesa_20.0.8-0ubuntu1~18.04.1_amd64.deb ...
Unpacking libegl1-mesa:amd64 (20.0.8-0ubuntu1~18.04.1) ...
Preparing to unpack .../9-libgl1-mesa-glx_20.0.8-0ubuntu1~18.04.1_amd64.deb ...
Unpacking libgl1-mesa-glx:amd64 (20.0.8-0ubuntu1~18.04.1) over (19.2.8-0ubuntu0~18.04.3) ...
Setting up libxcb-xfixes0:amd64 (1.13-2~ubuntu18.04) ...
Setting up libwayland-client0:amd64 (1.16.0-1ubuntu1.1~18.04.4) ...
Setting up libglapi-mesa:amd64 (20.0.8-0ubuntu1~18.04.1) ...
Setting up libglx-mesa0:amd64 (20.0.8-0ubuntu1~18.04.1) ...
Setting up libwayland-server0:amd64 (1.16.0-1ubuntu1.1~18.04.4) ...
Setting up libgbm1:amd64 (20.0.8-0ubuntu1~18.04.1) ...
Setting up libgl1-mesa-glx:amd64 (20.0.8-0ubuntu1~18.04.1) ...
Setting up libegl-mesa0:amd64 (20.0.8-0ubuntu1~18.04.1) ...
Setting up libegl1:amd64 (1.0.0-2ubuntu2.3) ...
Setting up libegl1-mesa:amd64 (20.0.8-0ubuntu1~18.04.1) ...
Processing triggers for libc-bin (2.27-3ubuntu1) ...
raul@119cb66ee7b2:~$ bash Anaconda3-2023.07-2-Linux-x86_64.sh

Welcome to Anaconda3 2023.07-2

In order to continue the installation process, please review the license
agreement.
Please, press ENTER to continue
>>>
==================================================
End User License Agreement - Anaconda Distribution
==================================================

Copyright 2015-2023, Anaconda, Inc.

All rights reserved under the 3-clause BSD License:

This End User License Agreement (the "Agreement") is a legal agreement between you and Anaconda, Inc. ("Anaconda") a
 your use of Anaconda Distribution (which was formerly known as Anaconda Individual Edition).

Subject to the terms of this Agreement, Anaconda hereby grants you a non-exclusive, non-transferable license to:

  * Install and use the Anaconda Distribution (which was formerly known as Anaconda Individual Edition),
  * Modify and create derivative works of sample source code delivered in Anaconda Distribution from Anaconda's repo
d;
  * Redistribute code files in source (if provided to you by Anaconda as source) and binary forms, with or without m
n subject to the requirements set forth below, and;

Anaconda may, at its option, make available patches, workarounds or other updates to Anaconda Distribution. Unless t
 are provided with their separate governing terms, they are deemed part of Anaconda Distribution licensed to you as
n this Agreement.  This Agreement does not entitle you to any support for Anaconda Distribution.

Anaconda reserves all rights not expressly granted to you in this Agreement.

Redistribution and use in source and binary forms, with or without modification, are permitted provided that the fol
ditions are met:

  * Redistributions of source code must retain the above copyright notice, this list of conditions and the following
r.
  * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the follow
imer in the documentation and/or other materials provided with the distribution.
  * Neither the name of Anaconda nor the names of its contributors may be used to endorse or promote products derive
s software without specific prior written permission.
  * The purpose of the redistribution is not part of a commercial product for resale. Please contact the Anaconda te
hird party redistribution commercial license
  * Commercial usage of the repository is non-compliant with our Terms of Service . Please contact us to learn more
commercial offerings.

You acknowledge that, as between you and Anaconda, Anaconda owns all right, title, and interest, including all intel
operty rights, in and to Anaconda Distribution and, with respect to third-party products distributed with or through
Distribution, the applicable third-party licensors own all right, title and interest, including all intellectual pro
ts, in and to such products.  If you send or transmit any communications or materials to Anaconda suggesting or reco
hanges to the software or documentation, including without limitation, new features or functionality relating theret
comments, questions, suggestions or the like ("Feedback"), Anaconda is free to use such Feedback. You hereby assign
a all right, title, and interest in, and Anaconda is free to use, without any attribution or compensation to any par
eas, know-how, concepts, techniques or other intellectual property rights contained in the Feedback, for any purpose
r, although Anaconda is not required to use any Feedback.

THIS SOFTWARE IS PROVIDED BY ANACONDA AND ITS CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
IMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVEN
ACONDA BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
D TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARIS
 WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

TO THE MAXIMUM EXTENT PERMITTED BY LAW, ANACONDA AND ITS AFFILIATES SHALL NOT BE LIABLE FOR ANY SPECIAL, INCIDENTAL,
OR CONSEQUENTIAL DAMAGES, OR ANY LOST PROFITS, LOSS OF USE, LOSS OF DATA OR LOSS OF GOODWILL, OR THE COSTS OF PROCUR
TUTE PRODUCTS, ARISING OUT OF OR IN CONNECTION WITH THIS AGREEMENT OR THE USE OR PERFORMANCE OF ANACONDA DISTRIBUTIO
 SUCH LIABILITY ARISES FROM ANY CLAIM BASED UPON BREACH OF CONTRACT, BREACH OF WARRANTY, TORT (INCLUDING NEGLIGENCE)
LIABILITY OR ANY OTHER CAUSE OF ACTION OR THEORY OF LIABILITY. IN NO EVENT WILL THE TOTAL CUMULATIVE LIABILITY OF AN
 ITS AFFILIATES UNDER OR ARISING OUT OF THIS AGREEMENT EXCEED 10.00 U.S. DOLLARS.

If you want to terminate this Agreement, you may do so by discontinuing use of Anaconda Distribution.  Anaconda may,
me, terminate this Agreement and the license granted hereunder if you fail to comply with any term of this Agreement
ny termination of this Agreement, you agree to promptly discontinue use of the Anaconda Distribution and destroy all
 your possession or control. Upon any termination of this Agreement all provisions survive except for the licenses g
you.

This Agreement is governed by and construed in accordance with the internal laws of the State of Texas without givin
o any choice or conflict of law provision or rule that would require or permit the application of the laws of any ju
 other than those of the State of Texas. Any legal suit, action, or proceeding arising out of or related to this Agr
the licenses granted hereunder by you must be instituted exclusively in the federal courts of the United States or t
of the State of Texas in each case located in Travis County, Texas, and you irrevocably submit to the jurisdiction o
rts in any such suit, action, or proceeding.

Notice of Third Party Software Licenses
=======================================

Anaconda Distribution provides access to a repository which contains software packages or tools licensed on an open
is from third parties and binary packages of these third party tools. These third party software packages or tools a
d on an "as is" basis and are subject to their respective license agreements as well as this Agreement and the Terms
e for the Repository located at https://know.anaconda.com/TOS.html; provided, however, no restriction contained in t
f Service shall be construed so as to limit Your ability to download the packages contained in Anaconda Distribution
you comply with the license for each such package.  These licenses may be accessed from within the Anaconda Distribu
are or https://www.anaconda.com/legal. Information regarding which license is applicable is available from within ma
third party software packages and tools and at https://repo.anaconda.com/pkgs/main/ and https://repo.anaconda.com/pk
conda reserves the right, in its sole discretion, to change which third party tools are included in the repository a
through Anaconda Distribution.

Intel Math Kernel Library
-------------------------

Anaconda Distribution provides access to re-distributable, run-time, shared-library files from the Intel Math Kernel
"MKL binaries").

Copyright 2018 Intel Corporation.  License available at https://software.intel.com/en-us/license/intel-simplified-so
ense (the "MKL License").

You may use and redistribute the MKL binaries, without modification, provided the following conditions are met:

  * Redistributions must reproduce the above copyright notice and the following terms of use in the MKL binaries and
cumentation and/or other materials provided with the distribution.
  * Neither the name of Intel nor the names of its suppliers may be used to endorse or promote products derived from
inaries without specific prior written permission.
  * No reverse engineering, decompilation, or disassembly of the MKL binaries is permitted.

You are specifically authorized to use and redistribute the MKL binaries with your installation of Anaconda Distribu
ct to the terms set forth in the MKL License. You are also authorized to redistribute the MKL binaries with Anaconda
ion or in the Anaconda package that contains the MKL binaries. If needed, instructions for removing the MKL binaries
tallation of Anaconda Distribution are available at https://docs.anaconda.com.

cuDNN Software
--------------

Anaconda Distribution also provides access to cuDNN software binaries ("cuDNN binaries") from NVIDIA Corporation. Yo
ifically authorized to use the cuDNN binaries with your installation of Anaconda Distribution subject to your compli
the license agreement located at https://docs.nvidia.com/deeplearning/sdk/cudnn-sla/index.html. You are also authori
istribute the cuDNN binaries with an Anaconda Distribution package that contains the cuDNN binaries. You can add or
 cuDNN binaries utilizing the install and uninstall features in Anaconda Distribution.

cuDNN binaries contain source code provided by NVIDIA Corporation.

Arm Performance Libraries
-------------------------

Arm Performance Libraries (Free Version): Anaconda provides access to software and related documentation from the Ar
nce Libraries ("Arm PL") provided by Arm Limited. By installing or otherwise accessing the Arm PL, you acknowledge a
hat use and distribution of the Arm PL is subject to your compliance with the Arm PL end user license agreement loca
tps://developer.arm.com/tools-and-software/server-and-hpc/downloads/arm-performance-libraries/eula.

Export; Cryptography Notice
===========================

You must comply with all domestic and international export laws and regulations that apply to the software, which in
rictions on destinations, end users, and end use.  Anaconda Distribution includes cryptographic software. The countr
 you currently reside may have restrictions on the import, possession, use, and/or re-export to another country, of
 software. BEFORE using any encryption software, please check your country's laws, regulations and policies concerni
ort, possession, or use, and re-export of encryption software, to see if this is permitted. See the Wassenaar Arrang
://www.wassenaar.org/ for more information.

Anaconda has self-classified this software as Export Commodity Control Number (ECCN) EAR99 which includes mass marke
ion security software using or performing cryptographic functions with asymmetric algorithms. No license is required
t of this software to non-embargoed countries.

The Intel Math Kernel Library contained in Anaconda Distribution is classified by Intel as ECCN 5D992.c with no lice
ed for export to non-embargoed countries.

The following packages listed on https://www.anaconda.com/cryptography are included in the repository accessible thr
nda Distribution that relate to cryptography.

Last updated February 25, 2022


Do you accept the license terms? [yes|no]
[no] >>> yesç
Please answer 'yes' or 'no':'
>>> yes

Anaconda3 will now be installed into this location:
/home/raul/anaconda3

  - Press ENTER to confirm the location
  - Press CTRL-C to abort the installation
  - Or specify a different location below

[/home/raul/anaconda3] >>>
PREFIX=/home/raul/anaconda3
Unpacking payload ...

Installing base environment...


Downloading and Extracting Packages


Downloading and Extracting Packages

Preparing transaction: done
Executing transaction: |

    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.
    More details are available here: https://intel.github.io/scikit-learn-intelex

    For example:

        $ conda install scikit-learn-intelex
        $ python -m sklearnex my_application.py


                                                                                                                    ne
installation finished.
Do you wish the installer to initialize Anaconda3
by running conda init? [yes|no]
[no] >>> yes
no change     /home/raul/anaconda3/condabin/conda
no change     /home/raul/anaconda3/bin/conda
no change     /home/raul/anaconda3/bin/conda-env
no change     /home/raul/anaconda3/bin/activate
no change     /home/raul/anaconda3/bin/deactivate
no change     /home/raul/anaconda3/etc/profile.d/conda.sh
no change     /home/raul/anaconda3/etc/fish/conf.d/conda.fish
no change     /home/raul/anaconda3/shell/condabin/Conda.psm1
no change     /home/raul/anaconda3/shell/condabin/conda-hook.ps1
no change     /home/raul/anaconda3/lib/python3.11/site-packages/xontrib/conda.xsh
no change     /home/raul/anaconda3/etc/profile.d/conda.csh
no change     /home/raul/.bashrc
No action taken.
If you'd prefer that conda's base environment not be activated on startup,
   set the auto_activate_base parameter to false:

conda config --set auto_activate_base false

Thank you for installing Anaconda3!
raul@119cb66ee7b2:~$ exit
logout
Connection to 192.168.150.119 closed.


 ? 19/09/2023 ? ? 09:57.52 ? ? /home/mobaxterm ? ssh raul@192.168.150.119 -p 49161
raul@192.168.150.119's password:
X11 forwarding request failed on channel 0
Welcome to Ubuntu 18.04.4 LTS (GNU/Linux 5.3.0-62-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

This system has been minimized by removing packages and content that are
not required on a system that users do not log into.

To restore this content, you can run the 'unminimize' command.
Last login: Tue Sep 19 09:41:55 2023 from 192.168.151.182
(base) raul@119cb66ee7b2:~$ conda --version
conda 23.7.2
(base) raul@119cb66ee7b2:~$ conda install mamba
Collecting package metadata (current_repodata.json): \ DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1naconda.org:443
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): conda.anaconda.org:443
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): conda.anaconda.org:443
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): conda.anaconda.org:443
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443                               DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 "GET /pkgs/r/noarch/current_repodata.json HTTP/1.1" 200 N
DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 "GET /pkgs/main/noarch/current_repodata.json HTTP/1.1" 20
DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 "GET /pkgs/main/linux-64/current_repodata.json HTTP/1.1"
DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 "GET /pkgs/r/linux-64/current_repodata.json HTTP/1.1" 200DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 "GET /bioconda/noarch/current_repodata.json HTTP/1.1" 20
DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 "GET /bioconda/linux-64/current_repodata.json HTTP/1.1"
DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 "GET /conda-forge/noarch/current_repodata.json HTTP/1.1"
DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 "GET /conda-forge/linux-64/current_repodata.json HTTP/1.e                                                                                                                   WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and woved in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1     ne
Solving environment: unsuccessful initial attempt using frozen solve. Retrying with flexible solve.

CondaError: KeyboardInterrupt

(base) raul@119cb66ee7b2:~$
(base) raul@119cb66ee7b2:~$ rm -rf anaconda3/
(base) raul@119cb66ee7b2:~$ rm -rf miniconda3/
(base) raul@119cb66ee7b2:~$ curl -L -O "https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge$(uname -m).sh"
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100 82.9M  100 82.9M    0     0  30.3M      0  0:00:02  0:00:02 --:--:-- 48.1M
(base) raul@119cb66ee7b2:~$ bash Mambaforge-Linux-x86_64.sh

Welcome to Mambaforge 23.3.1-1

In order to continue the installation process, please review the license
agreement.
Please, press ENTER to continue
>>>
Miniforge installer code uses BSD-3-Clause license as stated below.

Binary packages that come with it have their own licensing terms
and by installing miniforge you agree to the licensing terms of individual
packages as well. They include different OSI-approved licenses including
the GNU General Public License and can be found in pkgs/<pkg-name>/info/licenses
folders.

Miniforge installer comes with a boostrapping executable that is used
when installing miniforge and is deleted after miniforge is installed.
The bootstrapping executable uses micromamba, cli11, cpp-filesystem,
curl, c-ares, krb5, libarchive, libev, lz4, nghttp2, openssl, libsolv,
nlohmann-json, reproc and zstd which are licensed under BSD-3-Clause,
MIT and OpenSSL licenses. Licenses and copyright notices of these
projects can be found at the following URL.
https://github.com/conda-forge/micromamba-feedstock/tree/master/recipe.

=============================================================================

Copyright (c) 2019-2022, conda-forge
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

1. Redistributions of source code must retain the above copyright notice, this
list of conditions and the following disclaimer.

2. Redistributions in binary form must reproduce the above copyright notice,
this list of conditions and the following disclaimer in the documentation
and/or other materials provided with the distribution.

3. Neither the name of the copyright holder nor the names of its contributors
may be used to endorse or promote products derived from this software without
specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


Do you accept the license terms? [yes|no]
[no] >>> yes

Mambaforge will now be installed into this location:
/home/raul/mambaforge

  - Press ENTER to confirm the location
  - Press CTRL-C to abort the installation
  - Or specify a different location below

[/home/raul/mambaforge] >>>
PREFIX=/home/raul/mambaforge
Unpacking payload ...
Extracting _libgcc_mutex-0.1-conda_forge.tar.bz2
Extracting ca-certificates-2023.7.22-hbcca054_0.conda
Extracting ld_impl_linux-64-2.40-h41732ed_0.conda
Extracting libstdcxx-ng-13.1.0-hfd8a6a1_0.conda
Extracting pybind11-abi-4-hd8ed1ab_3.tar.bz2
Extracting python_abi-3.10-3_cp310.conda
Extracting tzdata-2023c-h71feb2d_0.conda
Extracting libgomp-13.1.0-he5830b7_0.conda
Extracting _openmp_mutex-4.5-2_gnu.tar.bz2
Extracting libgcc-ng-13.1.0-he5830b7_0.conda
Extracting bzip2-1.0.8-h7f98852_4.tar.bz2
Extracting c-ares-1.19.1-hd590300_0.conda
Extracting fmt-9.1.0-h924138e_0.tar.bz2
Extracting icu-73.2-h59595ed_0.conda
Extracting keyutils-1.6.1-h166bdaf_0.tar.bz2
Extracting libev-4.33-h516909a_1.tar.bz2
Extracting libffi-3.4.2-h7f98852_5.tar.bz2
Extracting libiconv-1.17-h166bdaf_0.tar.bz2
Extracting libnsl-2.0.0-h7f98852_0.tar.bz2
Extracting libuuid-2.38.1-h0b41bf4_0.conda
Extracting libzlib-1.2.13-hd590300_5.conda
Extracting lz4-c-1.9.4-hcb278e6_0.conda
Extracting lzo-2.10-h516909a_1000.tar.bz2
Extracting ncurses-6.4-hcb278e6_0.conda
Extracting openssl-3.1.2-hd590300_0.conda
Extracting reproc-14.2.4-h0b41bf4_0.conda
Extracting xz-5.2.6-h166bdaf_0.tar.bz2
Extracting yaml-cpp-0.7.0-h27087fc_2.tar.bz2
Extracting libedit-3.1.20191231-he28a2e2_2.tar.bz2
Extracting libnghttp2-1.52.0-h61bc06f_0.conda
Extracting libsolv-0.7.24-hfc55251_3.conda
Extracting libsqlite-3.43.0-h2797004_0.conda
Extracting libssh2-1.11.0-h0841786_0.conda
Extracting libxml2-2.11.5-h232c23b_1.conda
Extracting readline-8.2-h8228510_1.conda
Extracting reproc-cpp-14.2.4-hcb278e6_0.conda
Extracting tk-8.6.12-h27826a3_0.tar.bz2
Extracting zstd-1.5.5-hfc55251_0.conda
Extracting krb5-1.21.2-h659d440_0.conda
Extracting libarchive-3.6.2-h039dbb9_1.conda
Extracting python-3.10.12-hd12c33a_0_cpython.conda
Extracting boltons-23.0.0-pyhd8ed1ab_0.conda
Extracting brotli-python-1.1.0-py310hc6cd4ac_0.conda
Extracting certifi-2023.7.22-pyhd8ed1ab_0.conda
Extracting charset-normalizer-3.2.0-pyhd8ed1ab_0.conda
Extracting colorama-0.4.6-pyhd8ed1ab_0.tar.bz2
Extracting idna-3.4-pyhd8ed1ab_0.tar.bz2
Extracting jsonpointer-2.0-py_0.tar.bz2
Extracting libcurl-8.2.1-hca28451_0.conda
Extracting packaging-23.1-pyhd8ed1ab_0.conda
Extracting pluggy-1.3.0-pyhd8ed1ab_0.conda
Extracting pycosat-0.6.4-py310h5764c6d_1.tar.bz2
Extracting pycparser-2.21-pyhd8ed1ab_0.tar.bz2
Extracting pysocks-1.7.1-pyha2e5f31_6.tar.bz2
Extracting ruamel.yaml.clib-0.2.7-py310h1fa729e_1.conda
Extracting setuptools-68.1.2-pyhd8ed1ab_0.conda
Extracting toolz-0.12.0-pyhd8ed1ab_0.tar.bz2
Extracting wheel-0.41.2-pyhd8ed1ab_0.conda
Extracting cffi-1.15.1-py310h255011f_3.conda
Extracting jsonpatch-1.32-pyhd8ed1ab_0.tar.bz2
Extracting libmamba-1.4.2-hcea66bb_0.conda
Extracting pip-23.2.1-pyhd8ed1ab_0.conda
Extracting ruamel.yaml-0.17.32-py310h2372a71_0.conda
Extracting tqdm-4.66.1-pyhd8ed1ab_0.conda
Extracting urllib3-2.0.4-pyhd8ed1ab_0.conda
Extracting cryptography-41.0.3-py310h75e40e8_0.conda
Extracting libmambapy-1.4.2-py310h1428755_0.conda
Extracting requests-2.31.0-pyhd8ed1ab_0.conda
Extracting zstandard-0.19.0-py310h5764c6d_0.tar.bz2
Extracting conda-package-streaming-0.9.0-pyhd8ed1ab_0.conda
Extracting pyopenssl-23.2.0-pyhd8ed1ab_1.conda
Extracting conda-package-handling-2.2.0-pyh38be061_0.conda
Extracting conda-23.3.1-py310hff52083_0.conda
Extracting conda-libmamba-solver-23.3.0-pyhd8ed1ab_0.conda
Extracting mamba-1.4.2-py310h51d5547_0.conda

Installing base environment...


                                           __
          __  ______ ___  ____ _____ ___  / /_  ____ _
         / / / / __ `__ \/ __ `/ __ `__ \/ __ \/ __ `/
        / /_/ / / / / / / /_/ / / / / / / /_/ / /_/ /
       / .___/_/ /_/ /_/\__,_/_/ /_/ /_/_.___/\__,_/
      /_/

Transaction

  Prefix: /home/raul/mambaforge

  Updating specs:

   - conda-forge/linux-64::_libgcc_mutex==0.1=conda_forge[md5=d7c89558ba9fa0495403155b64376d81]
   - conda-forge/linux-64::ca-certificates==2023.7.22=hbcca054_0[md5=a73ecd2988327ad4c8f2c331482917f2]
   - conda-forge/linux-64::ld_impl_linux-64==2.40=h41732ed_0[md5=7aca3059a1729aa76c597603f10b0dd3]
   - conda-forge/linux-64::libstdcxx-ng==13.1.0=hfd8a6a1_0[md5=067bcc23164642f4c226da631f2a2e1d]
   - conda-forge/noarch::pybind11-abi==4=hd8ed1ab_3[md5=878f923dd6acc8aeb47a75da6c4098be]
   - conda-forge/linux-64::python_abi==3.10=3_cp310[md5=4eb33d14d794b0f4be116443ffed3853]
   - conda-forge/noarch::tzdata==2023c=h71feb2d_0[md5=939e3e74d8be4dac89ce83b20de2492a]
   - conda-forge/linux-64::libgomp==13.1.0=he5830b7_0[md5=56ca14d57ac29a75d23a39eb3ee0ddeb]
   - conda-forge/linux-64::_openmp_mutex==4.5=2_gnu[md5=73aaf86a425cc6e73fcf236a5a46396d]
   - conda-forge/linux-64::libgcc-ng==13.1.0=he5830b7_0[md5=cd93f779ff018dd85c7544c015c9db3c]
   - conda-forge/linux-64::bzip2==1.0.8=h7f98852_4[md5=a1fd65c7ccbf10880423d82bca54eb54]
   - conda-forge/linux-64::c-ares==1.19.1=hd590300_0[md5=e8c18d865be43e2fb3f7a145b6adf1f5]
   - conda-forge/linux-64::fmt==9.1.0=h924138e_0[md5=b57864c85261a0fbc7132d2cc17478c7]
   - conda-forge/linux-64::icu==73.2=h59595ed_0[md5=cc47e1facc155f91abd89b11e48e72ff]
   - conda-forge/linux-64::keyutils==1.6.1=h166bdaf_0[md5=30186d27e2c9fa62b45fb1476b7200e3]
   - conda-forge/linux-64::libev==4.33=h516909a_1[md5=6f8720dff19e17ce5d48cfe7f3d2f0a3]
   - conda-forge/linux-64::libffi==3.4.2=h7f98852_5[md5=d645c6d2ac96843a2bfaccd2d62b3ac3]
   - conda-forge/linux-64::libiconv==1.17=h166bdaf_0[md5=b62b52da46c39ee2bc3c162ac7f1804d]
   - conda-forge/linux-64::libnsl==2.0.0=h7f98852_0[md5=39b1328babf85c7c3a61636d9cd50206]
   - conda-forge/linux-64::libuuid==2.38.1=h0b41bf4_0[md5=40b61aab5c7ba9ff276c41cfffe6b80b]
   - conda-forge/linux-64::libzlib==1.2.13=hd590300_5[md5=f36c115f1ee199da648e0597ec2047ad]
   - conda-forge/linux-64::lz4-c==1.9.4=hcb278e6_0[md5=318b08df404f9c9be5712aaa5a6f0bb0]
   - conda-forge/linux-64::lzo==2.10=h516909a_1000[md5=bb14fcb13341b81d5eb386423b9d2bac]
   - conda-forge/linux-64::ncurses==6.4=hcb278e6_0[md5=681105bccc2a3f7f1a837d47d39c9179]
   - conda-forge/linux-64::openssl==3.1.2=hd590300_0[md5=e5ac5227582d6c83ccf247288c0eb095]
   - conda-forge/linux-64::reproc==14.2.4=h0b41bf4_0[md5=0f51393e019df1f0047ef864cd9ddeec]
   - conda-forge/linux-64::xz==5.2.6=h166bdaf_0[md5=2161070d867d1b1204ea749c8eec4ef0]
   - conda-forge/linux-64::yaml-cpp==0.7.0=h27087fc_2[md5=0449d47d8457feaa3720d4779616dde2]
   - conda-forge/linux-64::libedit==3.1.20191231=he28a2e2_2[md5=4d331e44109e3f0e19b4cb8f9b82f3e1]
   - conda-forge/linux-64::libnghttp2==1.52.0=h61bc06f_0[md5=613955a50485812985c059e7b269f42e]
   - conda-forge/linux-64::libsolv==0.7.24=hfc55251_3[md5=702feab0e98333ef3eac0d948c605c2d]
   - conda-forge/linux-64::libsqlite==3.43.0=h2797004_0[md5=903fa782a9067d5934210df6d79220f6]
   - conda-forge/linux-64::libssh2==1.11.0=h0841786_0[md5=1f5a58e686b13bcfde88b93f547d23fe]
   - conda-forge/linux-64::libxml2==2.11.5=h232c23b_1[md5=f3858448893839820d4bcfb14ad3ecdf]
   - conda-forge/linux-64::readline==8.2=h8228510_1[md5=47d31b792659ce70f470b5c82fdfb7a4]
   - conda-forge/linux-64::reproc-cpp==14.2.4=hcb278e6_0[md5=ede8e0f849f2fee2f78cb488b4ea3b33]
   - conda-forge/linux-64::tk==8.6.12=h27826a3_0[md5=5b8c42eb62e9fc961af70bdd6a26e168]
   - conda-forge/linux-64::zstd==1.5.5=hfc55251_0[md5=04b88013080254850d6c01ed54810589]
   - conda-forge/linux-64::krb5==1.21.2=h659d440_0[md5=cd95826dbd331ed1be26bdf401432844]
   - conda-forge/linux-64::libarchive==3.6.2=h039dbb9_1[md5=29cf970521d30d113f3425b84cb250f6]
   - conda-forge/linux-64::python==3.10.12=hd12c33a_0_cpython[md5=eb6f1df105f37daedd6dca78523baa75]
   - conda-forge/noarch::boltons==23.0.0=pyhd8ed1ab_0[md5=033eb25fffd222aceeca6d58cd953680]
   - conda-forge/linux-64::brotli-python==1.1.0=py310hc6cd4ac_0[md5=fb6201eb1daa3a3a2f91a4833bdf27c7]
   - conda-forge/noarch::certifi==2023.7.22=pyhd8ed1ab_0[md5=7f3dbc9179b4dde7da98dfb151d0ad22]
   - conda-forge/noarch::charset-normalizer==3.2.0=pyhd8ed1ab_0[md5=313516e9a4b08b12dfb1e1cd390a96e3]
   - conda-forge/noarch::colorama==0.4.6=pyhd8ed1ab_0[md5=3faab06a954c2a04039983f2c4a50d99]
   - conda-forge/noarch::idna==3.4=pyhd8ed1ab_0[md5=34272b248891bddccc64479f9a7fffed]
   - conda-forge/noarch::jsonpointer==2.0=py_0[md5=07d85c22a3beb102a48cd123df84c2a6]
   - conda-forge/linux-64::libcurl==8.2.1=hca28451_0[md5=96aec6156d58591f5a4e67056521ce1b]
   - conda-forge/noarch::packaging==23.1=pyhd8ed1ab_0[md5=91cda59e66e1e4afe9476f8ef98f5c30]
   - conda-forge/noarch::pluggy==1.3.0=pyhd8ed1ab_0[md5=2390bd10bed1f3fdc7a537fb5a447d8d]
   - conda-forge/linux-64::pycosat==0.6.4=py310h5764c6d_1[md5=0e565d732f6660374b45d76761c09b06]
   - conda-forge/noarch::pycparser==2.21=pyhd8ed1ab_0[md5=076becd9e05608f8dc72757d5f3a91ff]
   - conda-forge/noarch::pysocks==1.7.1=pyha2e5f31_6[md5=2a7de29fb590ca14b5243c4c812c8025]
   - conda-forge/linux-64::ruamel.yaml.clib==0.2.7=py310h1fa729e_1[md5=2f9b517412af46255cef5e53a22c264e]
   - conda-forge/noarch::setuptools==68.1.2=pyhd8ed1ab_0[md5=4fe12573bf499ff85a0a364e00cc5c53]
   - conda-forge/noarch::toolz==0.12.0=pyhd8ed1ab_0[md5=92facfec94bc02d6ccf42e7173831a36]
   - conda-forge/noarch::wheel==0.41.2=pyhd8ed1ab_0[md5=1ccd092478b3e0ee10d7a891adbf8a4f]
   - conda-forge/linux-64::cffi==1.15.1=py310h255011f_3[md5=800596144bb613cd7ac58b80900ce835]
   - conda-forge/noarch::jsonpatch==1.32=pyhd8ed1ab_0[md5=09150b51b0528a31a0f6500b96fdde82]
   - conda-forge/linux-64::libmamba==1.4.2=hcea66bb_0[md5=0b3b4c833ea1ec555063479e2ac259dc]
   - conda-forge/noarch::pip==23.2.1=pyhd8ed1ab_0[md5=e2783aa3f9235225eec92f9081c5b801]
   - conda-forge/linux-64::ruamel.yaml==0.17.32=py310h2372a71_0[md5=9a03abf74d5069bda767c1bce7a41e0b]
   - conda-forge/noarch::tqdm==4.66.1=pyhd8ed1ab_0[md5=03c97908b976498dcae97eb4e4f3149c]
   - conda-forge/noarch::urllib3==2.0.4=pyhd8ed1ab_0[md5=18badd8fa3648d1beb1fcc7f2e0f756e]
   - conda-forge/linux-64::cryptography==41.0.3=py310h75e40e8_0[md5=2ad1ab0b68e459f8864e74bdd5b00fe5]
   - conda-forge/linux-64::libmambapy==1.4.2=py310h1428755_0[md5=0c942ea14a0e7a9e394882a8e4405235]
   - conda-forge/noarch::requests==2.31.0=pyhd8ed1ab_0[md5=a30144e4156cdbb236f99ebb49828f8b]
   - conda-forge/linux-64::zstandard==0.19.0=py310h5764c6d_0[md5=74ea667169b1296fb31bb86f13abfa49]
   - conda-forge/noarch::conda-package-streaming==0.9.0=pyhd8ed1ab_0[md5=38253361efb303deead3eab39ae9269b]
   - conda-forge/noarch::pyopenssl==23.2.0=pyhd8ed1ab_1[md5=34f7d568bf59d18e3fef8c405cbece21]
   - conda-forge/noarch::conda-package-handling==2.2.0=pyh38be061_0[md5=8a3ae7f6318376aa08ea753367bb7dd6]
   - conda-forge/linux-64::conda==23.3.1=py310hff52083_0[md5=d182178e1a62f8743044658bf3242af5]
   - conda-forge/noarch::conda-libmamba-solver==23.3.0=pyhd8ed1ab_0[md5=2edd368915b8a1c3e294c9ac944390d9]
   - conda-forge/linux-64::mamba==1.4.2=py310h51d5547_0[md5=a84d408833491f202a6d9f6d8fc696db]


  Package                         Version  Build               Channel           Size
---------------------------------------------------------------------------------------
  Install:
---------------------------------------------------------------------------------------

  + _libgcc_mutex                     0.1  conda_forge         conda-forge     Cached
  + _openmp_mutex                     4.5  2_gnu               conda-forge     Cached
  + boltons                        23.0.0  pyhd8ed1ab_0        conda-forge     Cached
  + brotli-python                   1.1.0  py310hc6cd4ac_0     conda-forge     Cached
  + bzip2                           1.0.8  h7f98852_4          conda-forge     Cached
  + c-ares                         1.19.1  hd590300_0          conda-forge     Cached
  + ca-certificates             2023.7.22  hbcca054_0          conda-forge     Cached
  + certifi                     2023.7.22  pyhd8ed1ab_0        conda-forge     Cached
  + cffi                           1.15.1  py310h255011f_3     conda-forge     Cached
  + charset-normalizer              3.2.0  pyhd8ed1ab_0        conda-forge     Cached
  + colorama                        0.4.6  pyhd8ed1ab_0        conda-forge     Cached
  + conda                          23.3.1  py310hff52083_0     conda-forge     Cached
  + conda-libmamba-solver          23.3.0  pyhd8ed1ab_0        conda-forge     Cached
  + conda-package-handling          2.2.0  pyh38be061_0        conda-forge     Cached
  + conda-package-streaming         0.9.0  pyhd8ed1ab_0        conda-forge     Cached
  + cryptography                   41.0.3  py310h75e40e8_0     conda-forge     Cached
  + fmt                             9.1.0  h924138e_0          conda-forge     Cached
  + icu                              73.2  h59595ed_0          conda-forge     Cached
  + idna                              3.4  pyhd8ed1ab_0        conda-forge     Cached
  + jsonpatch                        1.32  pyhd8ed1ab_0        conda-forge     Cached
  + jsonpointer                       2.0  py_0                conda-forge     Cached
  + keyutils                        1.6.1  h166bdaf_0          conda-forge     Cached
  + krb5                           1.21.2  h659d440_0          conda-forge     Cached
  + ld_impl_linux-64                 2.40  h41732ed_0          conda-forge     Cached
  + libarchive                      3.6.2  h039dbb9_1          conda-forge     Cached
  + libcurl                         8.2.1  hca28451_0          conda-forge     Cached
  + libedit                  3.1.20191231  he28a2e2_2          conda-forge     Cached
  + libev                            4.33  h516909a_1          conda-forge     Cached
  + libffi                          3.4.2  h7f98852_5          conda-forge     Cached
  + libgcc-ng                      13.1.0  he5830b7_0          conda-forge     Cached
  + libgomp                        13.1.0  he5830b7_0          conda-forge     Cached
  + libiconv                         1.17  h166bdaf_0          conda-forge     Cached
  + libmamba                        1.4.2  hcea66bb_0          conda-forge     Cached
  + libmambapy                      1.4.2  py310h1428755_0     conda-forge     Cached
  + libnghttp2                     1.52.0  h61bc06f_0          conda-forge     Cached
  + libnsl                          2.0.0  h7f98852_0          conda-forge     Cached
  + libsolv                        0.7.24  hfc55251_3          conda-forge     Cached
  + libsqlite                      3.43.0  h2797004_0          conda-forge     Cached
  + libssh2                        1.11.0  h0841786_0          conda-forge     Cached
  + libstdcxx-ng                   13.1.0  hfd8a6a1_0          conda-forge     Cached
  + libuuid                        2.38.1  h0b41bf4_0          conda-forge     Cached
  + libxml2                        2.11.5  h232c23b_1          conda-forge     Cached
  + libzlib                        1.2.13  hd590300_5          conda-forge     Cached
  + lz4-c                           1.9.4  hcb278e6_0          conda-forge     Cached
  + lzo                              2.10  h516909a_1000       conda-forge     Cached
  + mamba                           1.4.2  py310h51d5547_0     conda-forge     Cached
  + ncurses                           6.4  hcb278e6_0          conda-forge     Cached
  + openssl                         3.1.2  hd590300_0          conda-forge     Cached
  + packaging                        23.1  pyhd8ed1ab_0        conda-forge     Cached
  + pip                            23.2.1  pyhd8ed1ab_0        conda-forge     Cached
  + pluggy                          1.3.0  pyhd8ed1ab_0        conda-forge     Cached
  + pybind11-abi                        4  hd8ed1ab_3          conda-forge     Cached
  + pycosat                         0.6.4  py310h5764c6d_1     conda-forge     Cached
  + pycparser                        2.21  pyhd8ed1ab_0        conda-forge     Cached
  + pyopenssl                      23.2.0  pyhd8ed1ab_1        conda-forge     Cached
  + pysocks                         1.7.1  pyha2e5f31_6        conda-forge     Cached
  + python                        3.10.12  hd12c33a_0_cpython  conda-forge     Cached
  + python_abi                       3.10  3_cp310             conda-forge     Cached
  + readline                          8.2  h8228510_1          conda-forge     Cached
  + reproc                         14.2.4  h0b41bf4_0          conda-forge     Cached
  + reproc-cpp                     14.2.4  hcb278e6_0          conda-forge     Cached
  + requests                       2.31.0  pyhd8ed1ab_0        conda-forge     Cached
  + ruamel.yaml                   0.17.32  py310h2372a71_0     conda-forge     Cached
  + ruamel.yaml.clib                0.2.7  py310h1fa729e_1     conda-forge     Cached
  + setuptools                     68.1.2  pyhd8ed1ab_0        conda-forge     Cached
  + tk                             8.6.12  h27826a3_0          conda-forge     Cached
  + toolz                          0.12.0  pyhd8ed1ab_0        conda-forge     Cached
  + tqdm                           4.66.1  pyhd8ed1ab_0        conda-forge     Cached
  + tzdata                          2023c  h71feb2d_0          conda-forge     Cached
  + urllib3                         2.0.4  pyhd8ed1ab_0        conda-forge     Cached
  + wheel                          0.41.2  pyhd8ed1ab_0        conda-forge     Cached
  + xz                              5.2.6  h166bdaf_0          conda-forge     Cached
  + yaml-cpp                        0.7.0  h27087fc_2          conda-forge     Cached
  + zstandard                      0.19.0  py310h5764c6d_0     conda-forge     Cached
  + zstd                            1.5.5  hfc55251_0          conda-forge     Cached

  Summary:

  Install: 75 packages

  Total download: 0 B

---------------------------------------------------------------------------------------



Transaction starting
Linking _libgcc_mutex-0.1-conda_forge
Linking ca-certificates-2023.7.22-hbcca054_0
Linking ld_impl_linux-64-2.40-h41732ed_0
Linking libstdcxx-ng-13.1.0-hfd8a6a1_0
Linking pybind11-abi-4-hd8ed1ab_3
Linking python_abi-3.10-3_cp310
Linking tzdata-2023c-h71feb2d_0
Linking libgomp-13.1.0-he5830b7_0
Linking _openmp_mutex-4.5-2_gnu
Linking libgcc-ng-13.1.0-he5830b7_0
Linking bzip2-1.0.8-h7f98852_4
Linking c-ares-1.19.1-hd590300_0
Linking fmt-9.1.0-h924138e_0
Linking icu-73.2-h59595ed_0
Linking keyutils-1.6.1-h166bdaf_0
Linking libev-4.33-h516909a_1
Linking libffi-3.4.2-h7f98852_5
Linking libiconv-1.17-h166bdaf_0
Linking libnsl-2.0.0-h7f98852_0
Linking libuuid-2.38.1-h0b41bf4_0
Linking libzlib-1.2.13-hd590300_5
Linking lz4-c-1.9.4-hcb278e6_0
Linking lzo-2.10-h516909a_1000
Linking ncurses-6.4-hcb278e6_0
Linking openssl-3.1.2-hd590300_0
Linking reproc-14.2.4-h0b41bf4_0
Linking xz-5.2.6-h166bdaf_0
Linking yaml-cpp-0.7.0-h27087fc_2
Linking libedit-3.1.20191231-he28a2e2_2
Linking libnghttp2-1.52.0-h61bc06f_0
Linking libsolv-0.7.24-hfc55251_3
Linking libsqlite-3.43.0-h2797004_0
Linking libssh2-1.11.0-h0841786_0
Linking libxml2-2.11.5-h232c23b_1
Linking readline-8.2-h8228510_1
Linking reproc-cpp-14.2.4-hcb278e6_0
Linking tk-8.6.12-h27826a3_0
Linking zstd-1.5.5-hfc55251_0
Linking krb5-1.21.2-h659d440_0
Linking libarchive-3.6.2-h039dbb9_1
Linking python-3.10.12-hd12c33a_0_cpython
Linking boltons-23.0.0-pyhd8ed1ab_0
Linking brotli-python-1.1.0-py310hc6cd4ac_0
Linking certifi-2023.7.22-pyhd8ed1ab_0
Linking charset-normalizer-3.2.0-pyhd8ed1ab_0
Linking colorama-0.4.6-pyhd8ed1ab_0
Linking idna-3.4-pyhd8ed1ab_0
Linking jsonpointer-2.0-py_0
Linking libcurl-8.2.1-hca28451_0
Linking packaging-23.1-pyhd8ed1ab_0
Linking pluggy-1.3.0-pyhd8ed1ab_0
Linking pycosat-0.6.4-py310h5764c6d_1
Linking pycparser-2.21-pyhd8ed1ab_0
Linking pysocks-1.7.1-pyha2e5f31_6
Linking ruamel.yaml.clib-0.2.7-py310h1fa729e_1
Linking setuptools-68.1.2-pyhd8ed1ab_0
Linking toolz-0.12.0-pyhd8ed1ab_0
Linking wheel-0.41.2-pyhd8ed1ab_0
Linking cffi-1.15.1-py310h255011f_3
Linking jsonpatch-1.32-pyhd8ed1ab_0
Linking libmamba-1.4.2-hcea66bb_0
Linking pip-23.2.1-pyhd8ed1ab_0
Linking ruamel.yaml-0.17.32-py310h2372a71_0
Linking tqdm-4.66.1-pyhd8ed1ab_0
Linking urllib3-2.0.4-pyhd8ed1ab_0
Linking cryptography-41.0.3-py310h75e40e8_0
Linking libmambapy-1.4.2-py310h1428755_0
Linking requests-2.31.0-pyhd8ed1ab_0
Linking zstandard-0.19.0-py310h5764c6d_0
Linking conda-package-streaming-0.9.0-pyhd8ed1ab_0
Linking pyopenssl-23.2.0-pyhd8ed1ab_1
Linking conda-package-handling-2.2.0-pyh38be061_0
Linking conda-23.3.1-py310hff52083_0
Linking conda-libmamba-solver-23.3.0-pyhd8ed1ab_0
Linking mamba-1.4.2-py310h51d5547_0
Transaction finished
installation finished.
Do you wish the installer to initialize Mambaforge
by running conda init? [yes|no]
[no] >>> yes
no change     /home/raul/mambaforge/condabin/conda
no change     /home/raul/mambaforge/bin/conda
no change     /home/raul/mambaforge/bin/conda-env
no change     /home/raul/mambaforge/bin/activate
no change     /home/raul/mambaforge/bin/deactivate
no change     /home/raul/mambaforge/etc/profile.d/conda.sh
no change     /home/raul/mambaforge/etc/fish/conf.d/conda.fish
no change     /home/raul/mambaforge/shell/condabin/Conda.psm1
no change     /home/raul/mambaforge/shell/condabin/conda-hook.ps1
no change     /home/raul/mambaforge/lib/python3.10/site-packages/xontrib/conda.xsh
no change     /home/raul/mambaforge/etc/profile.d/conda.csh
modified      /home/raul/.bashrc

==> For changes to take effect, close and re-open your current shell. <==


                  __    __    __    __
                 /  \  /  \  /  \  /  \
                /    \/    \/    \/    \
¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦/  /¦¦/  /¦¦/  /¦¦/  /¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦
              /  / \   / \   / \   / \  \____
             /  /   \_/   \_/   \_/   \    o \__,
            / _/                       \_____/  `
            |/
        ¦¦¦+   ¦¦¦+ ¦¦¦¦¦+ ¦¦¦+   ¦¦¦+¦¦¦¦¦¦+  ¦¦¦¦¦+
        ¦¦¦¦+ ¦¦¦¦¦¦¦+--¦¦+¦¦¦¦+ ¦¦¦¦¦¦¦+--¦¦+¦¦+--¦¦+
        ¦¦+¦¦¦¦+¦¦¦¦¦¦¦¦¦¦¦¦¦+¦¦¦¦+¦¦¦¦¦¦¦¦¦++¦¦¦¦¦¦¦¦
        ¦¦¦+¦¦++¦¦¦¦¦+--¦¦¦¦¦¦+¦¦++¦¦¦¦¦+--¦¦+¦¦+--¦¦¦
        ¦¦¦ +-+ ¦¦¦¦¦¦  ¦¦¦¦¦¦ +-+ ¦¦¦¦¦¦¦¦¦++¦¦¦  ¦¦¦
        +-+     +-++-+  +-++-+     +-++-----+ +-+  +-+

        mamba (1.4.2) supported by @QuantStack

        GitHub:  https://github.com/mamba-org/mamba
        Twitter: https://twitter.com/QuantStack

¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦

no change     /home/raul/mambaforge/condabin/conda
no change     /home/raul/mambaforge/bin/conda
no change     /home/raul/mambaforge/bin/conda-env
no change     /home/raul/mambaforge/bin/activate
no change     /home/raul/mambaforge/bin/deactivate
no change     /home/raul/mambaforge/etc/profile.d/conda.sh
no change     /home/raul/mambaforge/etc/fish/conf.d/conda.fish
no change     /home/raul/mambaforge/shell/condabin/Conda.psm1
no change     /home/raul/mambaforge/shell/condabin/conda-hook.ps1
no change     /home/raul/mambaforge/lib/python3.10/site-packages/xontrib/conda.xsh
no change     /home/raul/mambaforge/etc/profile.d/conda.csh
no change     /home/raul/.bashrc
No action taken.
Added mamba to /home/raul/.bashrc

==> For changes to take effect, close and re-open your current shell. <==

If you'd prefer that conda's base environment not be activated on startup,
   set the auto_activate_base parameter to false:

conda config --set auto_activate_base false

Thank you for installing Mambaforge!
(base) raul@119cb66ee7b2:~$
(base) raul@119cb66ee7b2:~$
(base) raul@119cb66ee7b2:~$ mamba --help
-bash: mamba: command not found
(base) raul@119cb66ee7b2:~$ exit
logout
Connection to 192.168.150.119 closed.


 ? 19/09/2023 ? ? 10:03.56 ? ? /home/mobaxterm ? ssh raul@192.168.150.119 -p 49161
raul@192.168.150.119's password:
X11 forwarding request failed on channel 0
Welcome to Ubuntu 18.04.4 LTS (GNU/Linux 5.3.0-62-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

This system has been minimized by removing packages and content that are
not required on a system that users do not log into.

To restore this content, you can run the 'unminimize' command.
Last login: Tue Sep 19 09:57:59 2023 from 192.168.151.182
(base) raul@119cb66ee7b2:~$ mamba --help
usage: mamba [-h] [-V] command ...

conda is a tool for managing and deploying applications, environments and packages.

Options:

positional arguments:
  command
    clean             Remove unused packages and caches.
    compare           Compare packages between conda environments.
    config            Modify configuration values in .condarc. This is modeled after the git config command. Writes
                      user .condarc file (/home/raul/.condarc) by default. Use the --show-sources flag to display al
                      identified configuration locations on your computer.
    create            Create a new conda environment from a list of specified packages.
    info              Display information about current conda install.
    init              Initialize conda for shell interaction.
    install           Installs a list of packages into a specified conda environment.
    list              List installed packages in a conda environment.
    package           Low-level conda package utility. (EXPERIMENTAL)
    remove (uninstall)
                      Remove a list of packages from a specified conda environment. Use `--all` flag to remove all p
                      and the environment itself.
    rename            Renames an existing environment.
    run               Run an executable in a conda environment.
    search            Search for packages and display associated information.The input is a MatchSpec, a query langu
                      conda packages. See examples below.
    update (upgrade)  Updates conda packages to the latest compatible version.
    notices           Retrieves latest channel notifications.
    repoquery         Query repositories using mamba.

options:
  -h, --help          Show this help message and exit.
  -V, --version       Show the conda version number and exit.

conda commands available from other packages (legacy):
  env
(base) raul@119cb66ee7b2:~$ mamba search salmon

                  __    __    __    __
                 /  \  /  \  /  \  /  \
                /    \/    \/    \/    \
¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦/  /¦¦/  /¦¦/  /¦¦/  /¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦
              /  / \   / \   / \   / \  \____
             /  /   \_/   \_/   \_/   \    o \__,
            / _/                       \_____/  `
            |/
        ¦¦¦+   ¦¦¦+ ¦¦¦¦¦+ ¦¦¦+   ¦¦¦+¦¦¦¦¦¦+  ¦¦¦¦¦+
        ¦¦¦¦+ ¦¦¦¦¦¦¦+--¦¦+¦¦¦¦+ ¦¦¦¦¦¦¦+--¦¦+¦¦+--¦¦+
        ¦¦+¦¦¦¦+¦¦¦¦¦¦¦¦¦¦¦¦¦+¦¦¦¦+¦¦¦¦¦¦¦¦¦++¦¦¦¦¦¦¦¦
        ¦¦¦+¦¦++¦¦¦¦¦+--¦¦¦¦¦¦+¦¦++¦¦¦¦¦+--¦¦+¦¦+--¦¦¦
        ¦¦¦ +-+ ¦¦¦¦¦¦  ¦¦¦¦¦¦ +-+ ¦¦¦¦¦¦¦¦¦++¦¦¦  ¦¦¦
        +-+     +-++-+  +-++-+     +-++-----+ +-+  +-+

        mamba (1.4.2) supported by @QuantStack

        GitHub:  https://github.com/mamba-org/mamba
        Twitter: https://twitter.com/QuantStack

¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦

Loading channels: done
# Name                       Version           Build  Channel
salmon                         0.5.1               0  bioconda
salmon                         0.6.0               0  bioconda
salmon                         0.6.0               1  bioconda
salmon                         0.6.0     boost1.60_1  bioconda
salmon                         0.6.0     boost1.60_2  bioconda
salmon                         0.7.2     boost1.60_2  bioconda
salmon                         0.7.2     boost1.60_3  bioconda
salmon                         0.7.2     boost1.61_3  bioconda
salmon                         0.8.0     boost1.60_0  bioconda
salmon                         0.8.0     boost1.61_0  bioconda
salmon                         0.8.1               0  bioconda
salmon                         0.8.2               0  bioconda
salmon                         0.8.2               1  bioconda
salmon                         0.9.0               0  bioconda
salmon                         0.9.1               0  bioconda
salmon                         0.9.1               1  bioconda
salmon                        0.10.0               1  bioconda
salmon                        0.10.1               1  bioconda
salmon                        0.10.2               1  bioconda
salmon                        0.11.0      h445c947_0  bioconda
salmon                        0.11.1      h445c947_0  bioconda
salmon                        0.11.2      h445c947_0  bioconda
salmon                        0.11.3      h86b0361_1  bioconda
salmon                        0.11.3      h86b0361_2  bioconda
salmon                        0.12.0      h86b0361_1  bioconda
salmon                        0.13.0      h86b0361_1  bioconda
salmon                        0.13.0      h86b0361_2  bioconda
salmon                        0.13.1      h86b0361_0  bioconda
salmon                        0.14.0      h86b0361_0  bioconda
salmon                        0.14.0      h86b0361_1  bioconda
salmon                        0.14.1      h86b0361_0  bioconda
salmon                        0.14.1      h86b0361_1  bioconda
salmon                        0.14.1      ha0cc327_2  bioconda
salmon                        0.14.2      ha0cc327_0  bioconda
salmon                        0.14.2      hf69c8f4_1  bioconda
salmon                        0.15.0      hf69c8f4_0  bioconda
salmon                         1.0.0      hf69c8f4_0  bioconda
salmon                         1.1.0      hf69c8f4_0  bioconda
salmon                         1.2.0      hf69c8f4_0  bioconda
salmon                         1.2.1      hf69c8f4_0  bioconda
salmon                         1.3.0      hf69c8f4_0  bioconda
salmon                         1.4.0      h84f40af_1  bioconda
salmon                         1.4.0      hf69c8f4_0  bioconda
salmon                         1.5.0      h84f40af_0  bioconda
salmon                         1.5.1      h84f40af_0  bioconda
salmon                         1.5.2      h84f40af_0  bioconda
salmon                         1.6.0      h84f40af_0  bioconda
salmon                         1.7.0      h10bb6b4_1  bioconda
salmon                         1.7.0      h84f40af_0  bioconda
salmon                         1.8.0      h7e5ed60_0  bioconda
salmon                         1.8.0      h7e5ed60_1  bioconda
salmon                         1.9.0      h7e5ed60_0  bioconda
salmon                         1.9.0      h7e5ed60_1  bioconda
salmon                        1.10.0      h7e5ed60_0  bioconda
salmon                        1.10.1      h7e5ed60_0  bioconda
salmon                        1.10.1      h7e5ed60_1  bioconda
salmon                        1.10.1      hecfa306_2  bioconda
salmon                        1.10.2      hecfa306_0  bioconda
(base) raul@119cb66ee7b2:~$ mamba create -n salmon salmon=1.10.2

                  __    __    __    __
                 /  \  /  \  /  \  /  \
                /    \/    \/    \/    \
¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦/  /¦¦/  /¦¦/  /¦¦/  /¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦
              /  / \   / \   / \   / \  \____
             /  /   \_/   \_/   \_/   \    o \__,
            / _/                       \_____/  `
            |/
        ¦¦¦+   ¦¦¦+ ¦¦¦¦¦+ ¦¦¦+   ¦¦¦+¦¦¦¦¦¦+  ¦¦¦¦¦+
        ¦¦¦¦+ ¦¦¦¦¦¦¦+--¦¦+¦¦¦¦+ ¦¦¦¦¦¦¦+--¦¦+¦¦+--¦¦+
        ¦¦+¦¦¦¦+¦¦¦¦¦¦¦¦¦¦¦¦¦+¦¦¦¦+¦¦¦¦¦¦¦¦¦++¦¦¦¦¦¦¦¦
        ¦¦¦+¦¦++¦¦¦¦¦+--¦¦¦¦¦¦+¦¦++¦¦¦¦¦+--¦¦+¦¦+--¦¦¦
        ¦¦¦ +-+ ¦¦¦¦¦¦  ¦¦¦¦¦¦ +-+ ¦¦¦¦¦¦¦¦¦++¦¦¦  ¦¦¦
        +-+     +-++-+  +-++-+     +-++-----+ +-+  +-+

        mamba (1.4.2) supported by @QuantStack

        GitHub:  https://github.com/mamba-org/mamba
        Twitter: https://twitter.com/QuantStack

¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦¦


Looking for: ['salmon=1.10.2']

warning  libmamba Cache file "/home/raul/mambaforge/pkgs/cache/497deca9.json" was modified by another program
warning  libmamba Cache file "/home/raul/mambaforge/pkgs/cache/09cdf8bf.json" was modified by another program
warning  libmamba Cache file "/home/raul/mambaforge/pkgs/cache/ffeee55f.json" was modified by another program
warning  libmamba Cache file "/home/raul/mambaforge/pkgs/cache/2a957770.json" was modified by another program
warning  libmamba Cache file "/home/raul/mambaforge/pkgs/cache/47929eba.json" was modified by another program
warning  libmamba Cache file "/home/raul/mambaforge/pkgs/cache/3e39a7aa.json" was modified by another program
warning  libmamba Cache file "/home/raul/mambaforge/pkgs/cache/2ce54b42.json" was modified by another program
warning  libmamba Cache file "/home/raul/mambaforge/pkgs/cache/4ea078d6.json" was modified by another program
bioconda/noarch                                      4.7MB @   3.5MB/s  1.6s
pkgs/main/linux-64                                   6.1MB @   3.7MB/s  2.1s
bioconda/linux-64                                    5.1MB @   2.4MB/s  2.4s
pkgs/main/noarch                                   852.8kB @ 400.1kB/s  0.8s
pkgs/r/linux-64                                      1.4MB @ 551.6kB/s  0.5s
pkgs/r/noarch                                        1.3MB @ 433.8kB/s  1.7s
conda-forge/noarch                                  14.1MB @   3.7MB/s  4.8s
conda-forge/linux-64                                34.3MB @   4.0MB/s 11.5s
Transaction

  Prefix: /home/raul/mambaforge/envs/salmon

  Updating specs:

   - salmon=1.10.2


  Package           Version  Build        Channel                    Size
---------------------------------------------------------------------------
  Install:
---------------------------------------------------------------------------

  + _libgcc_mutex       0.1  conda_forge  conda-forge/linux-64     Cached
  + _openmp_mutex       4.5  2_gnu        conda-forge/linux-64     Cached
  + boost-cpp        1.78.0  h5adbc97_2   conda-forge/linux-64       16MB
  + bzip2             1.0.8  h7f98852_4   conda-forge/linux-64     Cached
  + icu                70.1  h27087fc_0   conda-forge/linux-64       14MB
  + libgcc-ng        13.2.0  h807b86a_1   conda-forge/linux-64      771kB
  + libgomp          13.2.0  h807b86a_1   conda-forge/linux-64      421kB
  + libhwloc          2.9.1  hd6dc26d_0   conda-forge/linux-64        3MB
  + libiconv           1.17  h166bdaf_0   conda-forge/linux-64     Cached
  + libjemalloc       5.3.0  hcb278e6_0   conda-forge/linux-64        2MB
  + libstdcxx-ng     13.2.0  h7e041cc_1   conda-forge/linux-64        4MB
  + libxml2          2.10.3  hca2bb57_4   conda-forge/linux-64      714kB
  + libzlib          1.2.13  hd590300_5   conda-forge/linux-64     Cached
  + salmon           1.10.2  hecfa306_0   bioconda/linux-64           6MB
  + tbb            2021.9.0  hf52228f_0   conda-forge/linux-64        2MB
  + xz                5.2.6  h166bdaf_0   conda-forge/linux-64     Cached
  + zstd              1.5.5  hfc55251_0   conda-forge/linux-64     Cached

  Summary:

  Install: 17 packages

  Total download: 48MB

---------------------------------------------------------------------------


Confirm changes: [Y/n] Y
libgomp                                            420.7kB @   1.4MB/s  0.3s
libstdcxx-ng                                         3.8MB @   9.5MB/s  0.4s
libxml2                                            713.9kB @   1.5MB/s  0.2s
tbb                                                  1.5MB @   2.8MB/s  0.1s
libhwloc                                             2.6MB @   3.9MB/s  0.2s
libgcc-ng                                          770.9kB @   1.2MB/s  0.7s
salmon                                               6.3MB @   6.7MB/s  0.4s
libjemalloc                                          1.6MB @   1.6MB/s  1.0s
boost-cpp                                           15.9MB @  14.9MB/s  0.4s
icu                                                 14.2MB @   9.7MB/s  1.5s

Downloading and Extracting Packages

Preparing transaction: done
Verifying transaction: done
Executing transaction: done

To activate this environment, use

     $ mamba activate salmon

To deactivate an active environment, use

     $ mamba deactivate

(base) raul@119cb66ee7b2:~$ mamba activate salmon
(salmon) raul@119cb66ee7b2:~$ salmon --version
salmon 1.10.2
(salmon) raul@119cb66ee7b2:~$ mamba deactivate
(base) raul@119cb66ee7b2:~$ vast-tools --help

VAST-TOOLS v2.5.1

Usage: vast-tools sub-commands [options]

[sub-commands]
        align           :       Align RNA-Seq reads to exon-exon junctions and quantify AS
        merge           :       Merge vast-tool outputs from multiple sub-samples
        combine         :       Combine two or more 'aligned' RNA-Seq samples into summary tables
        compare         :       Compare PSIs between samples and produces lists for GO analysis
        compare_expr    :       Compare Gene Expression (cRPKMs) between samples
        diff            :       Compare posterior distributions over PSI of two or more samples
        plot            :       Utility application to plot PSI scatterplots
        tidy            :       Simplifies and filters the PSI table for external analysis (e.g. in R)

[global options]
        -h,--help       :       Print this message
        -o,--output     :       Output directory (default vast_out;
                                    except for plot, which uses input file location)
        --legacy        :       Use old input/output styles
        --verbose       :       Print stderr


*** Questions & Bug Reports:
    - align, merge, combine, compare, tidy: Manuel Irimia (mirimia@gmail.com)
    - diff: Tim Sterne-Weiler (tim.sterne.weiler@utoronto.ca)
    - plot: Kevin Ha (k.ha@mail.utoronto.ca)

(base) raul@119cb66ee7b2:~$ matt --help

Matt v. 1.3.1

Usage: matt <command> ...

Commands:

*Import data / check table                             *Maths and statistics
  chk_nls:  check newlines in table                      col_calc:  apply calculations to columns
  chk_tab:  check format of table                        perm_test: test differences between groups
  get_pwm:  get PWM in Matt format                       row_calc:  apply calculations to rows
  get_sj:   get SANJUAN CEs output
  get_vast: get VAST-TOOLS output                      *Other
                                                         extr_scafids: extract scaffold ids
*Retrieve data from table                                get_kmers_from_pwm: get top-N kmers from PWM
  col_uniq:   unique values in columns                   mk_uniq:      make table unique wrt. rows
  conc:       concatenate columns                        perm_seqs:    randomly permute seqs
  get_colnms: extract column names                       prnt_tab:     print table nicely
  get_cols:   retrieve columns                           retr_geneids: retrieve gene IDs from GTF
  get_match:  find ID match                              retr_rnaseq:  retrieve RNAseq data from GEO
  get_ovl:    overlap of sets                            sort_tab:     sort table
  get_rows:   retrieve rows                              stratify:     stratify data in table
  rand_rows:  get random rows
                                                       *High-level analyses
*Manipulate table                                        cmpr_exons:   discriminate feature analysis
  add_cols:   add columns to table                       cmpr_features: feature comparison
  add_header: add column names                           cmpr_introns: discriminate feature analysis
  add_range:  add column with range of values            rna_maps:     generate motif RNA maps
  add_rows:   add rows at bottom                         rna_maps_cisbp: with all CISBP-RNA/k-mer motifs
  add_val:    add column with fixed value                test_cisbp_enrich: test CISBP motif enrichment
  chg_labs:   change labels
  def_cats:   define categories
  rm_cols:    removes columns from table
  rn_cols:    rename columns

*Retrieve sequences
  extr_seqs: extract sequences from table
  get_seqs:  get sequences from FASTA

*Analyze sequences
  cmpr_motif:      plot motif / PWM comparison
  get_efeatures:   get exon features
  get_gcc:         determines GC content
  get_ifeatures:   get intron features
  get_pwm_hits:    get hits of motif PWM
  get_pwm_prof:    get profiles of PWM hits
  get_regexp_hits: get REGEXP hits
  get_regexp_prof: get profiles of REGEXP hits
  get_seql:        determine sequence length
  get_sss:         get SS strengths
  plot_motif:      plot motif / PWM
  test_pwm_enrich: test PWM motif enrichment
  test_regexp_enrich: test REGEXP enrichment

Attention: Tables processed by Matt must contain a header with column names and must not contain " characters
           with exception of regular expressions. All other " characters will be ignored and removed. When using
           MS Excel for table generation, please save tables in format Windows Text. Matt recognizes Windows newline
           but not DOS nor old-style MacOS newlines (CR or \r only). Use command chk_nls to see and check newlines i


(base) raul@119cb66ee7b2:~$ sra
sra-pileup             sra-search.3           sra-sort-cg.3.0.7      sra-stat.3.0.7         sratools.3.0.7
sra-pileup-orig.3.0.7  sra-search.3.0.7       sra-sort.3             srapath
sra-pileup.3           sra-sort               sra-sort.3.0.7         srapath-orig.3.0.7
sra-pileup.3.0.7       sra-sort-cg            sra-stat               srapath.3
sra-search             sra-sort-cg.3          sra-stat.3             srapath.3.0.7
(base) raul@119cb66ee7b2:~$ sra
sra-pileup             sra-search.3           sra-sort-cg.3.0.7      sra-stat.3.0.7         sratools.3.0.7
sra-pileup-orig.3.0.7  sra-search.3.0.7       sra-sort.3             srapath
sra-pileup.3           sra-sort               sra-sort.3.0.7         srapath-orig.3.0.7
sra-pileup.3.0.7       sra-sort-cg            sra-stat               srapath.3
sra-search             sra-sort-cg.3          sra-stat.3             srapath.3.0.7
(base) raul@119cb66ee7b2:~$ fastq
fastq-dump             fastq-dump.3           fastq-load             fastq-load.3.0.7
fastq-dump-orig.3.0.7  fastq-dump.3.0.7       fastq-load.3           fastqc
(base) raul@119cb66ee7b2:~$ fastq
fastq-dump             fastq-dump.3           fastq-load             fastq-load.3.0.7
fastq-dump-orig.3.0.7  fastq-dump.3.0.7       fastq-load.3           fastqc
(base) raul@119cb66ee7b2:~$ fastq-dump --help

Usage:
  fastq-dump [options] <path> [<path>...]
  fastq-dump [options] <accession>

INPUT
  -A|--accession <accession>       Replaces accession derived from <path> in
                                   filename(s) and deflines (only for single
                                   table dump)
  --table <table-name>             Table name within cSRA object, default is
                                   "SEQUENCE"

PROCESSING

Read Splitting                     Sequence data may be used in raw form or
                                     split into individual reads
  --split-spot                     Split spots into individual reads

Full Spot Filters                  Applied to the full spot independently
                                     of --split-spot
  -N|--minSpotId <rowid>           Minimum spot id
  -X|--maxSpotId <rowid>           Maximum spot id
  --spot-groups <[list]>           Filter by SPOT_GROUP (member): name[,...]
  -W|--clip                        Remove adapter sequences from reads

Common Filters                     Applied to spots when --split-spot is not
                                     set, otherwise - to individual reads
  -M|--minReadLen <len>            Filter by sequence length >= <len>
  -R|--read-filter <[filter]>      Split into files by READ_FILTER value
                                   optionally filter by value:
                                   pass|reject|criteria|redacted
  -E|--qual-filter                 Filter used in early 1000 Genomes data: no
                                   sequences starting or ending with >= 10N
  --qual-filter-1                  Filter used in current 1000 Genomes data

Filters based on alignments        Filters are active when alignment
                                     data are present
  --aligned                        Dump only aligned sequences
  --unaligned                      Dump only unaligned sequences
  --aligned-region <name[:from-to]>  Filter by position on genome. Name can
                                   either be accession.version (ex:
                                   NC_000001.10) or file specific name (ex:
                                   "chr1" or "1"). "from" and "to" are 1-based
                                   coordinates
  --matepair-distance <from-to|unknown>  Filter by distance between matepairs.
                                   Use "unknown" to find matepairs split
                                   between the references. Use from-to to limit
                                   matepair distance on the same reference

Filters for individual reads       Applied only with --split-spot set
  --skip-technical                 Dump only biological reads

OUTPUT
  -O|--outdir <path>               Output directory, default is working
                                   directory '.' )
  -Z|--stdout                      Output to stdout, all split data become
                                   joined into single stream
  --gzip                           Compress output using gzip: deprecated, not
                                   recommended
  --bzip2                          Compress output using bzip2: deprecated,
                                   not recommended

Multiple File Options              Setting these options will produce more
                                     than 1 file, each of which will be suffixed
                                     according to splitting criteria.
  --split-files                    Write reads into separate files. Read
                                   number will be suffixed to the file name.
                                   NOTE! The `--split-3` option is recommended.
                                   In cases where not all spots have the same
                                   number of reads, this option will produce
                                   files that WILL CAUSE ERRORS in most programs
                                   which process split pair fastq files.
  --split-3                        3-way splitting for mate-pairs. For each
                                   spot, if there are two biological reads
                                   satisfying filter conditions, the first is
                                   placed in the `*_1.fastq` file, and the
                                   second is placed in the `*_2.fastq` file. If
                                   there is only one biological read
                                   satisfying the filter conditions, it is
                                   placed in the `*.fastq` file.All other
                                   reads in the spot are ignored.
  -G|--spot-group                  Split into files by SPOT_GROUP (member name)
  -R|--read-filter <[filter]>      Split into files by READ_FILTER value
                                   optionally filter by value:
                                   pass|reject|criteria|redacted
  -T|--group-in-dirs               Split into subdirectories instead of files
  -K|--keep-empty-files            Do not delete empty files

FORMATTING

Sequence
  -C|--dumpcs <[cskey]>            Formats sequence using color space (default
                                   for SOLiD),"cskey" may be specified for
                                   translation
  -B|--dumpbase                    Formats sequence using base space (default
                                   for other than SOLiD).

Quality
  -Q|--offset <integer>            Offset to use for quality conversion,
                                   default is 33
  --fasta <[line width]>           FASTA only, no qualities, optional line
                                   wrap width (set to zero for no wrapping)
  --suppress-qual-for-cskey        suppress quality-value for cskey

Defline
  -F|--origfmt                     Defline contains only original sequence name
  -I|--readids                     Append read id after spot id as
                                   'accession.spot.readid' on defline
  --helicos                        Helicos style defline
  --defline-seq <fmt>              Defline format specification for sequence.
  --defline-qual <fmt>             Defline format specification for quality.
                                   <fmt> is string of characters and/or
                                   variables. The variables can be one of: $ac
                                   - accession, $si spot id, $sn spot
                                   name, $sg spot group (barcode), $sl spot
                                   length in bases, $ri read number, $rn
                                   read name, $rl read length in bases. '[]'
                                   could be used for an optional output: if
                                   all vars in [] yield empty values whole
                                   group is not printed. Empty value is empty
                                   string or for numeric variables. Ex:
                                   @$sn[_$rn]/$ri '_$rn' is omitted if name
                                   is empty

OTHER:
  --ngc <path>                     <path> to ngc file
  --disable-multithreading         disable multithreading
  -h|--help                        Output brief explanation of program usage
  -V|--version                     Display the version of the program
  -L|--log-level <level>           Logging level as number or enum string One
                                   of (fatal|sys|int|err|warn|info) or (0-5)
                                   Current/default is warn
  -v|--verbose                     Increase the verbosity level of the program
                                   Use multiple times for more verbosity
  --ncbi_error_report              Control program execution environment
                                   report generation (if implemented). One of
                                   (never|error|always). Default is error
  --legacy-report                  use legacy style 'Written spots' for tool

fastq-dump : 3.0.7

(base) raul@119cb66ee7b2:~$
(base) raul@119cb66ee7b2:~$
(base) raul@119cb66ee7b2:~$
(base) raul@119cb66ee7b2:~$
(base) raul@119cb66ee7b2:~$
(base) raul@119cb66ee7b2:~$ mamba activate salmon
(salmon) raul@119cb66ee7b2:~$ salmon --help
salmon v1.10.2

Usage:  salmon -h|--help or
        salmon -v|--version or
        salmon -c|--cite or
        salmon [--no-version-check] <COMMAND> [-h | options]

Commands:
     index      : create a salmon index
     quant      : quantify a sample
     alevin     : single cell analysis
     swim       : perform super-secret operation
     quantmerge : merge multiple quantifications into a single file
(salmon) raul@119cb66ee7b2:~$ --help
-bash: --help: command not found
(salmon) raul@119cb66ee7b2:~$ salmon -h
salmon v1.10.2

Usage:  salmon -h|--help or
        salmon -v|--version or
        salmon -c|--cite or
        salmon [--no-version-check] <COMMAND> [-h | options]

Commands:
     index      : create a salmon index
     quant      : quantify a sample
     alevin     : single cell analysis
     swim       : perform super-secret operation
     quantmerge : merge multiple quantifications into a single file
(salmon) raul@119cb66ee7b2:~$ salmon quant --help
Version Server Response: Not Found
    salmon v1.10.2
    ===============

    salmon quant has two modes --- one quantifies expression using raw reads
    and the other makes use of already-aligned reads (in BAM/SAM format).
    Which algorithm is used depends on the arguments passed to salmon quant.
    If you provide salmon with alignments '-a [ --alignments ]' then the
    alignment-based algorithm will be used, otherwise the algorithm for
    quantifying from raw reads will be used.

    to view the help for salmon's selective-alignment-based mode, use the command

    salmon quant --help-reads

    To view the help for salmon's alignment-based mode, use the command

    salmon quant --help-alignment


(salmon) raul@119cb66ee7b2:~$ salmon quant --help-reads
Version Server Response: Not Found

Quant
==========
Perform dual-phase, selective-alignment-based estimation of
transcript abundance from RNA-seq reads

salmon quant options:


mapping input options:
  -l [ --libType ] arg                  Format string describing the library
                                        type
  -i [ --index ] arg                    salmon index
  -r [ --unmatedReads ] arg             List of files containing unmated reads
                                        of (e.g. single-end reads)
  -1 [ --mates1 ] arg                   File containing the #1 mates
  -2 [ --mates2 ] arg                   File containing the #2 mates


basic options:
  -v [ --version ]                      print version string
  -h [ --help ]                         produce help message
  -o [ --output ] arg                   Output quantification directory.
  --seqBias                             Perform sequence-specific bias
                                        correction.
  --gcBias                              [beta for single-end reads] Perform
                                        fragment GC bias correction.
  --posBias                             Perform positional bias correction.
  -p [ --threads ] arg (=64)            The number of threads to use
                                        concurrently.
  --incompatPrior arg (=0)              This option sets the prior probability
                                        that an alignment that disagrees with
                                        the specified library type (--libType)
                                        results from the true fragment origin.
                                        Setting this to 0 specifies that
                                        alignments that disagree with the
                                        library type should be "impossible",
                                        while setting it to 1 says that
                                        alignments that disagree with the
                                        library type are no less likely than
                                        those that do
  -g [ --geneMap ] arg                  File containing a mapping of
                                        transcripts to genes.  If this file is
                                        provided salmon will output both
                                        quant.sf and quant.genes.sf files,
                                        where the latter contains aggregated
                                        gene-level abundance estimates.  The
                                        transcript to gene mapping should be
                                        provided as either a GTF file, or a in
                                        a simple tab-delimited format where
                                        each line contains the name of a
                                        transcript and the gene to which it
                                        belongs separated by a tab.  The
                                        extension of the file is used to
                                        determine how the file should be
                                        parsed.  Files ending in '.gtf', '.gff'
                                        or '.gff3' are assumed to be in GTF
                                        format; files with any other extension
                                        are assumed to be in the simple format.
                                        In GTF / GFF format, the
                                        "transcript_id" is assumed to contain
                                        the transcript identifier and the
                                        "gene_id" is assumed to contain the
                                        corresponding gene identifier.
  --auxTargetFile arg                   A file containing a list of "auxiliary"
                                        targets.  These are valid targets
                                        (i.e., not decoys) to which fragments
                                        are allowed to map and be assigned, and
                                        which will be quantified, but for which
                                        auxiliary models like sequence-specific
                                        and fragment-GC bias correction should
                                        not be applied.
  --meta                                If you're using Salmon on a metagenomic
                                        dataset, consider setting this flag to
                                        disable parts of the abundance
                                        estimation model that make less sense
                                        for metagenomic data.


options specific to mapping mode:
  --discardOrphansQuasi                 [selective-alignment mode only] :
                                        Discard orphan mappings in
                                        selective-alignment mode.  If this flag
                                        is passed then only paired mappings
                                        will be considered toward
                                        quantification estimates.  The default
                                        behavior is to consider orphan mappings
                                        if no valid paired mappings exist.
                                        This flag is independent of the option
                                        to write the orphaned mappings to file
                                        (--writeOrphanLinks).
  --validateMappings                    [*deprecated* (no effect;
                                        selective-alignment is the default)]
  --consensusSlack arg (=0.349999994)   [selective-alignment mode only] : The
                                        amount of slack allowed in the
                                        selective-alignment filtering
                                        mechanism.  If this is set to a
                                        fraction, X, greater than 0 (and in
                                        [0,1)), then uniMEM chains with scores
                                        below (100 * X)% of the best chain
                                        score for a read, and read pairs with a
                                        sum of chain scores below (100 * X)% of
                                        the best chain score for a read pair
                                        will be discounted as a mapping
                                        candidates.  The default value of this
                                        option is 0.35.
  --preMergeChainSubThresh arg (=0.75)  [selective-alignment mode only] : The
                                        threshold of sub-optimal chains,
                                        compared to the best chain on a given
                                        target, that will be retained and
                                        passed to the next phase of mapping.
                                        Specifically, if the best chain for a
                                        read (or read-end in paired-end mode)
                                        to target t has score X_t, then all
                                        chains for this read with score >= X_t
                                        * preMergeChainSubThresh will be
                                        retained and passed to subsequent
                                        mapping phases.  This value must be in
                                        the range [0, 1].
  --postMergeChainSubThresh arg (=0.90000000000000002)
                                        [selective-alignment mode only] : The
                                        threshold of sub-optimal chain pairs,
                                        compared to the best chain pair on a
                                        given target, that will be retained and
                                        passed to the next phase of mapping.
                                        This is different than
                                        preMergeChainSubThresh, because this is
                                        applied to pairs of chains (from the
                                        ends of paired-end reads) after merging
                                        (i.e. after checking concordancy
                                        constraints etc.).  Specifically, if
                                        the best chain pair to target t has
                                        score X_t, then all chain pairs for
                                        this read pair with score >= X_t *
                                        postMergeChainSubThresh will be
                                        retained and passed to subsequent
                                        mapping phases.  This value must be in
                                        the range [0, 1]. Note: This option is
                                        only meaningful for paired-end
                                        libraries, and is ignored for
                                        single-end libraries.
  --orphanChainSubThresh arg (=0.94999999999999996)
                                        [selective-alignment mode only] : This
                                        threshold sets a global sub-optimality
                                        threshold for chains corresponding to
                                        orphan mappings.  That is, if the
                                        merging procedure results in no
                                        concordant mappings then only orphan
                                        mappings with a chain score >=
                                        orphanChainSubThresh * bestChainScore
                                        will be retained and passed to
                                        subsequent mapping phases.  This value
                                        must be in the range [0, 1]. Note: This
                                        option is only meaningful for
                                        paired-end libraries, and is ignored
                                        for single-end libraries.
  --scoreExp arg (=1)                   [selective-alignment mode only] : The
                                        factor by which sub-optimal alignment
                                        scores are downweighted to produce a
                                        probability.  If the best alignment
                                        score for the current read is S, and
                                        the score for a particular alignment is
                                        w, then the probability will be
                                        computed porportional to exp( -
                                        scoreExp * (S-w) ).
  --minScoreFraction arg                [selective-alignment mode only] : The
                                        fraction of the optimal possible
                                        alignment score that a mapping must
                                        achieve in order to be considered
                                        "valid" --- should be in (0,1].
                                        Salmon Default 0.65 and Alevin Default
                                        0.87
  --mismatchSeedSkip arg (=3)           [selective-alignment mode only] : After
                                        a k-mer hit is extended to a uni-MEM,
                                        the uni-MEM extension can terminate for
                                        one of 3 reasons; the end of the read,
                                        the end of the unitig, or a mismatch.
                                        If the extension ends because of a
                                        mismatch, this is likely the result of
                                        a sequencing error.  To avoid looking
                                        up many k-mers that will likely fail to
                                        be located in the index, the search
                                        procedure skips by a factor of
                                        mismatchSeedSkip until it either (1)
                                        finds another match or (2) is k-bases
                                        past the mismatch position. This value
                                        controls that skip length.  A smaller
                                        value can increase sensitivity, while a
                                        larger value can speed up seeding.
  --disableChainingHeuristic            [selective-alignment mode only] : By
                                        default, the heuristic of (Li 2018) is
                                        implemented, which terminates the
                                        chaining DP once a given number of
                                        valid backpointers are found.  This
                                        speeds up the seed (MEM) chaining step,
                                        but may result in sub-optimal chains in
                                        complex situations (e.g. sequences with
                                        many repeats and overlapping repeats).
                                        Passing this flag will disable the
                                        chaining heuristic, and perform the
                                        full chaining dynamic program,
                                        guaranteeing the optimal chain is found
                                        in this step.
  --decoyThreshold arg (=1)             [selective-alignment mode only] : For
                                        an alignemnt to an annotated transcript
                                        to be considered invalid, it must have
                                        an alignment score < (decoyThreshold *
                                        bestDecoyScore).  A value of 1.0 means
                                        that any alignment strictly worse than
                                        the best decoy alignment will be
                                        discarded.  A smaller value will allow
                                        reads to be allocated to transcripts
                                        even if they strictly align better to
                                        the decoy sequence.
  --ma arg (=2)                         [selective-alignment mode only] : The
                                        value given to a match between read and
                                        reference nucleotides in an alignment.
  --mp arg (=-4)                        [selective-alignment mode only] : The
                                        value given to a mis-match between read
                                        and reference nucleotides in an
                                        alignment.
  --go arg (=6)                         [selective-alignment mode only] : The
                                        value given to a gap opening in an
                                        alignment.
  --ge arg (=2)                         [selective-alignment mode only] : The
                                        value given to a gap extension in an
                                        alignment.
  --bandwidth arg (=15)                 [selective-alignment mode only] : The
                                        value used for the bandwidth passed to
                                        ksw2.  A smaller bandwidth can make the
                                        alignment verification run more
                                        quickly, but could possibly miss valid
                                        alignments.
  --allowDovetail                       [selective-alignment mode only] : allow
                                        dovetailing mappings.
  --recoverOrphans                      [selective-alignment mode only] :
                                        Attempt to recover the mates of
                                        orphaned reads. This uses edlib for
                                        orphan recovery, and so introduces some
                                        computational overhead, but it can
                                        improve sensitivity.
  --mimicBT2                            [selective-alignment mode only] : Set
                                        flags to mimic parameters similar to
                                        Bowtie2 with --no-discordant and
                                        --no-mixed flags.  This increases
                                        disallows dovetailing reads, and
                                        discards orphans. Note, this does not
                                        impose the very strict parameters
                                        assumed by RSEM+Bowtie2, like gapless
                                        alignments.  For that behavior, use the
                                        --mimiStrictBT2 flag below.
  --mimicStrictBT2                      [selective-alignment mode only] : Set
                                        flags to mimic the very strict
                                        parameters used by RSEM+Bowtie2.  This
                                        increases --minScoreFraction to 0.8,
                                        disallows dovetailing reads, discards
                                        orphans, and disallows gaps in
                                        alignments.
  --softclip                            [selective-alignment mode only
                                        (experimental)] : Allos soft-clipping
                                        of reads during selective-alignment. If
                                        this option is provided, then regions
                                        at the beginning or end of the read can
                                        be withheld from alignment without any
                                        effect on the resulting score (i.e.
                                        neither adding nor removing from the
                                        score).  This will drastically reduce
                                        the penalty if there are mismatches at
                                        the beginning or end of the read due to
                                        e.g. low-quality bases or adapters.
                                        NOTE: Even with soft-clipping enabled,
                                        the read must still achieve a score of
                                        at least minScoreFraction * maximum
                                        achievable score, where the maximum
                                        achievable score is computed based on
                                        the full (un-clipped) read length.
  --softclipOverhangs                   [selective-alignment mode only] : Allow
                                        soft-clipping of reads that overhang
                                        the beginning or ends of the
                                        transcript.  In this case, the
                                        overhaning section of the read will
                                        simply be unaligned, and will not
                                        contribute or detract from the
                                        alignment score.  The default policy is
                                        to force an end-to-end alignment of the
                                        entire read, so that overhanings will
                                        result in some deletion of nucleotides
                                        from the read.
  --fullLengthAlignment                 [selective-alignment mode only] :
                                        Perform selective alignment over the
                                        full length of the read, beginning from
                                        the (approximate) initial mapping
                                        location and using extension alignment.
                                          This is in contrast with the default
                                        behavior which is to only perform
                                        alignment between the MEMs in the
                                        optimal chain (and before the first and
                                        after the last MEM if applicable).  The
                                        default strategy forces the MEMs to
                                        belong to the alignment, but has the
                                        benefit that it can discover indels
                                        prior to the first hit shared between
                                        the read and reference. Except in very
                                        rare circumstances, the default mode
                                        should be more accurate.
  --hardFilter                          [selective-alignemnt mode only] :
                                        Instead of weighting mappings by their
                                        alignment score, this flag will discard
                                        any mappings with sub-optimal alignment
                                        score.  The default option of
                                        soft-filtering (i.e. weighting mappings
                                        by their alignment score) usually
                                        yields slightly more accurate abundance
                                        estimates but this flag may be
                                        desirable if you want more accurate
                                        'naive' equivalence classes, rather
                                        than range factorized equivalence
                                        classes.
  --minAlnProb arg (=1.0000000000000001e-05)
                                        [selective-alignment mode only] : Any
                                        mapping whose alignment probability (as
                                        computed by P(aln) = exp(-scoreExp *
                                        difference from best mapping score) is
                                        less than minAlnProb will not be
                                        considered as a valid alignment for
                                        this read.  The goal of this flag is to
                                        remove very low probability alignments
                                        that are unlikely to have any
                                        non-trivial effect on the final
                                        quantifications.  Filtering such
                                        alignments reduces the number of
                                        variables that need to be considered
                                        and can result in slightly faster
                                        inference and 'cleaner' equivalence
                                        classes.
  -z [ --writeMappings ] [=arg(=-)]     If this option is provided, then the
                                        selective-alignment results will be
                                        written out in SAM-compatible format.
                                        By default, output will be directed to
                                        stdout, but an alternative file name
                                        can be provided instead.
  --writeQualities                      This flag only has meaning if mappings
                                        are being written (with
                                        --writeMappings/-z). If this flag is
                                        provided, then the output SAM file will
                                        contain quality strings as well as read
                                        sequences. Note that this can greatly
                                        increase the size of the output file.
  --hitFilterPolicy arg (=AFTER)        [selective-alignment mode only] :
                                        Determines the policy by which hits are
                                        filtered in selective alignment.
                                        Filtering hits after chaining (the
                                        default) is more sensitive, but more
                                        computationally intensive, because it
                                        performs the chaining dynamic program
                                        for all hits.  Filtering before
                                        chaining is faster, but some true hits
                                        may be missed.  The options are BEFORE,
                                        AFTER, BOTH and NONE.


advanced options:
  --alternativeInitMode                 [Experimental]: Use an alternative
                                        strategy (rather than simple
                                        interpolation between) the online and
                                        uniform abundance estimates to
                                        initialize the EM / VBEM algorithm.
  --auxDir arg (=aux_info)              The sub-directory of the quantification
                                        directory where auxiliary information
                                        e.g. bootstraps, bias parameters, etc.
                                        will be written.
  --skipQuant                           Skip performing the actual transcript
                                        quantification (including any Gibbs
                                        sampling or bootstrapping).
  --dumpEq                              Dump the simple equivalence class
                                        counts that were computed during
                                        mapping or alignment.
  -d [ --dumpEqWeights ]                Dump conditional probabilities
                                        associated with transcripts when
                                        equivalence class information is being
                                        dumped to file. Note, this will dump
                                        the factorization that is actually used
                                        by salmon's offline phase for
                                        inference.  If you are using
                                        range-factorized equivalence classes
                                        (the default) then the same transcript
                                        set may appear multiple times with
                                        different associated conditional
                                        probabilities.
  --minAssignedFrags arg (=10)          The minimum number of fragments that
                                        must be assigned to the transcriptome
                                        for quantification to proceed.
  --reduceGCMemory                      If this option is selected, a more
                                        memory efficient (but slightly slower)
                                        representation is used to compute
                                        fragment GC content. Enabling this will
                                        reduce memory usage, but can also
                                        reduce speed.  However, the results
                                        themselves will remain the same.
  --biasSpeedSamp arg (=5)              The value at which the fragment length
                                        PMF is down-sampled when evaluating
                                        sequence-specific & GC fragment bias.
                                        Larger values speed up effective length
                                        correction, but may decrease the
                                        fidelity of bias modeling results.
  --fldMax arg (=1000)                  The maximum fragment length to consider
                                        when building the empirical
                                        distribution
  --fldMean arg (=250)                  The mean used in the fragment length
                                        distribution prior
  --fldSD arg (=25)                     The standard deviation used in the
                                        fragment length distribution prior
  -f [ --forgettingFactor ] arg (=0.65000000000000002)
                                        The forgetting factor used in the
                                        online learning schedule.  A smaller
                                        value results in quicker learning, but
                                        higher variance and may be unstable.  A
                                        larger value results in slower learning
                                        but may be more stable.  Value should
                                        be in the interval (0.5, 1.0].
  --initUniform                         initialize the offline inference with
                                        uniform parameters, rather than seeding
                                        with online parameters.
  --maxOccsPerHit arg (=1000)           When collecting "hits" (MEMs), hits
                                        having more than maxOccsPerHit
                                        occurrences won't be considered.
  -w [ --maxReadOcc ] arg (=200)        Reads "mapping" to more than this many
                                        places won't be considered.
  --maxRecoverReadOcc arg (=2500)       Relevant for alevin with '--sketch'
                                        mode only: if a read has valid seed
                                        matches, but no read has matches
                                        leading to fewer than "maxReadOcc"
                                        mappings, then try to recover mappings
                                        for this read as long as there are
                                        fewer than "maxRecoverReadOcc"
                                        mappings.
  --noLengthCorrection                  [experimental] : Entirely disables
                                        length correction when estimating the
                                        abundance of transcripts.  This option
                                        can be used with protocols where one
                                        expects that fragments derive from
                                        their underlying targets without regard
                                        to that target's length (e.g. QuantSeq)
  --noEffectiveLengthCorrection         Disables effective length correction
                                        when computing the probability that a
                                        fragment was generated from a
                                        transcript.  If this flag is passed in,
                                        the fragment length distribution is not
                                        taken into account when computing this
                                        probability.
  --noSingleFragProb                    Disables the estimation of an
                                        associated fragment length probability
                                        for single-end reads or for orphaned
                                        mappings in paired-end libraries.  The
                                        default behavior is to consider the
                                        probability of all possible fragment
                                        lengths associated with the retained
                                        mapping.  Enabling this flag (i.e.
                                        turning this default behavior off) will
                                        simply not attempt to estimate a
                                        fragment length probability in such
                                        cases.
  --noFragLengthDist                    [experimental] : Don't consider
                                        concordance with the learned fragment
                                        length distribution when trying to
                                        determine the probability that a
                                        fragment has originated from a
                                        specified location.  Normally,
                                        Fragments with unlikely lengths will be
                                        assigned a smaller relative probability
                                        than those with more likely lengths.
                                        When this flag is passed in, the
                                        observed fragment length has no effect
                                        on that fragment's a priori
                                        probability.
  --noBiasLengthThreshold               [experimental] : If this option is
                                        enabled, then no (lower) threshold will
                                        be set on how short bias correction can
                                        make effective lengths. This can
                                        increase the precision of bias
                                        correction, but harm robustness.  The
                                        default correction applies a threshold.
  --numBiasSamples arg (=2000000)       Number of fragment mappings to use when
                                        learning the sequence-specific bias
                                        model.
  --numAuxModelSamples arg (=5000000)   The first <numAuxModelSamples> are used
                                        to train the auxiliary model parameters
                                        (e.g. fragment length distribution,
                                        bias, etc.).  After ther first
                                        <numAuxModelSamples> observations the
                                        auxiliary model parameters will be
                                        assumed to have converged and will be
                                        fixed.
  --numPreAuxModelSamples arg (=5000)   The first <numPreAuxModelSamples> will
                                        have their assignment likelihoods and
                                        contributions to the transcript
                                        abundances computed without applying
                                        any auxiliary models.  The purpose of
                                        ignoring the auxiliary models for the
                                        first <numPreAuxModelSamples>
                                        observations is to avoid applying these
                                        models before their parameters have
                                        been learned sufficiently well.
  --useEM                               Use the traditional EM algorithm for
                                        optimization in the batch passes.
  --useVBOpt                            Use the Variational Bayesian EM
                                        [default]
  --rangeFactorizationBins arg (=4)     Factorizes the likelihood used in
                                        quantification by adopting a new notion
                                        of equivalence classes based on the
                                        conditional probabilities with which
                                        fragments are generated from different
                                        transcripts.  This is a more
                                        fine-grained factorization than the
                                        normal rich equivalence classes.  The
                                        default value (4) corresponds to the
                                        default used in Zakeri et al. 2017
                                        (doi: 10.1093/bioinformatics/btx262),
                                        and larger values imply a more
                                        fine-grained factorization.  If range
                                        factorization is enabled, a common
                                        value to select for this parameter is
                                        4. A value of 0 signifies the use of
                                        basic rich equivalence classes.
  --numGibbsSamples arg (=0)            Number of Gibbs sampling rounds to
                                        perform.
  --noGammaDraw                         This switch will disable drawing
                                        transcript fractions from a Gamma
                                        distribution during Gibbs sampling.  In
                                        this case the sampler does not account
                                        for shot-noise, but only assignment
                                        ambiguity
  --numBootstraps arg (=0)              Number of bootstrap samples to
                                        generate. Note: This is mutually
                                        exclusive with Gibbs sampling.
  --bootstrapReproject                  This switch will learn the parameter
                                        distribution from the bootstrapped
                                        counts for each sample, but will
                                        reproject those parameters onto the
                                        original equivalence class counts.
  --thinningFactor arg (=16)            Number of steps to discard for every
                                        sample kept from the Gibbs chain. The
                                        larger this number, the less chance
                                        that subsequent samples are
                                        auto-correlated, but the slower
                                        sampling becomes.
  -q [ --quiet ]                        Be quiet while doing quantification
                                        (don't write informative output to the
                                        console unless something goes wrong).
  --perTranscriptPrior                  The prior (either the default or the
                                        argument provided via --vbPrior) will
                                        be interpreted as a transcript-level
                                        prior (i.e. each transcript will be
                                        given a prior read count of this value)
  --perNucleotidePrior                  The prior (either the default or the
                                        argument provided via --vbPrior) will
                                        be interpreted as a nucleotide-level
                                        prior (i.e. each nucleotide will be
                                        given a prior read count of this value)
  --sigDigits arg (=3)                  The number of significant digits to
                                        write when outputting the
                                        EffectiveLength and NumReads columns
  --vbPrior arg (=0.01)                 The prior that will be used in the VBEM
                                        algorithm.  This is interpreted as a
                                        per-transcript prior, unless the
                                        --perNucleotidePrior flag is also
                                        given.  If the --perNucleotidePrior
                                        flag is given, this is used as a
                                        nucleotide-level prior.  If the default
                                        is used, it will be divided by 1000
                                        before being used as a nucleotide-level
                                        prior, i.e. the default per-nucleotide
                                        prior will be 1e-5.
  --writeOrphanLinks                    Write the transcripts that are linked
                                        by orphaned reads.
  --writeUnmappedNames                  Write the names of un-mapped reads to
                                        the file unmapped_names.txt in the
                                        auxiliary directory.

(salmon) raul@119cb66ee7b2:~$ salmon index --help
Version Server Response: Not Found

Index
==========
Creates a salmon index.

Command Line Options:
  -v [ --version ]              print version string
  -h [ --help ]                 produce help message
  -t [ --transcripts ] arg      Transcript fasta file.
  -k [ --kmerLen ] arg (=31)    The size of k-mers that should be used for the
                                quasi index.
  -i [ --index ] arg            salmon index.
  --gencode                     This flag will expect the input transcript
                                fasta to be in GENCODE format, and will split
                                the transcript name at the first '|' character.
                                These reduced names will be used in the output
                                and when looking for these transcripts in a
                                gene to transcript GTF.
  --features                    This flag will expect the input reference to be
                                in the tsv file format, and will split the
                                feature name at the first 'tab' character.
                                These reduced names will be used in the output
                                and when looking for the sequence of the
                                features.GTF.
  --keepDuplicates              This flag will disable the default indexing
                                behavior of discarding sequence-identical
                                duplicate transcripts.  If this flag is passed,
                                then duplicate transcripts that appear in the
                                input will be retained and quantified
                                separately.
  -p [ --threads ] arg (=2)     Number of threads to use during indexing.
  --keepFixedFasta              Retain the fixed fasta file (without short
                                transcripts and duplicates, clipped, etc.)
                                generated during indexing
  -f [ --filterSize ] arg (=-1) The size of the Bloom filter that will be used
                                by TwoPaCo during indexing. The filter will be
                                of size 2^{filterSize}. The default value of -1
                                means that the filter size will be
                                automatically set based on the number of
                                distinct k-mers in the input, as estimated by
                                nthll.
  --tmpdir arg                  The directory location that will be used for
                                TwoPaCo temporary files; it will be created if
                                need be and be removed prior to indexing
                                completion. The default value will cause a
                                (temporary) subdirectory of the salmon index
                                directory to be used for this purpose.
  --sparse                      Build the index using a sparse sampling of
                                k-mer positions This will require less memory
                                (especially during quantification), but will
                                take longer to construct and can slow down
                                mapping / alignment
  -d [ --decoys ] arg           Treat these sequences ids from the reference as
                                the decoys that may have sequence homologous to
                                some known transcript. for example in case of
                                the genome, provide a list of chromosome name
                                --- one per line
  -n [ --no-clip ]              Don't clip poly-A tails from the ends of target
                                sequences
  --type arg (=puff)            The type of index to build; the only option is
                                "puff" in this version of salmon.

(salmon) raul@119cb66ee7b2:~$ mkdir Genome_Refs
(salmon) raul@119cb66ee7b2:~$ cd Genome_Refs/
(salmon) raul@119cb66ee7b2:~/Genome_Refs$ wget https://ftp.ensembl.org/pub/release-110/fasta/homo_sapiens/cdna/Homo_Ch38.cdna.all.fa.gz
--2023-09-19 12:59:27--  https://ftp.ensembl.org/pub/release-110/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.al
Resolving ftp.ensembl.org (ftp.ensembl.org)... 193.62.193.169
Connecting to ftp.ensembl.org (ftp.ensembl.org)|193.62.193.169|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 78889691 (75M) [application/x-gzip]
Saving to: 'Homo_sapiens.GRCh38.cdna.all.fa.gz'

Homo_sapiens.GRCh38.cdna.all.fa 100%[=====================================================>]  75.23M  1.06MB/s    in

2023-09-19 13:00:41 (1.02 MB/s) - 'Homo_sapiens.GRCh38.cdna.all.fa.gz' saved [78889691/78889691]

(salmon) raul@119cb66ee7b2:~/Genome_Refs$ salmon index -t Homo_sapiens.GRCh38.cdna.all.fa.gz -i Transcriptome_Index_sa_v38
Version Server Response: Not Found
index ["Transcriptome_Index_Ref_Hsa_v38"] did not previously exist  . . . creating it
[2023-09-19 13:03:59.859] [jLog] [warning] The salmon index is being built without any decoy sequences.  It is recomd that decoy sequence (either computed auxiliary decoy sequence or the genome of the organism) be provided during ing. Further details can be found at https://salmon.readthedocs.io/en/latest/salmon.html#preparing-transcriptome-indicpping-based-mode.
[2023-09-19 13:03:59.859] [jLog] [info] building index
out : Transcriptome_Index_Ref_Hsa_v38
[2023-09-19 13:03:59.860] [puff::index::jointLog] [info] Running fixFasta

[Step 1 of 4] : counting k-mers
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000415118.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000448914.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000434970.2], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000631435.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000632684.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000710614.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000605284.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000604642.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000603077.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000604446.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000604102.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000603693.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000604950.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000604838.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000603935.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000632524.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000633009.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000634070.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000632963.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.879] [puff::index::jointLog] [warning] Entry with header [ENST00000633030.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000633765.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000632619.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000632968.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000633159.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000631871.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000633010.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000632473.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000631884.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000632859.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000631895.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000634154.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000632609.2], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000632911.2], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000633504.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000632304.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000632542.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000633968.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000634085.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000633353.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000631803.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000633210.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000603326.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000439842.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000390567.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000452198.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000390569.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000437320.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000390571.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000390572.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000450276.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000390574.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000390575.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000431870.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000390578.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000451044.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000390580.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000390581.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000431440.2], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000390585.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000430425.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000454691.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000390588.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000414852.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000390590.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000390591.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000454908.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000390583.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:03:59.880] [puff::index::jointLog] [warning] Entry with header [ENST00000390584.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:04:00.544] [puff::index::jointLog] [warning] Entry with header [ENST00000626807.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:04:00.706] [puff::index::jointLog] [warning] Entry with header [ENST00000629250.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:04:00.773] [puff::index::jointLog] [warning] Entry with header [ENST00000632054.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:04:01.478] [puff::index::jointLog] [warning] Entry with header [ENST00000417283.5], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:04:01.478] [puff::index::jointLog] [warning] Entry with header [ENST00000465958.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:04:01.746] [puff::index::jointLog] [warning] Entry with header [ENST00000437226.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:04:05.102] [puff::index::jointLog] [warning] Entry with header [ENST00000692460.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:04:07.090] [puff::index::jointLog] [warning] Entry with header [ENST00000682202.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:04:08.305] [puff::index::jointLog] [warning] Entry with header [ENST00000632342.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:04:08.305] [puff::index::jointLog] [warning] Entry with header [ENST00000518246.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:04:08.493] [puff::index::jointLog] [warning] Entry with header [ENST00000473810.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:04:08.502] [puff::index::jointLog] [warning] Entry with header [ENST00000543745.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:04:08.511] [puff::index::jointLog] [warning] Entry with header [ENST00000603775.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:04:08.528] [puff::index::jointLog] [warning] Entry with header [ENST00000579054.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:04:08.601] [puff::index::jointLog] [warning] Entry with header [ENST00000573437.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 13:04:08.608] [puff::index::jointLog] [warning] Entry with header [ENST00000634174.1], had length less tqual to the k-mer length of 31 (perhaps after poly-A clipping)

[2023-09-19 13:04:08.643] [puff::index::jointLog] [warning] Removed 13067 transcripts that were sequence duplicates dexed transcripts.
[2023-09-19 13:04:08.643] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use --keepDuplicates` flag
[2023-09-19 13:04:08.647] [puff::index::jointLog] [info] Replaced 100005 non-ATCG nucleotides
[2023-09-19 13:04:08.647] [puff::index::jointLog] [info] Clipped poly-A tails from 1525 transcripts
wrote 194135 cleaned references
[2023-09-19 13:04:09.532] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distincers
[2023-09-19 13:04:11.764] [puff::index::jointLog] [info] ntHll estimated 115888588 distinct k-mers, setting filter so 2^31
Threads = 2
Vertex length = 31
Hash functions = 5
Filter size = 2147483648
Capacity = 2
Files:
Transcriptome_Index_Ref_Hsa_v38/ref_k31_fixed.fa
--------------------------------------------------------------------------------
Round 0, 0:2147483648
Pass    Filling Filtering
1       55      93
2       7       0
True junctions count = 796713
False junctions count = 1437204
Hash table size = 2233917
Candidate marks count = 12831559
--------------------------------------------------------------------------------
Reallocating bifurcations time: 0
True marks count: 8105724
Edges construction time: 7
--------------------------------------------------------------------------------
Distinct junctions = 796713

TwoPaCo::buildGraphMain:: allocated with scalable_malloc; freeing.
TwoPaCo::buildGraphMain:: Calling scalable_allocation_command(TBBMALLOC_CLEAN_ALL_BUFFERS, 0);
allowedIn: 18
Max Junction ID: 904287
seen.size():7234305 kmerInfo.size():904288
approximateContigTotalLength: 80962941
counters for complex kmers:
(prec>1 & succ>1)=54955 | (succ>1 & isStart)=883 | (prec>1 & isEnd)=835 | (isStart & isEnd)=80
contig count: 1195517 element count: 152591552 complex nodes: 56753
# of ones in rank vector: 1195516
[2023-09-19 13:07:17.741] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary
[2023-09-19 13:07:17.741] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory Transcriptome_Index_Ra_v38
size = 152591552
-----------------------------------------
| Loading contigs | Time = 23.746 ms
-----------------------------------------
size = 152591552
-----------------------------------------
| Loading contig boundaries | Time = 11.784 ms
-----------------------------------------
Number of ones: 1195516
Number of ones per inventory item: 512
Inventory entries filled: 2335
1195516
[2023-09-19 13:07:18.022] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.
[2023-09-19 13:07:18.033] [puff::index::jointLog] [info] contig count for validation: 1195516
[2023-09-19 13:07:18.531] [puff::index::jointLog] [info] Total # of Contigs : 1195516
[2023-09-19 13:07:18.531] [puff::index::jointLog] [info] Total # of numerical Contigs : 1195516
[2023-09-19 13:07:18.593] [puff::index::jointLog] [info] Total # of contig vec entries: 8156827
[2023-09-19 13:07:18.593] [puff::index::jointLog] [info] bits per offset entry 23
[2023-09-19 13:07:18.848] [puff::index::jointLog] [info] Done constructing the contig vector. 1195517
[2023-09-19 13:07:19.324] [puff::index::jointLog] [info] # segments = 1195516
[2023-09-19 13:07:19.324] [puff::index::jointLog] [info] total length = 152591552
[2023-09-19 13:07:19.416] [puff::index::jointLog] [info] Reading the reference files ...
[2023-09-19 13:07:20.470] [puff::index::jointLog] [info] positional integer width = 28
[2023-09-19 13:07:20.470] [puff::index::jointLog] [info] seqSize = 152591552
[2023-09-19 13:07:20.470] [puff::index::jointLog] [info] rankSize = 152591552
[2023-09-19 13:07:20.470] [puff::index::jointLog] [info] edgeVecSize = 0
[2023-09-19 13:07:20.470] [puff::index::jointLog] [info] num keys = 116726072
for info, total work write each  : 2.331    total work inram from level 3 : 4.322  total work raw : 25.000
[Building BooPHF]  100  %   elapsed:   0 min 13 sec   remaining:   0 min 0  sec
Bitarray       611612992  bits (100.00 %)   (array + ranks )
final hash             0  bits (0.00 %) (nb in final hash 0)
[2023-09-19 13:07:33.209] [puff::index::jointLog] [info] mphf size = 72.91 MB
[2023-09-19 13:07:33.399] [puff::index::jointLog] [info] chunk size = 76295776
[2023-09-19 13:07:33.399] [puff::index::jointLog] [info] chunk 0 = [0, 76295776)
[2023-09-19 13:07:33.399] [puff::index::jointLog] [info] chunk 1 = [76295776, 152591522)
[2023-09-19 13:07:50.677] [puff::index::jointLog] [info] finished populating pos vector
[2023-09-19 13:07:50.678] [puff::index::jointLog] [info] writing index components
[2023-09-19 13:07:51.031] [puff::index::jointLog] [info] finished writing dense pufferfish index
[2023-09-19 13:07:51.143] [jLog] [info] done building index
(salmon) raul@119cb66ee7b2:~/Genome_Refs$
(salmon) raul@119cb66ee7b2:~/Genome_Refs$
(salmon) raul@119cb66ee7b2:~/Genome_Refs$ wget https://ftp.ensembl.org/pub/release-110/fasta/mus_musculus/cdna/Mus_mus.GRCm39.cdna.all.fa.gz
--2023-09-19 14:07:07--  https://ftp.ensembl.org/pub/release-110/fasta/mus_musculus/cdna/Mus_musculus.GRCm39.cdna.algz
Resolving ftp.ensembl.org (ftp.ensembl.org)... 193.62.193.169
Connecting to ftp.ensembl.org (ftp.ensembl.org)|193.62.193.169|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 51111850 (49M) [application/x-gzip]
Saving to: 'Mus_musculus.GRCm39.cdna.all.fa.gz'

Mus_musculus.GRCm39.cdna.all.f 100%[=================================================>]  48.74M  1.05MB/s    in 47s

2023-09-19 14:07:54 (1.05 MB/s) - 'Mus_musculus.GRCm39.cdna.all.fa.gz' saved [51111850/51111850]

(salmon) raul@119cb66ee7b2:~/Genome_Refs$ salmon index -t Mus_musculus.GRCm39.cdna.all.fa.gz -i Transcriptome_Index_mu_v39
Version Server Response: Not Found
index ["Transcriptome_Index_Ref_Mmu_v39"] did not previously exist  . . . creating it
[2023-09-19 14:15:06.062] [jLog] [warning] The salmon index is being built without any decoy sequences.  It is recomd that decoy sequence (either computed auxiliary decoy sequence or the genome of the organism) be provided during ing. Further details can be found at https://salmon.readthedocs.io/en/latest/salmon.html#preparing-transcriptome-indicpping-based-mode.
[2023-09-19 14:15:06.062] [jLog] [info] building index
out : Transcriptome_Index_Ref_Mmu_v39
[2023-09-19 14:15:06.063] [puff::index::jointLog] [info] Running fixFasta

[Step 1 of 4] : counting k-mers
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000196221.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000179664.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000177564.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000178537.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000178862.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000179520.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000179883.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000195858.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000179932.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000180001.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000178815.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000177965.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000178909.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000177646.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000178230.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000178483.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000179262.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000178549.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000193012.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000179166.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000179560.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000177839.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000103439.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000180266.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.078] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000103441.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.287] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000226961.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.574] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000227002.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:06.958] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000228114.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:07.320] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000226615.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:07.354] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000231713.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:07.354] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000231466.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:07.551] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000226153.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:08.274] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000226589.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:08.397] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000226226.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:08.535] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000226172.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:08.641] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000227223.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:08.976] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000229312.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:10.606] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000103739.4], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:10.615] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000191703.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:10.691] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000200713.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:10.764] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000178902.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:10.764] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000192089.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:10.764] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000170385.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)
[2023-09-19 14:15:10.764] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000178811.2], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)

[2023-09-19 14:15:10.839] [puff::index::jointLog] [warning] Removed 695 transcripts that were sequence duplicates ofxed transcripts.
[2023-09-19 14:15:10.839] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use --keepDuplicates` flag
[2023-09-19 14:15:10.839] [puff::index::jointLog] [info] Replaced 0 non-ATCG nucleotides
[2023-09-19 14:15:10.839] [puff::index::jointLog] [info] Clipped poly-A tails from 653 transcripts
wrote 116141 cleaned references
[2023-09-19 14:15:11.338] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distincers
[2023-09-19 14:15:12.629] [puff::index::jointLog] [info] ntHll estimated 100340972 distinct k-mers, setting filter so 2^31
Threads = 2
Vertex length = 31
Hash functions = 5
Filter size = 2147483648
Capacity = 2
Files:
Transcriptome_Index_Ref_Mmu_v39/ref_k31_fixed.fa
--------------------------------------------------------------------------------
Round 0, 0:2147483648
Pass    Filling Filtering
1       37      59
2       4       0
True junctions count = 476230
False junctions count = 802311
Hash table size = 1278541
Candidate marks count = 5276921
--------------------------------------------------------------------------------
Reallocating bifurcations time: 0
True marks count: 3452997
Edges construction time: 4
--------------------------------------------------------------------------------
Distinct junctions = 476230

TwoPaCo::buildGraphMain:: allocated with scalable_malloc; freeing.
TwoPaCo::buildGraphMain:: Calling scalable_allocation_command(TBBMALLOC_CLEAN_ALL_BUFFERS, 0);
allowedIn: 21
Max Junction ID: 566313
seen.size():4530513 kmerInfo.size():566314
approximateContigTotalLength: 72299091
counters for complex kmers:
(prec>1 & succ>1)=22014 | (succ>1 & isStart)=433 | (prec>1 & isEnd)=413 | (isStart & isEnd)=30
contig count: 723530 element count: 122544467 complex nodes: 22890
# of ones in rank vector: 723529
[2023-09-19 14:17:10.041] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary
[2023-09-19 14:17:10.041] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory Transcriptome_Index_Ru_v39
size = 122544467
-----------------------------------------
| Loading contigs | Time = 19.021 ms
-----------------------------------------
size = 122544467
-----------------------------------------
| Loading contig boundaries | Time = 9.4448 ms
-----------------------------------------
Number of ones: 723529
Number of ones per inventory item: 512
Inventory entries filled: 1414
723529
[2023-09-19 14:17:10.257] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.
[2023-09-19 14:17:10.264] [puff::index::jointLog] [info] contig count for validation: 723529
[2023-09-19 14:17:10.484] [puff::index::jointLog] [info] Total # of Contigs : 723529
[2023-09-19 14:17:10.484] [puff::index::jointLog] [info] Total # of numerical Contigs : 723529
[2023-09-19 14:17:10.514] [puff::index::jointLog] [info] Total # of contig vec entries: 3434763
[2023-09-19 14:17:10.514] [puff::index::jointLog] [info] bits per offset entry 22
[2023-09-19 14:17:10.611] [puff::index::jointLog] [info] Done constructing the contig vector. 723530
[2023-09-19 14:17:10.822] [puff::index::jointLog] [info] # segments = 723529
[2023-09-19 14:17:10.822] [puff::index::jointLog] [info] total length = 122544467
[2023-09-19 14:17:10.875] [puff::index::jointLog] [info] Reading the reference files ...
[2023-09-19 14:17:11.484] [puff::index::jointLog] [info] positional integer width = 27
[2023-09-19 14:17:11.484] [puff::index::jointLog] [info] seqSize = 122544467
[2023-09-19 14:17:11.484] [puff::index::jointLog] [info] rankSize = 122544467
[2023-09-19 14:17:11.484] [puff::index::jointLog] [info] edgeVecSize = 0
[2023-09-19 14:17:11.484] [puff::index::jointLog] [info] num keys = 100838597
for info, total work write each  : 2.331    total work inram from level 3 : 4.322  total work raw : 25.000
[Building BooPHF]  99.9 %   elapsed:   0 min 11 sec   remaining:   0 min 0  sec
Bitarray       528367552  bits (100.00 %)   (array + ranks )
final hash             0  bits (0.00 %) (nb in final hash 0)
[2023-09-19 14:17:22.104] [puff::index::jointLog] [info] mphf size = 62.9863 MB
[2023-09-19 14:17:22.313] [puff::index::jointLog] [info] chunk size = 61272234
[2023-09-19 14:17:22.313] [puff::index::jointLog] [info] chunk 0 = [0, 61272234)
[2023-09-19 14:17:22.313] [puff::index::jointLog] [info] chunk 1 = [61272234, 122544437)
[2023-09-19 14:17:36.827] [puff::index::jointLog] [info] finished populating pos vector
[2023-09-19 14:17:36.827] [puff::index::jointLog] [info] writing index components
[2023-09-19 14:17:37.153] [puff::index::jointLog] [info] finished writing dense pufferfish index
[2023-09-19 14:17:37.230] [jLog] [info] done building index
(salmon) raul@119cb66ee7b2:~/Genome_Refs$ wget https://ftp.ensembl.org/pub/release-110/fasta/rattus_norvegicus/cdna/s_norvegicus.mRatBN7.2.cdna.all.fa.gz
--2023-09-19 14:21:49--  https://ftp.ensembl.org/pub/release-110/fasta/rattus_norvegicus/cdna/Rattus_norvegicus.mRat.cdna.all.fa.gz
Resolving ftp.ensembl.org (ftp.ensembl.org)... 193.62.193.169
Connecting to ftp.ensembl.org (ftp.ensembl.org)|193.62.193.169|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 30708909 (29M) [application/x-gzip]
Saving to: 'Rattus_norvegicus.mRatBN7.2.cdna.all.fa.gz'

.mRatBN7.2.cdna.all.fa.gz       26%[============>                                     ]   7.71M  1.05MB/s    eta 21s
(salmon) raul@119cb66ee7b2:~/Genome_Refs$ wget https://ftp.ensembl.org/pub/release-110/fasta/rattus_norvegicus/cdna/s_norvegicus.mRatBN7.2.cdna.all.fa.gz
--2023-09-19 14:24:43--  https://ftp.ensembl.org/pub/release-110/fasta/rattus_norvegicus/cdna/Rattus_norvegicus.mRat.cdna.all.fa.gz
Resolving ftp.ensembl.org (ftp.ensembl.org)... 193.62.193.169
Connecting to ftp.ensembl.org (ftp.ensembl.org)|193.62.193.169|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 30708909 (29M) [application/x-gzip]
Saving to: 'Rattus_norvegicus.mRatBN7.2.cdna.all.fa.gz.1'

Rattus_norvegicus.mRatBN7.2.cd 100%[=================================================>]  29.29M  19.8MB/s    in 1.5s

2023-09-19 14:24:45 (19.8 MB/s) - 'Rattus_norvegicus.mRatBN7.2.cdna.all.fa.gz.1' saved [30708909/30708909]

(salmon) raul@119cb66ee7b2:~/Genome_Refs$ salmon index -t Rattus_norvegicus.mRatBN7.2.cdna.all.fa.gz.1 -i Transcriptndex_Ref_Rno_v7_2
Version Server Response: Not Found
index ["Transcriptome_Index_Ref_Rno_v7_2"] did not previously exist  . . . creating it
[2023-09-19 14:25:57.301] [jLog] [warning] The salmon index is being built without any decoy sequences.  It is recomd that decoy sequence (either computed auxiliary decoy sequence or the genome of the organism) be provided during ing. Further details can be found at https://salmon.readthedocs.io/en/latest/salmon.html#preparing-transcriptome-indicpping-based-mode.
[2023-09-19 14:25:57.301] [jLog] [info] building index
out : Transcriptome_Index_Ref_Rno_v7_2
[2023-09-19 14:25:57.301] [puff::index::jointLog] [info] Running fixFasta

[Step 1 of 4] : counting k-mers
[2023-09-19 14:25:59.232] [puff::index::jointLog] [warning] Entry with header [ENSRNOT00000119815.1], had length lesn equal to the k-mer length of 31 (perhaps after poly-A clipping)

[2023-09-19 14:26:00.290] [puff::index::jointLog] [warning] Removed 128 transcripts that were sequence duplicates ofxed transcripts.
[2023-09-19 14:26:00.290] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use --keepDuplicates` flag
[2023-09-19 14:26:00.290] [puff::index::jointLog] [info] Replaced 37 non-ATCG nucleotides
[2023-09-19 14:26:00.290] [puff::index::jointLog] [info] Clipped poly-A tails from 190 transcripts
wrote 46727 cleaned references
[2023-09-19 14:26:00.565] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distincers
[2023-09-19 14:26:01.381] [puff::index::jointLog] [info] ntHll estimated 65734791 distinct k-mers, setting filter si 2^31
Threads = 2
Vertex length = 31
Hash functions = 5
Filter size = 2147483648
Capacity = 2
Files:
Transcriptome_Index_Ref_Rno_v7_2/ref_k31_fixed.fa
--------------------------------------------------------------------------------
Round 0, 0:2147483648
Pass    Filling Filtering

(salmon) raul@119cb66ee7b2:~/Genome_Refs$ salmon index -t Rattus_norvegicus.mRatBN7.2.cdna.all.fa.gz -i Transcriptomef_Rno_v7_2
Version Server Response: Not Found
[2023-09-19 14:26:38.361] [jLog] [warning] The salmon index is being built without any decoy sequences.  It is recomat decoy sequence (either computed auxiliary decoy sequence or the genome of the organism) be provided during indexier details can be found at https://salmon.readthedocs.io/en/latest/salmon.html#preparing-transcriptome-indices-mappimode.
[2023-09-19 14:26:38.362] [jLog] [info] building index
out : Transcriptome_Index_Ref_Rno_v7_2
[2023-09-19 14:26:38.362] [puff::index::jointLog] [info] Running fixFasta

[Step 1 of 4] : counting k-mers

[2023-09-19 14:26:39.226] [puff::index::jointLog] [warning] Removed 18 transcripts that were sequence duplicates of ranscripts.
[2023-09-19 14:26:39.226] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use epDuplicates` flag
[2023-09-19 14:26:39.226] [puff::index::jointLog] [info] Replaced 0 non-ATCG nucleotides
[2023-09-19 14:26:39.226] [puff::index::jointLog] [info] Clipped poly-A tails from 32 transcripts
wrote 12383 cleaned references
[2023-09-19 14:26:39.456] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinc
[2023-09-19 14:26:39.690] [puff::index::jointLog] [info] ntHll estimated 17712801 distinct k-mers, setting filter si9
Threads = 2
Vertex length = 31
Hash functions = 5
Filter size = 536870912
Capacity = 2
Files:
Transcriptome_Index_Ref_Rno_v7_2/ref_k31_fixed.fa
--------------------------------------------------------------------------------
Round 0, 0:536870912
Pass    Filling Filtering
1       6       9
2       1       0
True junctions count = 41077
False junctions count = 42499
Hash table size = 83576
Candidate marks count = 272088
--------------------------------------------------------------------------------
Reallocating bifurcations time: 0
True marks count: 205783
Edges construction time: 1
--------------------------------------------------------------------------------
Distinct junctions = 41077

TwoPaCo::buildGraphMain:: allocated with scalable_malloc; freeing.
TwoPaCo::buildGraphMain:: Calling scalable_allocation_command(TBBMALLOC_CLEAN_ALL_BUFFERS, 0);
allowedIn: 20
Max Junction ID: 52674
seen.size():421401 kmerInfo.size():52675
approximateContigTotalLength: 14205342
counters for complex kmers:
(prec>1 & succ>1)=1238 | (succ>1 & isStart)=13 | (prec>1 & isEnd)=10 | (isStart & isEnd)=1
contig count: 63758 element count: 19637521 complex nodes: 1262
# of ones in rank vector: 63757
[2023-09-19 14:26:57.915] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary
[2023-09-19 14:26:57.915] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory Transcriptome_Index_R_2
size = 19637521
-----------------------------------------
| Loading contigs | Time = 2.8945 ms
-----------------------------------------
size = 19637521
-----------------------------------------
| Loading contig boundaries | Time = 1.5956 ms
-----------------------------------------
Number of ones: 63757
Number of ones per inventory item: 512
Inventory entries filled: 125
63757
[2023-09-19 14:26:57.948] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.
[2023-09-19 14:26:57.948] [puff::index::jointLog] [info] contig count for validation: 63757
[2023-09-19 14:26:57.962] [puff::index::jointLog] [info] Total # of Contigs : 63757
[2023-09-19 14:26:57.962] [puff::index::jointLog] [info] Total # of numerical Contigs : 63757
[2023-09-19 14:26:57.963] [puff::index::jointLog] [info] Total # of contig vec entries: 198942
[2023-09-19 14:26:57.963] [puff::index::jointLog] [info] bits per offset entry 18
[2023-09-19 14:26:57.968] [puff::index::jointLog] [info] Done constructing the contig vector. 63758
[2023-09-19 14:26:57.981] [puff::index::jointLog] [info] # segments = 63757
[2023-09-19 14:26:57.981] [puff::index::jointLog] [info] total length = 19637521
[2023-09-19 14:26:57.987] [puff::index::jointLog] [info] Reading the reference files ...
[2023-09-19 14:26:58.091] [puff::index::jointLog] [info] positional integer width = 25
[2023-09-19 14:26:58.091] [puff::index::jointLog] [info] seqSize = 19637521
[2023-09-19 14:26:58.091] [puff::index::jointLog] [info] rankSize = 19637521
[2023-09-19 14:26:58.091] [puff::index::jointLog] [info] edgeVecSize = 0
[2023-09-19 14:26:58.091] [puff::index::jointLog] [info] num keys = 17724811
for info, total work write each  : 2.331    total work inram from level 3 : 4.322  total work raw : 25.000
[Building BooPHF]  100  %   elapsed:   0 min 1  sec   remaining:   0 min 0  sec
Bitarray        92877888  bits (100.00 %)   (array + ranks )
final hash             0  bits (0.00 %) (nb in final hash 0)
[2023-09-19 14:26:59.141] [puff::index::jointLog] [info] mphf size = 11.0719 MB
[2023-09-19 14:26:59.171] [puff::index::jointLog] [info] chunk size = 9818761
[2023-09-19 14:26:59.172] [puff::index::jointLog] [info] chunk 0 = [0, 9818761)
[2023-09-19 14:26:59.172] [puff::index::jointLog] [info] chunk 1 = [9818761, 19637491)
[2023-09-19 14:27:00.598] [puff::index::jointLog] [info] finished populating pos vector
[2023-09-19 14:27:00.598] [puff::index::jointLog] [info] writing index components
[2023-09-19 14:27:00.653] [puff::index::jointLog] [info] finished writing dense pufferfish index
[2023-09-19 14:27:00.665] [jLog] [info] done building index
(salmon) raul@119cb66ee7b2:~/Genome_Refs$ cd ..
(salmon) raul@119cb66ee7b2:~$ cd Fran/Basal_vs_Luminal/matt_analyses/
(salmon) raul@119cb66ee7b2:~/Fran/Basal_vs_Luminal/matt_analyses$ cd rnaseq_data/
(salmon) raul@119cb66ee7b2:~/Fran/Basal_vs_Luminal/matt_analyses/rnaseq_data$ salmon quant -i Transcriptome_Index_Ref_Hsa_v38 -l A -1 Basal_1_1.fastq.gz -2 Basal_1_2.fastq.gz --validateMappings -o transcripts_quant
Version Server Response: Not Found
### salmon (selective-alignment-based) v1.10.2
### [ program ] => salmon
### [ command ] => quant
### [ index ] => { Transcriptome_Index_Ref_Hsa_v38 }
### [ libType ] => { A }
### [ mates1 ] => { Basal_1_1.fastq.gz }
### [ mates2 ] => { Basal_1_2.fastq.gz }
### [ validateMappings ] => { }
### [ output ] => { transcripts_quant }
Logs will be written to transcripts_quant/logs
[2023-09-19 15:56:32.625] [jointLog] [info] setting maxHashResizeThreads to 64
Exception : [Error: The index version file Transcriptome_Index_Ref_Hsa_v38/versionInfo.json doesn't seem to exist.  Please try re-building the salmon index.]
salmon quant was invoked improperly.
For usage information, try salmon quant --help
Exiting.
[2023-09-19 15:56:32.625] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.
[2023-09-19 15:56:32.625] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65
[2023-09-19 15:56:32.625] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.
[2023-09-19 15:56:32.625] [jointLog] [info] parsing read library format
[2023-09-19 15:56:32.625] [jointLog] [info] There is 1 library.
(salmon) raul@119cb66ee7b2:~/Fran/Basal_vs_Luminal/matt_analyses/rnaseq_data$ salmon quant -i home/raul/Genome_Refs/Transcriptome_Index_Ref_Hsa_v38 -l A -1 Basal_1_1.fastq.gz -2 Basal_1_2.fastq.gz --validateMappings -o transcripts_quant
Version Server Response: Not Found
### salmon (selective-alignment-based) v1.10.2
### [ program ] => salmon
### [ command ] => quant
### [ index ] => { home/raul/Genome_Refs/Transcriptome_Index_Ref_Hsa_v38 }
### [ libType ] => { A }
### [ mates1 ] => { Basal_1_1.fastq.gz }
### [ mates2 ] => { Basal_1_2.fastq.gz }
### [ validateMappings ] => { }
### [ output ] => { transcripts_quant }
Logs will be written to transcripts_quant/logs
[2023-09-19 15:58:12.242] [jointLog] [info] setting maxHashResizeThreads to 64
Exception : [Error: The index version file home/raul/Genome_Refs/Transcriptome_Index_Ref_Hsa_v38/versionInfo.json doesn't seem to exist.  Please try re-building the salmon index.]
salmon quant was invoked improperly.
For usage information, try salmon quant --help
Exiting.
[2023-09-19 15:58:12.242] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.
[2023-09-19 15:58:12.242] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65
[2023-09-19 15:58:12.242] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.
[2023-09-19 15:58:12.242] [jointLog] [info] parsing read library format
[2023-09-19 15:58:12.242] [jointLog] [info] There is 1 library.
(salmon) raul@119cb66ee7b2:~/Fran/Basal_vs_Luminal/matt_analyses/rnaseq_data$ salmon quant -i /home/raul/Genome_Refs/Transcriptome_Index_Ref_Hsa_v38/ -l A -1 Basal_1_1.fastq.gz -2 Basal_1_2.fastq.gz --validateMappings -o transcripts_quant
Version Server Response: Not Found
### salmon (selective-alignment-based) v1.10.2
### [ program ] => salmon
### [ command ] => quant
### [ index ] => { /home/raul/Genome_Refs/Transcriptome_Index_Ref_Hsa_v38/ }
### [ libType ] => { A }
### [ mates1 ] => { Basal_1_1.fastq.gz }
### [ mates2 ] => { Basal_1_2.fastq.gz }
### [ validateMappings ] => { }
### [ output ] => { transcripts_quant }
Logs will be written to transcripts_quant/logs
[2023-09-19 15:59:49.015] [jointLog] [info] setting maxHashResizeThreads to 64
[2023-09-19 15:59:49.015] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.
[2023-09-19 15:59:49.015] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65
[2023-09-19 15:59:49.015] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.
[2023-09-19 15:59:49.015] [jointLog] [info] parsing read library format
[2023-09-19 15:59:49.015] [jointLog] [info] There is 1 library.
[2023-09-19 15:59:49.015] [jointLog] [info] Loading pufferfish index
[2023-09-19 15:59:49.015] [jointLog] [info] Loading dense pufferfish index.
-----------------------------------------
| Loading contig table | Time = 496.91 ms
-----------------------------------------
size = 1195517
-----------------------------------------
| Loading contig offsets | Time = 2.3156 ms
-----------------------------------------
-----------------------------------------
| Loading reference lengths | Time = 577.82 us
-----------------------------------------
-----------------------------------------
| Loading mphf table | Time = 46.055 ms
-----------------------------------------
size = 152591552
Number of ones: 1195516
Number of ones per inventory item: 512
Inventory entries filled: 2335
-----------------------------------------
| Loading contig boundaries | Time = 259.22 ms
-----------------------------------------
size = 152591552
-----------------------------------------
| Loading sequence | Time = 25.471 ms
-----------------------------------------
size = 116726072
-----------------------------------------
| Loading positions | Time = 253.29 ms
-----------------------------------------
size = 372349075
-----------------------------------------
| Loading reference sequence | Time = 57.46 ms
-----------------------------------------
-----------------------------------------
| Loading reference accumulative lengths | Time = 1.0305 ms
-----------------------------------------
[2023-09-19 15:59:50.159] [jointLog] [info] done
[2023-09-19 15:59:50.257] [jointLog] [info] Index contained 194182 targets
[2023-09-19 15:59:50.326] [jointLog] [info] Number of decoys : 0




[2023-09-19 15:59:50.890] [jointLog] [info] Automatically detected most likely library type as ISR
processed 114500001 fragments
hits: 628439964, hits per frag:  5.50089[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.10% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.12% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.06% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.02% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.10% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.18% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.02% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.02% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.18% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.06% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.16% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.00% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.06% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.00% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.06% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.14% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.10% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.12% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.06% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.06% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.18% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.12% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.06% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.12% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.02% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.10% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.10% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.02% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.18% zero probability fragments
[2023-09-19 16:07:09.657] [jointLog] [info] Thread saw mini-batch with a maximum of 1.10% zero probability fragments
[2023-09-19 16:07:09.672] [jointLog] [info] Thread saw mini-batch with a maximum of 1.10% zero probability fragments
[2023-09-19 16:07:09.672] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments
[2023-09-19 16:07:09.672] [jointLog] [info] Thread saw mini-batch with a maximum of 1.12% zero probability fragments
[2023-09-19 16:07:09.672] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments
[2023-09-19 16:07:09.672] [jointLog] [info] Thread saw mini-batch with a maximum of 1.02% zero probability fragments
[2023-09-19 16:07:09.672] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments
[2023-09-19 16:07:09.672] [jointLog] [info] Thread saw mini-batch with a maximum of 1.12% zero probability fragments
[2023-09-19 16:07:09.728] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments
[2023-09-19 16:07:09.730] [jointLog] [info] Thread saw mini-batch with a maximum of 1.12% zero probability fragments
[2023-09-19 16:07:09.736] [jointLog] [info] Thread saw mini-batch with a maximum of 1.12% zero probability fragments
[2023-09-19 16:07:09.746] [jointLog] [info] Thread saw mini-batch with a maximum of 1.12% zero probability fragments
[2023-09-19 16:07:09.756] [jointLog] [info] Thread saw mini-batch with a maximum of 1.06% zero probability fragments
[2023-09-19 16:07:09.761] [jointLog] [info] Thread saw mini-batch with a maximum of 1.00% zero probability fragments
[2023-09-19 16:07:09.780] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments
[2023-09-19 16:07:09.784] [jointLog] [info] Thread saw mini-batch with a maximum of 1.12% zero probability fragments
[2023-09-19 16:07:09.789] [jointLog] [info] Thread saw mini-batch with a maximum of 1.02% zero probability fragments
[2023-09-19 16:07:09.806] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments
[2023-09-19 16:07:09.830] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments
[2023-09-19 16:07:09.885] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments
[2023-09-19 16:07:09.904] [jointLog] [info] Thread saw mini-batch with a maximum of 1.14% zero probability fragments
[2023-09-19 16:07:09.913] [jointLog] [info] Thread saw mini-batch with a maximum of 1.10% zero probability fragments








[2023-09-19 16:07:10.894] [jointLog] [info] Computed 1026473 rich equivalence classes for further processing
[2023-09-19 16:07:10.894] [jointLog] [info] Counted 98962852 total reads in the equivalence classes
[2023-09-19 16:07:10.967] [jointLog] [info] Number of mappings discarded because of alignment score : 57922745
[2023-09-19 16:07:10.967] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 3173499
[2023-09-19 16:07:10.967] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 0
[2023-09-19 16:07:10.967] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 830463
[2023-09-19 16:07:10.967] [jointLog] [info] Mapping rate = 86.0746%

[2023-09-19 16:07:10.967] [jointLog] [info] finished quantifyLibrary()
[2023-09-19 16:07:10.967] [jointLog] [info] Starting optimizer
[2023-09-19 16:07:20.428] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate
[2023-09-19 16:07:20.448] [jointLog] [info] iteration = 0 | max rel diff. = 119.09
[2023-09-19 16:07:22.130] [jointLog] [info] iteration = 100 | max rel diff. = 15.4538
[2023-09-19 16:07:23.786] [jointLog] [info] iteration = 200 | max rel diff. = 9.08486
[2023-09-19 16:07:25.360] [jointLog] [info] iteration = 300 | max rel diff. = 1.08538
[2023-09-19 16:07:26.924] [jointLog] [info] iteration = 400 | max rel diff. = 2.50373
[2023-09-19 16:07:28.492] [jointLog] [info] iteration = 500 | max rel diff. = 1.39735
[2023-09-19 16:07:30.053] [jointLog] [info] iteration = 600 | max rel diff. = 0.938655
[2023-09-19 16:07:31.616] [jointLog] [info] iteration = 700 | max rel diff. = 1.58569
[2023-09-19 16:07:33.168] [jointLog] [info] iteration = 800 | max rel diff. = 13.3609
[2023-09-19 16:07:34.724] [jointLog] [info] iteration = 900 | max rel diff. = 0.70984
[2023-09-19 16:07:36.246] [jointLog] [info] iteration = 1000 | max rel diff. = 0.42229
[2023-09-19 16:07:37.781] [jointLog] [info] iteration = 1100 | max rel diff. = 0.391976
[2023-09-19 16:07:39.256] [jointLog] [info] iteration = 1200 | max rel diff. = 0.127066
[2023-09-19 16:07:40.733] [jointLog] [info] iteration = 1300 | max rel diff. = 0.0827328
[2023-09-19 16:07:42.209] [jointLog] [info] iteration = 1400 | max rel diff. = 0.36072
[2023-09-19 16:07:43.683] [jointLog] [info] iteration = 1500 | max rel diff. = 0.110667
[2023-09-19 16:07:45.157] [jointLog] [info] iteration = 1600 | max rel diff. = 0.189472
[2023-09-19 16:07:46.628] [jointLog] [info] iteration = 1700 | max rel diff. = 0.163825
[2023-09-19 16:07:48.098] [jointLog] [info] iteration = 1800 | max rel diff. = 0.188727
[2023-09-19 16:07:49.570] [jointLog] [info] iteration = 1900 | max rel diff. = 0.0460824
[2023-09-19 16:07:51.039] [jointLog] [info] iteration = 2000 | max rel diff. = 0.0108482
[2023-09-19 16:07:52.510] [jointLog] [info] iteration = 2100 | max rel diff. = 0.121544
[2023-09-19 16:07:53.983] [jointLog] [info] iteration = 2200 | max rel diff. = 0.0276969
[2023-09-19 16:07:55.449] [jointLog] [info] iteration = 2300 | max rel diff. = 0.0643161
[2023-09-19 16:07:56.574] [jointLog] [info] iteration = 2378 | max rel diff. = 0.00716951
[2023-09-19 16:07:56.607] [jointLog] [info] Finished optimizer
[2023-09-19 16:07:56.607] [jointLog] [info] writing output

(salmon) raul@119cb66ee7b2:~/Fran/Basal_vs_Luminal/matt_analyses/rnaseq_data$
