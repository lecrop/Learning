[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Como descargar datos de repositorios on-line",
    "section": "",
    "text": "Para buscar RNAseq disponibles on-line es aquí me han recomendado acceder a NCBI, a la sección SRA.\nAquí realizamos la búsqueda que queramos. Veremos que muchos títulos, esto se debe a que lo que nos aparece son muestras de experimetos, no experimentos completos (como sucede en GEO). Es por ello por lo que en todo momento estamos viendo dónde se ha secuenciado la muestra, el número de reads (spots), el número de bases y lo que pesa cada archivo.\nCuando tengamos un candidato de muestra de interés clickamos y acedemos a la siguiente pantalla:\nDónde 1) es el nombre que recibe el proyecto y donde tendremos toda la información asociada al mismo, tanto publicación (si está publicado), como accesos a GEO (si la tiene, que normalmente si) y accesos a la misma información que 2). Esta información se trata de un listado de los SRA de las muestras secuenciadas en este experimento. Tenemos que clickar en 2 para ver este listado, que es lo que nos interesa.\nUna vez aquí nos saldrá el Run Selector (hay veces que no aparecer pero no pasa nada, no es imprescindible hacer este paso), donde podremos ver las propiedades del experimento:\nAquí tenemos toda la información del experimento (en common Fields) al que pertenecen las muestras. Esta información es muy útil para generar un documento excel para recopilar información de posibles RNAseq a analizar (dejo el ejemplo del que he creado yo):\nEs recomendable dejar los hipervínculos para luego facilitar el trabajo a la hora de buscar los datos. Continuaremos trabajando como ejemplo con el experimento que he ido mostrado en las ilustraciones. El siguiente paso es descargar un .csv con los accession de los SRA que vamos a analizar en la primera columna. Para ello tenemos que tener buscado en el NIH/SRA el código SRA del estudio al que están asociadas las muestras (tal y como se ve en la ilustración 1). Una vez aquí, clickamos en “Send to”, seleccionamos “File” y en formato seleccionamos “Accession List”, tal y como se observa en la Ilustración 1, y le damos a Create File:\nNos quedaría el siguiente (1), del cual tendríamos que eliminar la primera fila para que quede como (2) de forma definitiva.\n!!Comienzsa la programación!! O no.. depende de ti jeje"
  },
  {
    "objectID": "index.html#comando-perl-de-descarga-de-datos-para-linux-y-mac",
    "href": "index.html#comando-perl-de-descarga-de-datos-para-linux-y-mac",
    "title": "Como descargar datos de repositorios on-line",
    "section": "1.1 Comando Perl de descarga de datos para Linux y Mac",
    "text": "1.1 Comando Perl de descarga de datos para Linux y Mac\nPara trabajar con este script y tener la información ordenada es recomendable crear una carpeta en el escritorio con un nombre sin espacios. En esta carpeta tenemos que introducir un .csv con los accession que hemos preparado previamente. Para ejecutarlo, el comando es el siguiente:\n\nperl Irimia_Script_SRA_File_maker.pl SraAccList.csv\n\nDonde, - Perl Abre las funciones del lenguaje perl. - Irimia_Script_SRA_File_maker.pl es el script que se va ejecutar. - SraAccList.csv es el documento csv que nos bajamos con los accesion de las muestras de un experimento."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#comando-perl-de-descarga-de-datos-para-windows",
    "href": "index.html#comando-perl-de-descarga-de-datos-para-windows",
    "title": "Como descargar datos de repositorios on-line",
    "section": "1.2 Comando Perl de descarga de datos para Windows",
    "text": "1.2 Comando Perl de descarga de datos para Windows\nPara utilizar Perl en Windows hay que descargar “Strawberry” e instalarlo en C\\: (siguiendo las recomendaciones de instalación en todo momento).\nUna vez lo hemos instalado podremos utilizar el lenguaje Perl en nuestro ordenador Windows. Para poder utilizarlo tenemos leer el script de descarga automática (Irirmia_Script_SRA_File_maker.pl).\n\n\n\n\n\n\nWarning\n\n\n\nPara visualizar el script (no es necesario modificar nada del script) es recomendable descargarse un visualizador de documentos. En Windows hay un visualizador bastante cómodo de utilizar que es el “Visual Studio Code”.\n\n\nPara trabajar con este script y tener la información ordenada es recomendable crear una carpeta en el escritorio con un nombre sin espacios (por ejemplo, yo puse “Visual_Studio_Folders”. En esta carpeta tenemos que introducir un .csv con los accession.\n\n\n\n\n\n\nTip\n\n\n\nEste archivo lo tenemos que colocar en la misma carpeta que el script (la que hemos creado para utilizar Perl)\n\n\nUna vez tenemos esta carpeta con los documentos adecuados abrimos el terminal de Windows (buscamos cmd) y nos vamos a la carpeta que hemos creado con estos archivos y lo ejecutamos con la misma sintaxis que para Linux.\n\n1.2.1 Problemas de windows\nEs posible que si estamos utilizando el cmd de windows nos de el siguiente error:\n\n\"wget\" no se reconoce como un comando interno o externo, programa o archivo por lotes ejecutable.\n\nEn este caso necesitamos instalar esta función como función ejecutable. Para ello debemos seguir las instrucciones de la siguiente página web\nEn esta página nos tenemos que ir al apartado siguiente (y ver el video):\n\n\n\nImagen 11\n\n\nPor si acaso, dejo también el enlace tanto del video en youtube como de la página de descarga (hay que descargar el de x64 bits, https://eternallybored.org/misc/wget/)\nPor algún motivo no se me ha descargado (por error 404 al intentar acceder a la pag web) pero no pasa nada porque voy a empezar a trabajar en el superordenador que va con Linux y así se me acaban los problemas."
  },
  {
    "objectID": "index.html#contenido-script-irirmia_script_sra_file_maker.pl",
    "href": "index.html#contenido-script-irirmia_script_sra_file_maker.pl",
    "title": "Como descargar datos de repositorios on-line",
    "section": "1.3 Contenido Script Irirmia_Script_SRA_File_maker.pl",
    "text": "1.3 Contenido Script Irirmia_Script_SRA_File_maker.pl\n\n1.3.1 Código\n\nopen (I, $ARGV[0]);\n\nopen (O, \"&gt;$ARGV[0].out\");\n\nsystem \"mkdir SRA\" unless (-e \"SRA\");\n\nwhile (&lt;I&gt;){\n\n    s/\\r//g;\n\n    s/\\\"//g;\n\n    ($sra)=/(.+)/;\n    \n    sleep 2 unless (-e \"$sra\" || -e \"SRA/$sra\");\n\n    system \"wget https://www.ncbi.nlm.nih.gov/sra/$sra -O SRA/$sra\" unless (-e \"$sra\" || -e \"SRA/$sra\");\n\n    open (F, \"SRA/$sra\");\n\n    $/=\"\";\n\n    $PE=$n_reads=$all_info=\"\";\n\n    while (&lt;F&gt;){\n\n    if (/$sra\\&lt;\\/a\\&gt;\\&lt;\\/td\\&gt;\\&lt;td align\\=\\\"right\\\"\\&gt;(.+?)\\&lt;\\/td\\&gt;\\&lt;td align\\=\\\"right\\\"\\&gt;(.+?)\\&lt;\\/td\\&gt;\\&lt;td align/){$n_reads=$1;$bases=$2;}\n\n    if (/(\\&gt;Sample\\: .+?)\\&gt;Library\\:/){$all_info1=$1;}\n\n    if (/(\\&gt;Library\\: .+?)\\&gt;Runs\\:/){$all_info2=$1;}\n\n    if (/Layout\\: \\&lt;span\\&gt;PAIRED\\&lt;\\/span\\&gt;/){$PE=\"PE\";}\n\n    elsif (/Layout\\: \\&lt;span\\&gt;SINGLE\\&lt;\\/span\\&gt;/){$PE=\"SE\";}\n\n    }\n\n    close F;\n\n    $/=\"\\n\";\n\n    ($bp,$mult)=$bases=~/(.+)(\\w)$/;\n\n    $bases=$bp*1000 if $mult eq \"K\";\n\n    $bases=$bp*1000000 if $mult eq \"M\";\n\n    $bases=$bp*1000000000 if $mult eq \"G\";\n\n    \n\n    $n_readsT=$n_reads;\n\n    $n_readsT=~s/\\,//g;\n\n    $le=sprintf(\"%.0f\",$bases/$n_readsT) if $n_readsT&gt;0;\n\n    $le=\"NA\" if $n_readsT==0;\n\n    ($info1)=$all_info1=~/\\&gt;Sample\\:.+?\\&gt;(.+?)\\&lt;/;\n\n    ($info2)=$all_info2=~/\\&gt;Name\\:.+?\\&gt;(.+?)\\&lt;/;\n \n    print O \"$sra\\t$info1\\t$info2\\t$n_reads\\t$le\\t$PE\\n\";\n}\nexit;\n\n\n\n1.3.2 Explicación del Script\n\nopen (I, $ARGV[0]);\n\n\nopen: open es una función incorporada en Perl que se utiliza para abrir archivos o comandos externos. Permite interactuar con archivos para lectura, escritura o ambas.\n(I, $ARGV[0]): Esta parte de la función open toma dos argumentos encerrados entre paréntesis.\n\n\nI: El primer argumento, I, es un identificador de archivo o “filehandle”. En Perl, los filehandles son como variables que representan archivos abiertos. En este caso, I se utiliza como el filehandle para referirse al archivo abierto.\n\\$ARGV[0]: El segundo argumento, \\$ARGV[0], es una variable de tipo array. \\$ARGV es un array especial en Perl que contiene los argumentos de línea de comandos proporcionados a tu script de Perl. \\$ARGV[0] se refiere específicamente al primer argumento de la línea de comandos, que generalmente es el nombre del archivo que deseas abrir. Por lo tanto, \\$ARGV[0] es el nombre del archivo que deseas abrir.\n\nLa línea que proporcionaste, open (I, $ARGV[0]), abre el archivo cuyo nombre se proporciona como el primer argumento de línea de comandos cuando ejecutas el script de Perl y lo asocia con el filehandle I. Después de esta línea, puedes leer o escribir en el archivo utilizando el filehandle I.\nPor ejemplo, puedes leer líneas del archivo de la siguiente manera:\n\nwhile (&lt;I&gt;) {\n    # Procesar cada línea del archivo abierto\n    print $_;  # Imprimir la línea\n}\n\nLuego habría que cerrar el archivo con: close(I)\n\nopen (O, \"&gt;$ARGV[0].out\");\n\nAquí está la explicación: 1. open: Al igual que en la línea anterior, open es una función incorporada en Perl que se utiliza para abrir archivos o realizar operaciones de archivo. 2. (O, \"&gt;$ARGV[0].out\"): Esta parte de la función open toma dos argumentos encerrados entre paréntesis. - O: El primer argumento, O, es un identificador de archivo o “filehandle”. Al igual que en el ejemplo anterior, se utiliza como un filehandle que representará al archivo que estamos a punto de abrir. - &gt;\\$ARGV[0].out: El segundo argumento es una cadena de texto que define cómo se abrirá el archivo. En este caso, la cadena contiene “&gt;”, que indica que el archivo se abrirá en modo escritura (output), y \\$ARGV[0].out, que es el nombre del archivo de salida. $ARGV[0] se refiere al primer argumento de la línea de comandos que generalmente es el nombre del archivo de entrada, y .out es una extensión que se agrega para el archivo de salida.\nEntonces, la línea open (O, \"&gt;\\$ARGV[0].out\"); está abriendo un archivo para escritura. Si \\$ARGV[0] fuera, por ejemplo, “entrada.txt”, esta línea crearía un nuevo archivo llamado “entrada.txt.out” (o con la extensión que hayas especificado) y asociaría el filehandle O con este archivo.\n\nsystem \"mkdir SRA\" unless (-e \"SRA\");\n\nExplicación: 1. system: es una función en Perl que te permite ejecutar comandos del sistema operativo desde tu script de Perl. Puedes proporcionarle un comando entre comillas, y Perl lo ejecutará en el sistema operativo. 2. mkdir SRA: Este es el comando que se ejecutará en el sistema operativo. En este caso, se trata del comando mkdir, que se utiliza para crear directorios (carpetas) en el sistema de archivos. mkdir SRA significa que se intentará crear un directorio llamado “SRA” en el directorio actual. 3. unless (-e \"SRA\"): Esta parte de la línea es una condición que se evalúa antes de ejecutar el comando mkdir. La condición verifica si el directorio “SRA” no existe en el sistema de archivos. Para hacerlo, utiliza -e, que es un operador de archivo en Perl que verifica si un archivo o directorio existe. Si el directorio “SRA” no existe (unless significa “a menos que” o “si no”), entonces se ejecuta el comando mkdir SRA para crear el directorio. En resumen, la línea system \"mkdir SRA\" unless (-e \"SRA\"); comprueba si el directorio “SRA” ya existe en el sistema de archivos. Si no existe, crea el directorio utilizando el comando del sistema mkdir. Esto es útil para asegurarse de que un directorio necesario esté presente antes de realizar alguna operación que dependa de su existencia en tu script de Perl.\nA continuación: 1. El script entra en un bucle while que lee líneas del archivo abierto para lectura (I). Las líneas leídas se procesan de la siguiente manera: - Se eliminan los caracteres de retorno de carro \\r y las comillas dobles ” de cada línea. - Se extrae el valor entre paréntesis ( ) en la variable $sra. 2. Después, el script espera 2 segundos (con sleep 2) si no se encuentra un archivo con el nombre almacenado en $sra en el directorio actual o en el directorio “SRA”. Esto parece ser una pausa para dar tiempo a que el archivo se descargue antes de continuar. 3. Si el archivo no existe en ninguno de los dos directorios, se utiliza el comando system para descargar el archivo desde el sitio web del NCBI y guardarlo en el directorio “SRA”. 4. Luego, se abre el archivo recién descargado (SRA/\\$sra) y se procesa su contenido para extraer información relevante, como el número de lecturas, la cantidad de bases, el tipo de lecturas (pareadas o no), etc. 5. Se realiza una serie de transformaciones y cálculos en los datos extraídos, como la conversión de unidades de bases (K, M, G) a números enteros y el cálculo de la longitud promedio de las lecturas (\\$le). 6. Finalmente, se extraen más información de las variables \\$all_info1 y \\$all_info2, se formatea y se imprime en el archivo de salida (O) junto con otros datos procesados. 7. El script continúa procesando el siguiente conjunto de datos en el archivo de entrada hasta que se llega al final del archivo. 8. Finalmente, el script sale con la instrucción exit, lo que indica que ha terminado su tarea.\nEn resumen, este script se utiliza para descargar información sobre secuencias de ADN desde el NCBI, procesar esos datos y guardarlos en un archivo de salida para su posterior análisis."
  },
  {
    "objectID": "index.html#caso-1",
    "href": "index.html#caso-1",
    "title": "Como descargar datos de repositorios on-line",
    "section": "2.1 Caso 1",
    "text": "2.1 Caso 1\nEste primer caso es el que he estado utilizando como ejemplo hasta ahora mismo. Los datos serían los siguientes\n\n\n\nImagen 12\n\n\nSi nos fijamos tenemos un gran problema a resolver: El número de spots es muy bajo. SE significa que es Single End, es decir, que solo se ha hecho una lectura del fragmento (en dirección 3’-&gt;5’ por lo que el número de Spots es el número real de lecturas que se han hecho (luego veremos un ejemplo para Paird End, PE). Para un análisis adecuado de splicing alternativo necesitamos un mínimo de 100 M de spots (aunque podemos bajar a 75 M como mucho). Una posible solución es juntar muestras.\nOtro problema que tenemos con estos datos es que la Read_Average_Length tiene en algunas muestras menos de 50 y para un análisis de AS tenemos que tener una longitud de lectura de 50 de manera que esas muestras no las podemos utilizar, lo que reduce las posibilidades de poder llegar al mínimo al juntar las muestras.\nUna explicación más detallada del tratamiento de datos de este caso la podrás encontrar en la carpeta “Casos_Practicos_SA/Caso_1”."
  },
  {
    "objectID": "index.html#caso-2",
    "href": "index.html#caso-2",
    "title": "Como descargar datos de repositorios on-line",
    "section": "2.2 Caso 2",
    "text": "2.2 Caso 2\n\n\n\nImagen 13\n\n\nPodemos ver que en este caso no tenemos Library Name pero no pasa nada, no es imprescindible realmente. En este caso, la longitud de lectura es adecuada ya que todas tienen una media superior a 50. Tenemos una secuenciación SE (Single-End) de nuevo de manera que la Avg_Lenght es la que estamos viendo. Volvemos a tener el problema de tener un número de lecturas muy reducido pero en este caso cada muestra es una condición distinta de manera que agruparlas no sería correcto. En este caso no se podría realizar un análisis de SA."
  },
  {
    "objectID": "index.html#caso-3",
    "href": "index.html#caso-3",
    "title": "Como descargar datos de repositorios on-line",
    "section": "2.3 Caso 3",
    "text": "2.3 Caso 3\n\n\n\nImagen 14\n\n\nPodemos ver que en este caso no tenemos Library Name pero no pasa nada, no es imprescindible realmente. En este caso, tenemos una secuenciación Paird-end (PE) de manera que la longitud de lectura es adecuada es la mitad de lo que estamos viendo ya que en este tipo de secuenciación, la lectura se hace tanto en dirección 5’3’ como en dirección 3’5’. Este tipo de secuenciación es bastante más robusta y fiable que la SE. Todas tienen una media superior a 50 si dividimos el Avg_Lenght entre 2 (de hecho todos están sobre 80-90). Volvemos a tener el problema de tener un número de lecturas muy reducido pero en este caso si podemos intentar agrupar los pacientes mediante clustering no dirigido para agrupar en 3 y 4 aquellos que más se parezcan y así poder tener un análisis 2 vs 2. En este caso si se podría realizar un análisis de SA. Una explicación más detallada del tratamiento de datos de este caso la podrás encontrar en la carpeta “Casos_Practicos_SA/Caso_3”."
  },
  {
    "objectID": "index.html#caso-4",
    "href": "index.html#caso-4",
    "title": "Como descargar datos de repositorios on-line",
    "section": "2.4 Caso 4",
    "text": "2.4 Caso 4\n\n\n\nImagen 15\n\n\nEn este caso tenemos una cohorte de 8 pacientes todos ellos con la misma patología. Dado que no podemos ver condiciones entre ellos (a simple vista, podríamos buscar los fenotipos de los pacientes e identificar grupos de comparación) no es un buen ejemplo para comenzar a analizar."
  },
  {
    "objectID": "index.html#caso-5",
    "href": "index.html#caso-5",
    "title": "Como descargar datos de repositorios on-line",
    "section": "2.5 Caso 5",
    "text": "2.5 Caso 5\n\n\n\nImagen 16\n\n\nEn este caso, tenemos una secuenciación Paird-end (PE) de manera todas tienen una media superior a 50 si dividimos el Avg_Lenght entre 2 (de hecho todos están sobre 75). En este caso hay un número de lecturas bastante bueno, de entorno a 100 M todos ellos. En este caso se podría realizar un análisis de SA. De hecho es el mejor para empezar a practicar de manera que este será el Dataset que utilizaré para continuar el proceso y las explicaciones."
  },
  {
    "objectID": "RNAseq.html",
    "href": "RNAseq.html",
    "title": "Bulk RNAseq",
    "section": "",
    "text": "#Instalación de Mamba y Salmon (en terminal) En un primer momento íbamos a instalar Salmon (enlace a documentacion GitHub de Salmon) con Anaconda pero daba problemas a la hora de realizar la instalación de Salmon. Luego procedimos a la instalación de Mamba (Enlace a página de Mamaba y de e instalación) a través de Anaconda pero crasheaba en la instalación. Buscando en webs hemos encontrado que no es recomendable tener instalado Anaconda y Mamba a la vez de manera que hemos borrado los repositorios de Anacoda del servidor (y de miniconda, que tener miniconda y Anaconda no tenia ningún sentido porque Anaconda es más rápido y grande que miniconda de manera que era absurdo). Para eliminar tanto Anaconda (que se encontraba e la carpeta anaconda3) como Miniconda (que se encontraba en la carpeta miniconda3) hemos usado los siguientes comandos:\nrm -rf anaconda3/\nrm -rf miniconda3/\nYa podemos proceder a la instalación de Mamba. Es preferible la instalación de Mamba porque es como Anaconda pero con esteroides (según el bioinformático de Manuel Irimia). En primer lugar vamos a instalar Mamba:\ncurl -L -O \"https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-$(uname)-$(uname -m).sh\"\nA continuación podemos instalar el programa Salmon para el análisis de Bulk RNAseq con los siguientes comandos. Primero comprobamos qué versiones podemos instalar (para descargarnos la última versión):\nmamba search salmon\nNos saldrá un listado de versiones disponibles para la instalación de Salmon y tendremos que instalar la versión que queramos (en nuestro caso vamos a instalar la última versión, que corresponde a la 1.10.3):\nmamba create -n salmon salmon=1.10.2\nEs una buena práctica comprobar que se ha instalado de forma adecuada (activando Salmon y comprobando la versión:\nmamba activate salmon\nsalmon –version\nEl output será el siguiente:\nsalmon 1.10.2\nCerramos salmon:\nsalmon deactivate\nAdemás es buena práctica también comprobar que las instalaciones que hemos hecho previamente (en nuestro caso matt, vast-tools y SRA-Toolkit) no se han visto afectadas por la instalación de Mamba:\nvast-tools –help\nmatt –help\nfastq-dump --help\nYa podemos proceder a usar Salmon."
  },
  {
    "objectID": "RNAseq.html#generar-el-genoma-de-referencia",
    "href": "RNAseq.html#generar-el-genoma-de-referencia",
    "title": "Bulk RNAseq",
    "section": "1.1 Generar el genoma de referencia",
    "text": "1.1 Generar el genoma de referencia\nPara descarganos el genoma de referencia que queramos evaluar vamos a utilizar la base de datos Ensembl. En la web accedemos a la especie que queramos (en nuestro ejemplo Homo sapiens).\n\n\n\nImagen 1\n\n\nA continuación, es la sección de Gene_annotation seleccionamos la opción de descargarnos bases de datos en formato FASTA.\n\n\n\nImagen 2\n\n\nEsto nos llevará un repositorio donde tendremos distintas referencias del genoma:\n\nTranscritos (cdna/)\nRegiones codificantes (cds/)\nRegiones del genoma/cromosomas (dna/)\nParece un índice del anterior (dna/index)\nNon-coding RNA (ncrna/)\nPéptidos para proteómica (pep/)\n\n\n\n\nImagen 3\n\n\nLo habitual para cuantificar genes por RNAseq es descargarse los transcritos de manera que vamos a seleccionar “cdna/” y dentro de las opciones que hay en este en nuestro caso hemos elegido el indicado con rojo.\n\n\n\nImagen 4\n\n\nTenemos que clickar con el botón derecho y copiar la dirección de enlace para en nuestro terminal descargarnos este archivo con la función wget.\nLo más conveniente para llevar a cabo la descarga de genomas de referencia es crear una carpeta para esto, de manera que la creamos:\n\nmkdir Genome_Refs\n\nVamos a esta carpeta y usamos el comando wget:\n\nwget https://ftp.ensembl.org/pub/release-110/fasta/homo_sapiens/cdna/Homo_sapieCh38.cdna.all.fa.gz\n\nEsto nos descarga el .gz del genoma elegido en nuestra carpeta. Ahora generamos el índice con salmon:\n\nsalmon index -t Homo_sapiens.GRCh38.cdna.all.fa.gz -i Transcriptome_Index_Ref_Hsa_v38\n\nCon este comando decimos con “-t &lt;archivo.gz&gt;” el archivo que tiene que leer, que en nuestro caso es el que nos acabamos de descargar de Ensembl. Con el argumento -i  indicamos el nombre que le vamos a poner a este índice (el archivo que se va a generar). Es muy importante poner un nombre que permita discernir bien la especie, versión y tipo de alineamiento que permite hacer, en nuestro caso son todos los trancritos de la versión 38 del genoma humano así que le he puesto Transcriptome_Index_Ref_Hsa_v38. Este es el nombre que luego usaremos en la cuantificación. Ya que estaba me he dejado descargado los genomas de ratón (v.39) y rata (v.7.2) por si los necesitamos en algún momento."
  },
  {
    "objectID": "RNAseq.html#comprobar-la-calidad-de-las-muestras-secuenciadas-fastqc",
    "href": "RNAseq.html#comprobar-la-calidad-de-las-muestras-secuenciadas-fastqc",
    "title": "Bulk RNAseq",
    "section": "1.2 Comprobar la calidad de las muestras secuenciadas (fastQC)",
    "text": "1.2 Comprobar la calidad de las muestras secuenciadas (fastQC)\nEs de buena praxis comprobar la calidad de los resultados de la secuenciación debido a que esta puede introducir algún tipo de bias interno a la misma. Por ejemplo, un bias a corregir es el de contenido de GC, lo cual se corrige en el siguiente paso con salmon. Para correr un archivo hay que usar el siguiente comando:\n\nfastqc Basal_1_1.fastq.gz\n\nSi queremos que se nos guarde en un directorio, primero tenemos que crearlo de firma manual y luego utilizar el argumento -o &lt;nombre_del_directorio&gt;:\n\nmkdir resultados_fastqc\nfastqc -o resultados_fastqc Basal_1_1.fastq.gz\n\nEsto hace que se generen unos archivos HTML que nos llevará a una página en la que podemos ver la calidad de la muestra. Para conocer lo que significa cada uno de los apartados podemos acceder a este enlace y si queremos también tenemos un video tutorial donde se explica cada cosa. Si tenemos muchas muestras y queremos verlas todas juntas podemos utilizar la herramienta multiQC. Para utilizar esta herramienta la hemos instalado desde mamba y para ejecutarla (suponiendo que hemos generado la carpeta anterior “resultados_fastqc”) tenemos que ejecutar el comando seguido del nombre de la carpeta.\n\nmultiqc resultados_fastqc\n\nSi estamos en la misma carpeta donde se han generado todos los archivos fastqc (es decir, dentro de “resultados_fastqc” para nuestro ejemplo) el comando sería el siguiente:\n\nmultiqc .\n\n\n\n\n\n\n\nTip\n\n\n\n(hay un script hecho en el terminal para usarlo como plantilla para que lo haga automático todo)."
  },
  {
    "objectID": "RNAseq.html#alineamiento-y-cuantificación-con-salmon",
    "href": "RNAseq.html#alineamiento-y-cuantificación-con-salmon",
    "title": "Bulk RNAseq",
    "section": "1.3 Alineamiento y cuantificación con Salmon",
    "text": "1.3 Alineamiento y cuantificación con Salmon\nPara realizar la cuantificación tenemos que tener en cuenta el tipo de secuenciación que hemos realizado. La secuenciación para una muestra ha podido ser Single-End o Paired-End. Asimismo para una misma muestra se han podido secuenciar una única réplica o dos replicas para una mayor fiabilidad de la secuenciación. De esta manera, se han podido generar los siguientes archivos (se va a usar el nombre sample de ejemplo para explicar el número de archivos que podemos tener):\n\n\n\nImagen 5\n\n\nTeniendo esto en cuenta vamos a cuantificar nuestra muestras con la función “salmon quant” en el formato mapping-based mode (recordatorio de que tenemos que estar en el entorno salmon para hacer esto, el cual se activa con el comando “mamba actívate salmon” y que tenemos que estar en la carpeta donde tengamos las muestras descargadas). Para llevar a cabo la cuantificación el imput variará en función de la elección que hayamos cogido. Si hemos hecho Opción 1 o 2, es decir, solo hemos secuenciado una réplica de cada muestra, tenemos que usar el comando -r &lt;argumento&gt;. Para la Opción 1 el comando para la cuantificación sería el siguiente:\n\nsalmon quant -i transcripts_index -l A -r Sample_1.fastq.gz --validateMappings -o transcripts_quant\n\nDonde: - -i &lt;opción&gt;. Indica el genoma de referencia para hacer el mapeo (en nuestro ejemplo sería el nombre de la dirección del genoma humano que hemos descargado previamente, “/home/raul/Genome_Refs/Transcriptome_Index_Ref_Hsa_v38/”). Esta parte del comando será la misma para los siguientes opciones. - -l &lt;opción&gt;. Indica el formato en el que se han generado las librerías. Nosotros vamos a usar siempre la opción “A”, que es una opción de salmon que identifica el tipo de librería que hemos utilizado. Esta parte del comando será la misma para los siguientes opciones. - -r &lt;nombre_muestra&gt;. Aquí indicamos el nombre de nuestra muestra. Este argumento es el que variará posteriormente para analizar las distintas opciones. - --validateMapping. Permite que Salmon realice una validación adicional de los emparejamientos (mappings) entre las lecturas y las secuencias de referencia durante el proceso de cuantificación de expresión génica. Esta parte del comando será la misma para los siguientes opciones. - -o &lt;nombre_carpeta&gt;. Este argumento genera una carpeta con el nombre que pongamos tras el comando -o. Esta parte del comando será la misma para los siguientes\n\n\n\n\n\n\nTip\n\n\n\nNOTA: Si en el fastQC hemos tenido un enriquecimiento en GC tenemos que llevar a cabo una corrección de este error, de manera que tenemos que deberíamos añadir al comando anterior (independientemente de la opción de tipo de muestra que tengamos) el argumento --gcBias\n\n\nPara la Opción 2 el comando para la cuantificación sería el siguiente:\n\nsalmon quant -i transcripts_index -l A -1 Sample_1_1.fastq.gz -2 Sample_1_2.fastq.gz --validateMappings -o transcripts_quant\n\nDonde: - -i &lt;opción&gt;. Explicado en opción 1. - -l &lt;opción&gt;. Explicado en opción 1. - -1 &lt;nombre_muestra_1_1&gt;. Aquí indicamos el nombre del primer sentido de secuenciación de nuestra muestra.\n- -2 &lt;nombre_muestra_1_2&gt;. Aquí indicamos el nombre del segundo sentido de secuenciación de nuestra muestra. - --validateMapping. Explicado en opción 1. - -o &lt;nombre_carpeta&gt;. Explicado en opción 1.\nPara la Opción 3 el comando para la cuantificación sería el siguiente:\n\nsalmon quant -i transcripts_index -l A -r Sample_Rep1.fastq.gz Sample_Rep2.fastq.gz --validateMappings -o transcripts_quant\n\nDonde: - -i &lt;opción&gt;. Explicado en opción 1. - -l &lt;opción&gt;. Explicado en opción 1. - -r &lt;nombre_muestra_Replica_1 nombre_muestra_Replica_2&gt;. Aquí incluimos las dos replicas de nuestra muestra.\n- --validateMapping. Explicado en opción 1. - -o &lt;nombre_carpeta&gt;. Explicado en opción 1.\nPara la Opción 4 el comando para la cuantificación sería el siguiente:\nDonde: - -i &lt;opción&gt;. Explicado en opción 1. - -l &lt;opción&gt;. Explicado en opción 1. - -r &lt;nombre_muestra_Replica_1 nombre_muestra_Replica_2&gt;. Aquí incluimos las dos replicas de nuestra muestra. - -2 &lt;nombre_muestra_Replica_1_2 nombre_muestra_Replica_2_2&gt;. Aquí incluimos las dos segundas replicas de nuestra muestra. Es muy importante que las réplicas se ordenen igual que en el primer argumento -1. - --validateMapping. Explicado en opción 1. - -o &lt;nombre_carpeta&gt;. Explicado en opción 1.\nTras la explicación teórica, continuamos con nuestro archivo de ejemplo. Para procesar la primera muestra (Basal_1), el comando sería el siguiente:\n\nsalmon quant -i /home/raul/Genome_Refs/Transcriptome_Index_Ref_Hsa_v38/ -l A -1 Basal_1_1.fastq.gz -2 Basal_1_2.fastq.gz --validateMappings -o transcripts_quant\n\n\n\n\n\n\n\nCódigo para todas las muestras a la vez\n\n\n\n\n\nPara correr todas las muestras a la vez tenemos la opción de crear un script sencillito de bash para que se ejecuten todas las muestras que tenemos. Lo más cómodo es abrir un entorno screen para trabajar allí y luego poder desvincularlo por si nos tenemos que ir o algo, para que no se pare. Una vez abierto el screen, tenemos que abrir el entono salmon (mamba actívate salmon). Los pasos son los siguientes:\n\nCrear el script con el editor de texto nano\n\n\nnano run_Salmon_Mapping.bash\n\n\nEsto nos abre una pantalla en la que podemos escribir, ahí podremos escribir las funciones que queramos que se ejecuten:\n\n\n#!/bin/bash\n\n# Comando para procesar el archivo 1\nsalmon quant -i /home/raul/Genome_Refs/Transcriptome_Index_Ref_Hsa_v38/ -l A -1 Basal_1_1.fastq.gz -2 Basal_1_2.fastq.gz --validateMappings -o transcripts_quant/Basal_1\n\necho \"Basal_1 procesado\"\n\n# Comando para procesar el archivo 2\nsalmon quant -i /home/raul/Genome_Refs/Transcriptome_Index_Ref_Hsa_v38/ -l A -1 Basal_2_1.fastq.gz -2 Basal_2_2.fastq.gz --validateMappings -o transcripts_quant /Basal_2\n\necho \"Basal_2 procesado\"\n\n# Comando para procesar el archivo 3\nsalmon quant -i /home/raul/Genome_Refs/Transcriptome_Index_Ref_Hsa_v38/ -l A -1 Basal_3_1.fastq.gz -2 Basal_3_2.fastq.gz --validateMappings -o transcripts_quant/Basal_3\n\necho \"Basal_3 procesado\"\n\n# Comando para procesar el archivo 4\nsalmon quant -i /home/raul/Genome_Refs/Transcriptome_Index_Ref_Hsa_v38/ -l A -1 Luminal_1_1.fastq.gz -2 Luminal_1_2.fastq.gz --validateMappings -o transcripts_quant/Luminal_1\n\necho \"Luminal_1 procesado\"\n\n# Comando para procesar el archivo 5\nsalmon quant -i /home/raul/Genome_Refs/Transcriptome_Index_Ref_Hsa_v38/ -l A -1 Luminal_2_1.fastq.gz -2 Luminal_2_2.fastq.gz --validateMappings -o transcripts_quant Luminal_2\n\necho \"Luminal_2 procesado\"\n\n# Comando para procesar el archivo 6\nsalmon quant -i /home/raul/Genome_Refs/Transcriptome_Index_Ref_Hsa_v38/ -l A -1 Luminal_3_1.fastq.gz -2 Luminal_3_2.fastq.gz --validateMappings -o transcripts_quant/Luminal_3\n\necho \"Luminal_3 procesado\"\n\necho \"Procesamiento completado para todos los archivos\"\n\n\nEsto hará que se procese un archivo tras otro y se vaya guardando en una subcarpeta dentro de la carpeta que se va a crear transcripts_quant/subcarpeta_por_muestra, porque sino se sobreescribirá siempre la misma carpeta (habla la voz de la experiencia amigo/a….) y que cada vez que acabe un archivo nos salga un mensaje de que ya está procesado y cuando acaba nos dirá que ya se ha completado el proceso. Para guardar el archivo sigue estos pasos: 1) Presiona Ctrl + O (mantén presionada la tecla Control y luego presiona la letra “O”). Te preguntará File Name to Write. Presiona “Enter” para confirmar el nombre del archivo; 2) Para salir del editor nano, presiona Ctrl + X.\n\n\nPara ejecutar el archivo debemos asegurarnos de tener los permisos de ejecución del script:\n\n\nChmod +x run_Salmon_Mapping.bash\n\n\nYa podemos ejecutar el script (debemos de estar en la carpeta que lo contenga y tener el entorno de salmon abierto con (mamba actívate salmon))\n\n\n./run_Salmon_Mapping.bash\n\nTras esto podremos hacer Ctrl + a + d para desvincular la sesión de screen y esperar a que acabe.\n\n\n\nLos archivos quant.sf van a tener el siguiente contenido:\n\n\n\nImage 6\n\n\nLas columnas tienen la siguiente interpretación. - Name - Es el nombre del transcrito objetivo proporcionado en la base de datos de transcritos de entrada (archivo FASTA). - Length - Es la longitud del transcrito objetivo en nucleótidos. - EffectiveLength - Es la longitud efectiva calculada del transcrito objetivo. Tiene en cuenta todos los factores que se están modelando y que afectarán a la probabilidad de muestreo de fragmentos de este transcrito, incluyendo la distribución de la longitud del fragmento y el sesgo específico de la secuencia y del fragmento gc (si se están modelando). - TPM - Es la estimación del salmón de la abundancia relativa de este transcrito en unidades de Transcritos Por Millón (TPM). TPM es la medida de abundancia relativa recomendada para el análisis posterior. - NumReads - Es la estimación de Salmon del número de lecturas que corresponden a cada transcrito cuantificado. Es una “estimación” en la medida en que es el número esperado de lecturas que se han originado a partir de cada transcrito dada la estructura de las lecturas de mapeo único y mapeo múltiple y las estimaciones de abundancia relativa para cada transcrito.\n\n\n\n\n\n\nNote\n\n\n\nTodo lo hecho a partir de aquí está en:\nTerminal_9-20-23.txt\n\n\nEl siguiente paso va a ser unir todos los archivos .sf en el que tenemos la cuantificación de cada una de las muestras para generar la matriz de datos para hacer los análisis.\nAl haber comparado con el transcriptoma de referencia, lo que nos va a generar salmon con cada uno de los archivos .sf es literalmente el transcriptoma, es decir, todos los transcritos de cada uno de los genes. Esto no es correcto analizarlo directamente. Es útil tener la información de cada uno de los transcritos de cada gen (especialmente si luego vamos a comparar con splicing alternativo) pero lo verdaderamente correcto es resumir y poner en conjunto la información de todos los transcrito para ver la expresión del gen en concreto. Para hacer esto tenemos que descargarnos un paquete de R que lo hace automáticamente. Además este paquete crea una matriz con todos los genes (en las filas) y todas las muestras que hemos analizado (en columnas) con salmon de manera que estaremos evaluando correctamente la expresión génica."
  },
  {
    "objectID": "RNAseq.html#importar-datos",
    "href": "RNAseq.html#importar-datos",
    "title": "Bulk RNAseq",
    "section": "3.1 Importar datos",
    "text": "3.1 Importar datos\nUna vez que hemos termimado de extraer las counts con salmon en el terminal y hemos generado un .csv con la expresión tenemos que instalar DESeq2, que es la herramienta que vamos a utilizar para normalizar y graficar los datos que hemos obtenido.\nPrimero instalamos todos lo paquetes que vamos a necesitar:\n\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(\"DESeq2\", dependencies = TRUE)\ninstall.packages(\"ggplot2\", dependencies = TRUE)\n#los siguientes paquetes son para representaciones y gestión de datos\ninstall.packages(\"pheatmap\", dependencies = TRUE)\ninstall.packages(\"RColorBrewer\", dependencies = TRUE)\ninstall.packages(\"tidyverse\", dependencies = TRUE)\nBiocManager::install(\"ashr\", dependencies = TRUE)\ninstall.packages(\"ggrepel\")\nBiocManager::install(\"EnsDb.Hsapiens.v86\", dependencies = TRUE)                \nBiocManager::install(\"biomaRt\", dependencies = TRUE)\nBiocManager::install(\"PCAtools\")\ninstall.packages(\"magick\")\n\nY cargamos las bibliotecas:\n\nlibrary(DESeq2)\nlibrary(ggplot2)\n#los siguientes paquetes son para representaciones de datos\nlibrary(pheatmap)\nlibrary(RColorBrewer)\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(ashr)\nlibrary(ggrepel)\nlibrary(EnsDb.Hsapiens.v86)\nlibrary(biomaRt)\nlibrary(PCAtools)\nlibrary(magick)\n\nAhora podemos cargar los datos que hemos generado el .csv:\n\n\n./Data/Basal_vs_Luminal_GC.csv\n\n\n\n\n\n\n\n\n\n\n\n\nBasal_1\nBasal_2\nBasal_3\nLuminal_1\nLuminal_2\nLuminal_3\n\n\n\n\nENSG00000000003\n3063.523\n2595.819\n1858.888\n5484.804\n5835.183\n5282.971\n\n\nENSG00000000005\n0.000\n1.000\n3.000\n0.000\n0.000\n0.000\n\n\nENSG00000000419\n5789.018\n3872.824\n4193.611\n4048.758\n2490.729\n3660.102\n\n\nENSG00000000457\n2009.020\n1613.409\n1420.251\n3384.663\n2402.486\n2763.960\n\n\nENSG00000000460\n614.459\n400.559\n455.363\n826.121\n505.659\n613.572\n\n\nENSG00000000938\n18.000\n93.000\n26.000\n9.000\n33.000\n8.000\n\n\n\n\n\n\n\n\n\n\nFormato de la metadata\n\n\n\nTenemos que crear un .csv de metada para poder analizar las distintas variables. Este archivo lo podemos crear mediante excel, en el cual en la primera columna tiene que estar el id de las muestras (el nombre que hayamos puesto a la muestra durante el análisis con salmon) y en el resto de columnos vamos metiendo variables de análisis. La primera fila tiene que tener el encabezado de la columna. Tenemos que asegurarnos de guardarlo en .csv y modificarlo desde el editor de texto para que esté verdaderamente separado con comas (ya que al crearlo en excel se nos guardará separado por “;”, en definitiva es hacer lo mismo que cuando queremos cargar algo en metaboanalyst).\n\n\nAhora podemos cargar el archivo que hemos creado con la metadata de las muestras. Tenemos que convertir en factor todas las variables que lo sean (no he probado con variables continuas):\n\nmetaData &lt;- as.data.frame(read.csv('./Data/Metadata_Basal_vs_Luminal.csv', header = TRUE, row.name=1, sep = \",\"))\nmetaData[,c(1:ncol(metaData))]&lt;-as.factor(metaData[,c(1:ncol(metaData))])\nhead(metaData)\n\n          cell_type\nBasal_1       Basal\nBasal_2       Basal\nBasal_3       Basal\nLuminal_1   Luminal\nLuminal_2   Luminal\nLuminal_3   Luminal\n\n\nVamos a introducir un paso de checkeo de que los nombres de las columnas de la matriz de datos y los nombre de las filas de matriz de MetaData están en el mismo orden para así estar seguros de que se van a cargar bien en el paquete:\n\nall(rownames(metaData) == colnames(countData))\n\n[1] TRUE\n\n\nA continuación vamos a crear el dataframe que contendrá el análisis con el siguiente comando:\n\ndds &lt;- DESeqDataSetFromMatrix(countData=round(countData), \n                              colData=metaData, \n                              design=~cell_type)\n\nconverting counts to integer mode\n\n\nCon el argumento countData definimos la variable en la que tenemos guardada la matriz de expresión de cada uno de los genes. Con el argumento colData vamos a definir el archivo en el que tenemos la metadata de las muestras. Con el argumento desing= vamos a definir cómo vamos a crear los grupos de comparación. Para ello tenemos que poner la virgulilla, es decir, “~” seguido del nombre de la columna que contenga la variable diferencial en la que basarse para crear los grupos. Si tuvieramos más grupos de interés para incluir en el análisis (tienen que estar incluidos en el archivo metadata) deberíamos añadirlos como en el siguiente ejemplo:\n\ndds &lt;- DESeqDataSetFromMatrix(countData=round(countData), \n                              colData=metaData, \n                              design=~cell_type + tissue + sex + age)\n\ncon este ejemplo, imaginando que pueden ser células de cualquier tejido, la comparación se calculará para tipo de células (cell_type), para el tipo de tejido (tissue), para el sexo del individuo (sex) y para la edad del mismo (age)."
  },
  {
    "objectID": "RNAseq.html#preprocesamiento-prefiltrado",
    "href": "RNAseq.html#preprocesamiento-prefiltrado",
    "title": "Bulk RNAseq",
    "section": "3.2 Preprocesamiento (prefiltrado)",
    "text": "3.2 Preprocesamiento (prefiltrado)\nSi bien no es necesario filtrar previamente los genes de conteo bajo antes de ejecutar las funciones de DESeq2, hay dos razones que hacen que el filtrado previo sea útil: al eliminar filas en las que hay muy pocas lecturas, reducimos el tamaño de la memoria del objeto de datos dds, y aumentamos la velocidad del modelado de conteo dentro de DESeq2. También puede mejorar las visualizaciones, ya que las características sin información para la expresión diferencial no se trazan en diagramas de dispersión o diagramas MA.\nAquí realizamos un filtrado previo para mantener solo las filas que tienen un recuento de al menos 10 para una cantidad mínima de muestras. El recuento de 10 es una opción razonable para la secuenciación de ARN masiva. Una recomendación para el número mínimo de muestras es especificar el tamaño de grupo más pequeño; por ejemplo, aquí hay 3 muestras tratadas. Si no hay grupos discretos, se puede utilizar el número mínimo de muestras donde los recuentos distintos de cero se considerarían interesantes. También se puede omitir este paso por completo y simplemente confiar en los procedimientos de filtrado independientes.\n\nsmallestGroupSize &lt;- 3\nkeep &lt;- rowSums(counts(dds) &gt;= 10) &gt;= smallestGroupSize\ndds &lt;- dds[keep,]\n\nA continuación es importante establecer cuál va a ser el grupo de control de los que tenemos (en nuestro caso van a ser las células basales):\n\ndds$condition&lt;-relevel(dds$cell_type, ref=\"Basal\")\n\nEl análisis de expresión diferencial propiamente dicho lo hacemos con la función DESeq(), y ya calcula muchas cosas (de forma automática) de las que vamos a ir viendo ahora. Pero para mejorar el entendimiento del trabajo con los datos no vamos a adelantar aconteciminetos, así que por ahora no lo vamos a usar y vamos a ver como se normalizan estos datos.\nLa función DESeq() realiza de forma automática los siguientes análisis:\n\nEstimar los “size factors” (el peso que tiene en la dispersión de los valores de cada muestra la variable que estamos utilizando para la comparación)\nEstimar la dispersión génica (como aumenta la variabilidad en función del número de transcritos, esto es intrínseco a la metodología de manera que hay que corregirlo)\nCorregir la dispersión génica (se realiza con estimaciones con respecto al modelo al que debería ajustarse la disperisón de los datos, pero como toda estimación, necesita ser corregiva para evitar sobreestimaciones, es decir, falsos positivos)\nReducción de las estimaciones de la dispersión por la corrección"
  },
  {
    "objectID": "RNAseq.html#análisis-de-calidad-de-las-muestras-qc-analyses",
    "href": "RNAseq.html#análisis-de-calidad-de-las-muestras-qc-analyses",
    "title": "Bulk RNAseq",
    "section": "3.3 Análisis de calidad de las muestras (QC Analyses)",
    "text": "3.3 Análisis de calidad de las muestras (QC Analyses)\nLos siguientes pasos son la normalización y análisis no supervisado de las muestras para evaluar la calidad de las mismas.\n\n3.3.1 Normalización\nVamos a seguir los pasos del workshop de Harvard que encontré (que está genial), en este caso vamos a usar el archivo Introduction to DGE donde está super bien explicado a nivel teórico (con esquemas y todo). Si queremos mayor profundidad a nivel matemáticod beremos acceder a la vignette de DESeq2. El primer paso de todo análisis de expresión diferencial es una normalización de los counts para que la comparación entre muestras sea más certera y fiable. Los pricipales factores que se deben de considerar para la normalización son:\n\nProfuncidad de la secuenciación\nLongitud del gen\nComposición del RNA\n\nEstos términos están perfectamente explicados en Introduction to DGE, además incluye una tabla con los métodos de normalización para RNAseq con ventajas y desventajas.\nDESeq2 utiliza un método de normalización de las counts dividads por factores de tamaño específicos de la muestra determinados por la relación mediana de los recuentos de genes en relación con la media geométrica por gen. Esta normalización hace que sea muy potente para la el análsis de expresión diderencial, pero no lo podemos utilizar para una comparación entre genes de una misma muestra\n\n\n\n\n\n\nNote\n\n\n\n(para eso deberíamos utilizar la expresión normalizada por TPM, es decir, utilizar la matriz de tximpor recupenrando los datos de la columna de “abundancia”). Perfectamente explicado, de nuevo, en Introduction to DGE.\n\n\nPara acceder a los size factors si hubieramos utilizado la función DESeq() podriamos utilizar la función sizeFactors directamente:\n\n#hacemos el análisis y lo definimos en la varibale dds_DEs\ndds_DEs&lt;-DESeq(dds)\n#y ahora extraeríamos los datos\nsizeFactors(dds_DEs)\n\nPero como todavía NO hemos utilizado todavía la función DEseq() y queremos averiguar los “size factors” de nuestra matriz, primero temnemos que usar la función estimateSizeFactors() para calcular dichos factores e incluirlos en el data frame dds. El código sería el siguiente:*\n\n#Calculamos los factores y lo metemos en la variable dds\ndds &lt;- estimateSizeFactors(dds)\n#y ahora podríamos acceder a esos datos\nsizeFactors(dds)\n\n  Basal_1   Basal_2   Basal_3 Luminal_1 Luminal_2 Luminal_3 \n1.1167981 1.0037478 0.9737041 1.0030643 0.9418799 0.9892795 \n\n\nAhora podríamos extraer los datos normalizados (con la función counts() en una matriz de datos distinta para así poder trabajar con ellos:\n\nnormalized_counts&lt;-counts(dds, normalized=TRUE)\nhead(normalized_counts)\n\n                   Basal_1    Basal_2    Basal_3   Luminal_1  Luminal_2\nENSG00000000003 2743.55778 2586.30696 1909.20427 5468.243490 6195.05740\nENSG00000000419 5183.56918 3858.53884 4307.26343 4036.630427 2644.71088\nENSG00000000457 1798.89281 1606.97732 1458.34861 3374.658927 2550.21900\nENSG00000000460  549.78606  399.50273  467.28776  823.476595  537.22349\nENSG00000000938   16.11751   92.65275   26.70216    8.972505   35.03631\nENSG00000000971 4315.91008 3637.36776 2018.06691 6813.122335 3766.93464\n                  Luminal_3\nENSG00000000003 5340.250419\nENSG00000000419 3699.662414\nENSG00000000457 2793.952709\nENSG00000000460  620.653749\nENSG00000000938    8.086694\nENSG00000000971 2155.103898\n\n\nVamos a extraer estos datos normalizados en un archivo para utilizarlos más adelante:\n\nwrite.csv(normalized_counts, file=\"./Data/normalized_counts.csv\")\n\n\n\n\n\n\n\nNote\n\n\n\nDESeq2 no utiliza realmente counts normalizadas, sino que utiliza los counts brutos y modela la normalización dentro del Modelo Lineal Generalizado (GLM). Estos recuentos normalizados serán útiles para la visualización posterior de los resultados, pero no se pueden utilizar como entrada para DESeq2 o cualquier otra herramienta que realice análisis de expresión diferencial que utilice el modelo binomial negativo.\n\n\n\n\n3.3.2 Análisis de clustering no supervisado\nPara realizar el análisis de calidad de las muestras necesitamos la matriz de datos normalizados. DESeq incluye una función propia de normalización de datos muy robusta y aceptada por la comunidad, que si quereis saber cómo funciona podeis ir a la vignette de DESeq2 o a la página que os recomendé al principio que explica todo el workflow, es este caso a la sección de “QC Analysis” y leerlo: En mi caso he usado una combinación de ambas cosas para evaluar más parámetros. Para ejecutarla:\n\nrld &lt;- rlog(dds, blind=FALSE)\n\nEl argumento blind= es para saber si la transformación debe ser ciega a la información de la muestra especificada por la fórmula de diseño. Cuando ciego es igual a TRUE (por defecto), las funciones reestimarán las dispersiones utilizando sólo un intercepto. Este argumento debería utilizarse para comparar muestras de una manera totalmente insesgada por la información sobre los grupos experimentales, por ejemplo para realizar el aseguramiento de la calidad de la muestra, como se demuestra a continuación.\nSin embargo, la estimación de la dispersión ciega no es la opción adecuada si se espera que muchos o la mayoría de los genes (filas) tengan grandes diferencias en los recuentos que puedan explicarse por el diseño experimental, y se desea transformar los datos para un análisis posterior. En este caso, el uso de la estimación ciega de la dispersión dará lugar a grandes estimaciones de la dispersión, ya que atribuye las diferencias debidas al diseño experimental como ruido no deseado, y dará lugar a una reducción excesiva de los valores transformados entre sí. Estableciendo ciego a FALSE, las dispersiones ya estimadas se utilizarán para realizar las transformaciones, o si no están presentes, se estimarán utilizando la fórmula de diseño actual. Tenga en cuenta que en la transformación sólo se utilizan las estimaciones de dispersión ajustadas de la línea de tendencia media-dispersión (la dependencia global de la dispersión respecto a la media para todo el experimento). Por lo tanto, establecer ciego a FALSE sigue siendo, en su mayor parte, no utilizar la información sobre qué muestras estaban en qué grupo experimental en la aplicación de la transformación.\nEn resumen, que seleccionemos FALSE.\nNOTA: La función rlog() puede ser un poco lenta cuando se tienen, por ejemplo, &gt; 20 muestras. En estas situaciones, la función vst() es mucho más rápida y realiza una transformación similar apropiada para su uso para análisis de calidad.\n\n3.3.2.1 Barplot\nCon estas gráficas vamos a mostrar el nº de counts totales para cada muestra para asegurarnos de que no están muy dispares, por lo que se utilizan los datos importados del .csv previos a la normalización (ya que solo queremos counts). para ello tenemso que trasformar los datos a dos columnas (x, el cual va a ser el nombre de la muestra, e y, que va a ser el valor de la suma de los counts de cada muestra) que son las que utilizaremos para realizar el gráfico:\n\n#Para llevar a cabo esta parte tenemos que instalar y cargar el paquete tidyverse\nsum_CD&lt;-as.data.frame(normalized_counts) %&gt;%\n  gather(columname, values) %&gt;%\n  group_by(columname) %&gt;%\n  summarize(Count_sum=sum(values))\n#\nggplot(sum_CD, aes(x=as.factor(columname), y=Count_sum))+\n  geom_bar(stat=\"identity\")+\n  ggtitle(\"Total number of counts\")+\n  xlab(\"Muestras\")+\n  ylab(\"Normalized counts\")+\n  theme(legend.position=\"right\")+\n  geom_text(aes(label=round(Count_sum)), color=\"white\", vjust=1.6, size=4)\n\n\n\n\nUna alternativa (simplemente para ver el explorar el uso de ggplot():\n\nsum_CD&lt;-as.data.frame(normalized_counts) %&gt;%\n  gather(columname, values) %&gt;%\n  group_by(columname) %&gt;%\n  summarize(Count_sum=sum(values))\n\n#tenemos que tranformar los datos para que sea interpretable por ggplot\nggplot(sum_CD, aes(x=as.factor(columname), y=Count_sum, fill=Count_sum))+\n     geom_bar(stat=\"identity\") +\n     scale_fill_gradientn(colors=pals::brewer.greens(15),\n                           lim=c(0,max(sum_CD$Count_sum)))+\n     ggtitle(\"Total number of counts\")+\n     xlab(\"Muestras\")+\n     ylab(\"Raw counts\")+\n     theme(legend.position=\"right\")+\n     geom_text(aes(label=round(Count_sum)), color=\"white\", vjust=1.6, size=3)\n\n\n\n\nSi quisieramos guardar la anterior gráfica como un documento tendremos que usar la función ggsave(), guardando la gráfica en una variable barplotcounts:\n\nbarplotcounts&lt;-ggplot(sum_CD, aes(x=as.factor(columname), y=Count_sum, fill=Count_sum))+\n  geom_bar(stat=\"identity\") +\n     scale_fill_gradientn(colors=pals::brewer.greens(15),\n                           lim=c(0,max(sum_CD$Count_sum)))+\n     ggtitle(\"Total number of counts\")+\n     xlab(\"Muestras\")+\n     ylab(\"Raw counts\")+\n     theme(legend.position=\"right\")+\n     geom_text(aes(label=round(Count_sum)), color=\"white\", vjust=1.6, size=3)\n\nggsave(barplotcounts,filename=\"barplotcounts.pdf\", device=pdf)\n\n\n\n3.3.2.2 boxplot\nTambien podemos hacer un boxplot de los counts de las muestras normalizadas con (log10(count)+1) y ver la distribución. Esto lo podemos hacer con la función boxplot:\n\nboxplot(log10(normalized_counts)+1,\n  main=\"Boxplot\", xlab=\"Muestras\", ylab=\"Normalized counts Log10(Counts)+1\")\n\n\n\n\nO con ggplot(), Pero para hacerlo con ggplot primero necesitamos crear una matriz interpretable por ggplot para generar el gráfico. Para ello vamos a usar el paquete tidyvese(), que generará una matriz de datos que podremos utilizar (transformación a matriz larga):\n\n#definimos la normalización para la representación como una variable independiente para trabajar de forma más sencilla.\nnormcounts&lt;-as.data.frame(log10(normalized_counts)+1)\n\n#a continuación creamos la matriz larga\nlong_df&lt;-normcounts %&gt;%\n  rownames_to_column(var=\"rowname\") %&gt;%\n  gather(columname, value, -rowname)\n#definimos el nombre de las columnas\ncolnames(long_df)&lt;-c(\"Ensembl_ID\", \"Samples\", \"Expression\")\n#también tenemos que definir las muestras como un factor para que boxplot funcione bien\nlong_df$Samples&lt;-as.factor(long_df$Samples)\n\n#ahora graficamos con ggplot\nggplot(long_df, aes(x=Samples, y=Expression)) + geom_boxplot() +\n  ggtitle(\"Boxpot\") +\n  xlab(\"Samples\") + ylab(\"Normalized expression \\n log(counts)+1\")\n\n\n\n\nCon ggplot es mucho más manejable el hacer gráficos.\n\n\n3.3.2.3 PCA plot\nDESe2 utiliza el paquete ggplot2 para generar gráficos. Para poder hacer el gráfico por defecto necesitamos los datos normalizados (lo que hemos hecho con la función rlog()). Por defecto podemos hacer una gráfica sencilla:\n\nplotPCA(rld, intgroup=\"cell_type\")\n\n\n\n\nTambién podemos customizar la gráfica con funciones del paquete ggplot2:\n\npcaData &lt;- plotPCA(rld, intgroup=c(\"cell_type\", \"cell_type\"), returnData=TRUE)\npercentVar &lt;- round(100 * attr(pcaData, \"percentVar\"))\nggplot(pcaData, aes(PC1, PC2, color=cell_type, shape=cell_type)) +\n  ggtitle(\"PCA plot of example \\n RNAseq\")+\n  geom_point(size=3) +\n  xlab(paste0(\"PC1 (\",percentVar[1],\"%)\")) +\n  ylab(paste0(\"PC2 (\",percentVar[2],\"%)\")) + \n  coord_fixed()\n\n\n\n\n\n\n3.3.2.4 Heatmap\nTambién es común utilizar un heatmap para la visualización de la calidad de las muestras para ver como clusterizan:\n\n#para utilizar esta función hemos tenido que instalar y cargar el paquete pheatmap\nselect&lt;-order(rowMeans(normalized_counts),decreasing=TRUE)[1:25]\ndf &lt;- metaData\npheatmap(assay(rld)[select,], cluster_rows=FALSE, show_rownames=FALSE,\n         cluster_cols=TRUE, annotation_col=df, main=\"Heatmap plot\")\n\n\n\n\nSi tuvieramos mayor cantidad de datos clínicos o variables en metadata podríamos añadirlos de la siguiente manera (yo voy a repetir el mismo tipo de datos dos veces):\n\n#voy a crear una nueva metadata que tenga dos veces la misma columna de cell_type para mostrar el ejemplo\nmetaData_ejm &lt;- metaData\nmetaData_ejm[,2]&lt;- metaData[, 1]\ncolnames(metaData_ejm)[2]&lt;- c(\"variable imaginaria\")\n#y ahora haríamos el heatmap\nselect&lt;-order(rowMeans(normalized_counts),decreasing=TRUE)[1:500]\n#en el df tenemos que meter las variables de nuestra metaData que queramos ver\ndf &lt;- metaData_ejm[,c(1, 2)]\npheatmap(assay(rld)[select,], cluster_rows=FALSE, show_rownames=FALSE,\n         cluster_cols=FALSE, annotation_col=df, main=\"Heatmap plot\")\n\n\n\n\nHay muchas posibilidades, buscad el paquete en google y consultais los argumentos para manipular los datos al gusto.\n\n\n3.3.2.5 Distancia entre muestras\nOtro uso de los datos transformados es la agrupación de muestras. En este caso, aplicamos la función dist() a la transposición de la matriz de recuento transformada para obtener distancia muestra-muestra:\n\nsampleDists &lt;- dist(t(assay(rld)))\n\nA continuación, si solo tenemos las muestras con una condición queremos enfrentar las muestras contra ellas mismas de manera que haríamos lo siguiente:\n\nsampleDistMatrix &lt;- as.matrix(sampleDists)\nrownames(sampleDistMatrix) &lt;- rld@colData@rownames\ncolnames(sampleDistMatrix) &lt;- rld@colData@rownames\ncolors &lt;- colorRampPalette( rev(brewer.pal(9, \"Blues\")) )(255)\npheatmap(sampleDistMatrix,\n         clustering_distance_rows=sampleDists,\n         clustering_distance_cols=sampleDists,\n         col=colors)\n\n\n\n\nSi tuvieramos dos o más condiciones descriptivas (en mi caso voy a repetir dos veces el tipo celular para que se pueda ver cómo se usaría el código para emparejar variables para la comparación):\n\n#Para estos colores hemos tenido que instalar y cargar el paquete \"RColorBrewer\"\nsampleDistMatrix &lt;- as.matrix(sampleDists)\nrownames(sampleDistMatrix) &lt;- paste(rld$cell_type, rld$cell_type, sep=\"-\")\ncolnames(sampleDistMatrix) &lt;- NULL\ncolors &lt;- colorRampPalette( rev(brewer.pal(9, \"Blues\")) )(255)\npheatmap(sampleDistMatrix,\n         clustering_distance_rows=sampleDists,\n         clustering_distance_cols=sampleDists,\n         col=colors)\n\n\n\n\nEn el heatmap podemos ver las distancias, lo que nos da una overview sobre similaridades y diferencias entre muestras."
  },
  {
    "objectID": "RNAseq.html#análisis-de-expresión-diferencial-de-analysis",
    "href": "RNAseq.html#análisis-de-expresión-diferencial-de-analysis",
    "title": "Bulk RNAseq",
    "section": "3.4 Análisis de Expresión diferencial (DE analysis)",
    "text": "3.4 Análisis de Expresión diferencial (DE analysis)\nBrevemente, DESeq2 modelará los recuentos brutos, utilizando factores de normalización (factores de tamaño) para tener en cuenta las diferencias en la profundidad de las bibliotecas. A continuación, estimará las dispersiones por genes y reducirá estas estimaciones para generar estimaciones más precisas de la dispersión para modelar los recuentos. Por último, DESeq2 ajustará el modelo binomial negativo y realizará pruebas de hipótesis utilizando el test de Wald o Likelihood Ratio Test (prueba de razón de verosimilitud).\nLa función DESeq() realiza de forma automática los siguientes análisis:\n\nEstimar los “size factors” (el peso que tiene en la dispersión de los valores de cada muestra la variable que estamos utilizando para la comparación)\nEstimar la dispersión génica (como aumenta la variabilidad en función del número de transcritos, esto es intrínseco a la metodología de manera que hay que corregirlo)\nCorregir la dispersión génica (se realiza con estimaciones con respecto al modelo al que debería ajustarse la disperisón de los datos, pero como toda estimación, necesita ser corregiva para evitar sobreestimaciones, es decir, falsos positivos)\nReducción de las estimaciones de la dispersión por la corrección\n\n\ndds_DEs&lt;-DESeq(dds)\n\nusing pre-existing size factors\n\n\nestimating dispersions\n\n\ngene-wise dispersion estimates\n\n\nmean-dispersion relationship\n\n\nfinal dispersion estimates\n\n\nfitting model and testing\n\nhead(dds_DEs)\n\nclass: DESeqDataSet \ndim: 6 6 \nmetadata(1): version\nassays(4): counts mu H cooks\nrownames(6): ENSG00000000003 ENSG00000000419 ... ENSG00000000938\n  ENSG00000000971\nrowData names(22): baseMean baseVar ... deviance maxCooks\ncolnames(6): Basal_1 Basal_2 ... Luminal_2 Luminal_3\ncolData names(3): cell_type condition sizeFactor\n\n\n\n3.4.1 Modelado de las counts para cada gen y Fold changes corregidos\n\n3.4.1.1 Generación de un modelo linaear de ajuste para cada gen\nEl último paso del flujo de trabajo de DESeq2 es ajustar el modelo binomial negativo para cada gen y realizar pruebas de expresión diferencial.\nComo se ha comentado anteriormente, los datos de recuento generados por RNA-seq presentan sobredispersión (varianza &gt; media) y la distribución estadística utilizada para modelar las “counts” debe tener en cuenta esta sobredispersión. DESeq2 utiliza una distribución binomial negativa para modelar los recuentos de RNA-seq.\nEl modelado es una forma matemática de aproximar cómo se comportan los datos dado un conjunto de parámetros (es decir, factor de tamaño, dispersión). DESeq2 utilizará esta fórmula como modelo para cada gen y ajustará a ella los datos de “counts” normalizados. Una vez ajustado el modelo, se estiman los coeficientes para cada grupo de muestras junto con su error estándar.\nLos coeficientes son las estimaciones de los cambios de log2 para cada grupo de muestras. Sin embargo, estas estimaciones no tienen en cuenta la gran dispersión que observamos en los recuentos bajos de lecturas. Para evitarlo, es necesario ajustar los cambios de pliegue log2 calculados por el modelo.\n\n\n3.4.1.2 Shrunken Log2 Foldchanges (LFC)\nPara generar una estimación más precisa de log2 Fold Change (LFC), DESeq2 permite la reducción de las estimaciones LFC hacia cero cuando la información de un gen es baja:\n\nPocas counts\nElevados valores de dispersión\n\nAl igual que con la reducción de las estimaciones de dispersión, la reducción de LFC utiliza información de todos los genes para generar estimaciones más precisas. En concreto, la distribución de las estimaciones de LFC para todos los genes se utiliza (como un prior) para encoger las estimaciones de LFC de los genes con poca información o alta dispersión hacia estimaciones de LFC más probables (más bajas).\nPara generar esta estimación del LFC, hay que correr la función adicional (lfcSrink()).\n\n\n\n\n\n\nNote\n\n\n\nLa reducción de los cambios de pliegues log2 no cambiará el número total de genes que se identifican como significativamente expresados de forma diferencial. La reducción del cambio de pliegue es para ayudar con la evaluación posterior de los resultados. Por ejemplo, si desea subconjuntar sus genes significativos basándose en el cambio de pliegue para una evaluación posterior, puede que desee utilizar los valores shruken. Además, para las herramientas de análisis funcional como GSEA que requieren valores de cambio de pliegue como entrada, usted querría proporcionar valores reducidos.\n\n\n\n\n\n3.4.2 Evaluación de la expresión diferencial\nEl primer paso en la prueba de hipótesis es establecer una hipótesis nula para cada gen. En nuestro caso, la hipótesis nula es que no hay expresión diferencial en los dos grupos de muestras (LFC == 0). En segundo lugar, utilizamos una prueba estadística para determinar si, basándonos en los datos observados, la hipótesis nula es cierta.\nCon DESeq2, el Test de Wald se utiliza habitualmente para la comprobación de hipótesis cuando se comparan dos grupos. Se calcula un estadístico de Test de Wald junto con una probabilidad (p-valor) de que se seleccionara al azar un estadístico de prueba al menos tan extremo como el valor observado. Si el valor p es pequeño, rechazamos la hipótesis nula y afirmamos que existen pruebas en contra de la nula (es decir, que el gen se expresa de forma diferencial).\n\n3.4.2.1 Crear los grupos de comparación\nPara indicar a DESeq2 qué dos grupos queremos comaprar, usamos la función contrasts(), la está integrada en DESeq2 para realizar este Test de Wald entre dos grupos de comparación. Las variables a comparar se pueden dar en DESeq de dos formas distintas:\n\nNo haciendo nada. Por defecto, DESeq2 utiliza el factor base de la condición de interés. El factor base de la condición de interés lo selecciona de forma alfabética.\nCon la función results() podemos definir la comparación de interés. El factor dado en último lugar se definirá como el factor base de la comparación. Para asegurarnos de tener nuestra comparación de interés usaremos esta opción. La sintaxis sería la siguiente:\n\n\n#Definimos la condición a evaluar, el factor a comparar y el factor base (en ese orden), en una variable\ncontrast&lt;-c(\"cell_type\", \"Luminal\",\"Basal\")\n\n#Ahora generamos los resultados y la guardamos en una variable nueva para utilzarlos luego\nres&lt;-results(dds_DEs, contrast = contrast, alpha = 0.05)\n\n#Visualizamos res:\nhead(res)\n\nlog2 fold change (MLE): cell_type Luminal vs Basal \nWald test p-value: cell type Luminal vs Basal \nDataFrame with 6 rows and 6 columns\n                 baseMean log2FoldChange     lfcSE      stat      pvalue\n                &lt;numeric&gt;      &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt;   &lt;numeric&gt;\nENSG00000000003 4040.4367       1.231831  0.219235  5.618779 1.92312e-08\nENSG00000000419 3955.0625      -0.362824  0.254226 -1.427170 1.53531e-01\nENSG00000000457 2263.8416       0.841835  0.204578  4.114984 3.87207e-05\nENSG00000000460  566.3217       0.483936  0.274408  1.763562 7.78057e-02\nENSG00000000938   31.2613      -1.380236  0.972290 -1.419572 1.55732e-01\nENSG00000000971 3784.4176       0.352932  0.488092  0.723085 4.69627e-01\n                       padj\n                  &lt;numeric&gt;\nENSG00000000003 5.89919e-07\nENSG00000000419 3.41626e-01\nENSG00000000457 4.48258e-04\nENSG00000000460 2.12177e-01\nENSG00000000938 3.44979e-01\nENSG00000000971 7.05029e-01\n\n\n\n\n\n\n\n\nNote\n\n\n\nEl Test de Wald tambien puede utilizar variables contínuas. Si la variable de interés dada en el diseño (con el argumento desing cuando realizamos el DESeqDataSetFromMatrix) es contínua, el report del LFC se realizará por unidad de cambio en esa variable\n\n\n\n\n3.4.2.2 Contracción de la tabla de resultados\nPara construir nuestra tabla de resultados utilizaremos la función results(). Para indicar a DESeq2 los grupos que deseamos comparar, introduciremos los contrastes que deseamos realizar mediante el argumento contrast. Para este ejemplo, guardaremos las versiones no reducidas y reducidas de los resultados en variables separadas. Además, incluimos el argumento alfa y lo establecemos en 0,05. Este es el límite de significación utilizado para el análisis de la varianza. Este es el límite de significación utilizado para optimizar el filtrado independiente (por defecto se establece en 0,1). Si el valor de corte p ajustado (FDR) será un valor distinto de 0,1 (para nuestra lista final de genes significativos), alfa debe fijarse en ese valor (alfa = 0.05).\n\n#puede ser que necesitemos instalar el paquete \"ashr\" desde Bioconductor\n#Creamos la tabla de resultados\nres_table &lt;- lfcShrink(dds_DEs, contrast=contrast, res=res, type=\"ashr\")\n\n#visualizamos la tabla de resultados\nhead(res_table)\n\nlog2 fold change (MMSE): cell_type Luminal vs Basal \nWald test p-value: cell type Luminal vs Basal \nDataFrame with 6 rows and 5 columns\n                 baseMean log2FoldChange     lfcSE      pvalue        padj\n                &lt;numeric&gt;      &lt;numeric&gt; &lt;numeric&gt;   &lt;numeric&gt;   &lt;numeric&gt;\nENSG00000000003 4040.4367       1.127634  0.228829 1.92312e-08 5.89919e-07\nENSG00000000419 3955.0625      -0.254933  0.222360 1.53531e-01 3.41626e-01\nENSG00000000457 2263.8416       0.734814  0.205440 3.87207e-05 4.48258e-04\nENSG00000000460  566.3217       0.336907  0.244572 7.78057e-02 2.12177e-01\nENSG00000000938   31.2613      -0.376240  0.601387 1.55732e-01 3.44979e-01\nENSG00000000971 3784.4176       0.157092  0.334196 4.69627e-01 7.05029e-01\n\n\n\n\n3.4.2.3 ¿Por qué usar el p-valor ajustado en vez del p-valor?\nEn results() tenemos p valores y p valores ajustados. ¿Cuál deberíamos utilizar para identificar los genes expresados de forma significativamente diferente?\nSi utilizamos el p valor directamente de la prueba de Wald con un corte de significación de p &lt; 0,05, significa que hay un 5% de posibilidades de que sea un falso positivo. Cada valor p es el resultado de una sola prueba (un solo gen). Cuantos más genes probemos, más inflamos la tasa de falsos positivos. Este es el problema de las pruebas múltiples. Por ejemplo, si probamos 20.000 genes en busca de expresión diferencial, a p &lt; 0,05 esperaríamos encontrar 1.000 genes por azar. Si encontramos un total de 3.000 genes con expresión diferencial, aproximadamente un tercio de nuestros genes son falsos positivos. No querríamos cribar nuestros genes “significativos” para identificar cuáles son los verdaderos positivos.\nDESeq2 ayuda a reducir el número de genes analizados mediante la eliminación de aquellos genes con pocas probabilidades de ser significativamente DE antes de la prueba, como aquellos con bajo número de recuentos y muestras atípicas (QC a nivel de genes). Sin embargo, aún necesitamos corregir las pruebas múltiples para reducir el número de falsos positivos, y existen algunos enfoques comunes:\n\nBonferroni: The adjusted p-value is calculated by: p-value * m (m = total number of tests). This is a very conservative approach with a high probability of false negatives, so is generally not recommended.\nFDR/Benjamini-Hochberg: Benjamini and Hochberg (1995) defined the concept of FDR and created an algorithm to control the expected FDR below a specified level given a list of independent p-values. An interpretation of the BH method for controlling the FDR is implemented in DESeq2 in which we rank the genes by p-value, then multiply each ranked p-value by m/rank.\nQ-value / Storey method: The minimum FDR that can be attained when calling that feature significant. For example, if gene X has a q-value of 0.013 it means that 1.3% of genes that show p-values at least as small as gene X are false positives\n\nEn DESeq2, los p valores obtenidos mediante la prueba de Wald se corrigen por defecto para pruebas múltiples utilizando el método de Benjamini y Hochberg. Existen opciones para utilizar otros métodos en la función results(). Los p valores ajustados deben utilizarse para determinar los genes significativos. Los genes significativos pueden mostrarse para su visualización y/o análisis funcional.\n\n\n\n\n\n\nEntonces, ¿qué significa FDR &lt; 0.05?\n\n\n\n\n\nAl establecer el límite FDR en &lt; 0,05, estamos diciendo que la proporción de falsos positivos que esperamos entre nuestros genes expresados diferencialmente es del 5%. Por ejemplo, si llama a 500 genes como expresados diferencialmente con un corte FDR de 0,05, espera que 25 de ellos sean falsos positivos.\n\n\n\n\n\n3.4.2.4 MA plot\nEl gráfico MA muestra la media de los recuentos normalizados frente a los cambios de pliegues log2 para todos los genes analizados. Los genes que son significativamente DE están coloreados para ser fácilmente identificados. Esta es también una buena manera de ilustrar el efecto de la contracción de LFC. El paquete DESeq2 ofrece una función sencilla para generar un gráfico MA.\nPara ver de forma visual en lo que consiste el ajuste de estimación que hemos hecho en el paso anterior vamos a hacer el MA plot (con la función plotMA()) con los datos sin corregir:\n\nplotMA(res, ylim=c(-5,5))\n\n\n\n\nY ahora tras ejecutar el ajuste de estimación:\n\nplotMA(res_table, ylim=c(-5,5))\n\n\n\n\n\n\n3.4.2.5 Extracción de los genes diferencialmente expresados\nCon la gran lista de genes significativos puede ser difícil extraer una relevancia biológica significativa. Para ayudar a aumentar el rigor, también se puede añadir un umbral de cambio de pliegue. La función summary() no tiene un argumento para el umbral de cambio de pliegue.\nPrimero creemos variables que contengan nuestros criterios de umbral:\n\npadj.cutoff &lt;- 0.05\nlfc.cutoff &lt;- 0.58\n#El lfc.cutoff() se establece en 0,58; recuerda que estamos trabajando con Fold Changes en log2, por lo que esto se traduce en un cambio de pliegue real de 1,5, que es bastante razonable.\n\nPodemos subdividir fácilmente la tabla de resultados para incluir sólo aquellos que sean significativos utilizando la función filter(), pero primero convertiremos la tabla de resultados en un tibble (matriz de elementos, como una especie de data.frame mejorado para el tratamiento de datos):\n\nres_table_tb &lt;- res_table %&gt;%\n  data.frame() %&gt;%\n  rownames_to_column(var=\"gene\") %&gt;% \n  as_tibble()\n\nhead(res_table_tb)\n\n# A tibble: 6 × 6\n  gene            baseMean log2FoldChange lfcSE       pvalue        padj\n  &lt;chr&gt;              &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n1 ENSG00000000003   4040.           1.13  0.229 0.0000000192 0.000000590\n2 ENSG00000000419   3955.          -0.255 0.222 0.154        0.342      \n3 ENSG00000000457   2264.           0.735 0.205 0.0000387    0.000448   \n4 ENSG00000000460    566.           0.337 0.245 0.0778       0.212      \n5 ENSG00000000938     31.3         -0.376 0.601 0.156        0.345      \n6 ENSG00000000971   3784.           0.157 0.334 0.470        0.705      \n\n\nAhora podemos hacer un subconjunto de esa tabla para conservar sólo los genes significativos utilizando nuestros umbrales predefinidos:\n\nsig &lt;- res_table_tb %&gt;%\n        dplyr::filter(padj &lt; padj.cutoff & abs(log2FoldChange) &gt; lfc.cutoff)\n\nhead(sig)\n\n# A tibble: 6 × 6\n  gene            baseMean log2FoldChange lfcSE        pvalue        padj\n  &lt;chr&gt;              &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n1 ENSG00000000003    4040.          1.13  0.229 0.0000000192  0.000000590\n2 ENSG00000000457    2264.          0.735 0.205 0.0000387     0.000448   \n3 ENSG00000001036    1678.          0.620 0.236 0.00141       0.00922    \n4 ENSG00000001497    2324.         -0.734 0.332 0.00262       0.0153     \n5 ENSG00000001561    3888.          1.71  0.330 0.00000000463 0.000000169\n6 ENSG00000001626    4004.          1.68  0.942 0.00119       0.00803    \n\n\n¿Cuantos genes hay diferencialmente expresados en las células luminales de próstata con respecto a las basales?\n\nsig\n\n# A tibble: 3,188 × 6\n   gene            baseMean log2FoldChange lfcSE        pvalue        padj\n   &lt;chr&gt;              &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 ENSG00000000003   4040.           1.13  0.229 0.0000000192  0.000000590\n 2 ENSG00000000457   2264.           0.735 0.205 0.0000387     0.000448   \n 3 ENSG00000001036   1678.           0.620 0.236 0.00141       0.00922    \n 4 ENSG00000001497   2324.          -0.734 0.332 0.00262       0.0153     \n 5 ENSG00000001561   3888.           1.71  0.330 0.00000000463 0.000000169\n 6 ENSG00000001626   4004.           1.68  0.942 0.00119       0.00803    \n 7 ENSG00000002726     57.7          2.11  0.717 0.0000513     0.000567   \n 8 ENSG00000003147   3870.           1.28  0.352 0.00000482    0.0000755  \n 9 ENSG00000003249    419.           1.05  0.466 0.000853      0.00613    \n10 ENSG00000003400   2427.           1.89  0.353 0.00000000260 0.000000102\n# ℹ 3,178 more rows\n\n\n\n3.4.2.5.1 Incorporación del GeneSymbol\nPor último, es recomendable asignarle a cada gen su GeneSymbol, ya que es el nombre de los genes que conocemos todos. Además para las representaciones va a ser más bonito de ver con el nombre del gen que con el código de Ensembl. Para crear este listado vamos a utilizar el paquete biomaRt.\n\n#para este apartado hemos intalado biomaRt\nensembl = useEnsembl(biomart=\"ensembl\", dataset=\"hsapiens_gene_ensembl\")\n\nComo no hemos escrito versión, accederá a la última versión que tenga registrada. Si quisieramos conectar con alguna versión antigua o de otro animal tenemos que escribir la versión:\n\nensembl = useEnsembl(biomart=\"ensembl\", dataset=\"hsapiens_gene_ensembl\", version=78)\n\nPara saber qué especies contiene el dataset tenemos que cargar el paquete ensemble completo y usar el comando listDatasets(ensembl):\n\nensembl = useEnsembl(biomart=\"ensembl\")\nhead(listDatasets(ensembl))\n\n                       dataset                           description\n1 abrachyrhynchus_gene_ensembl Pink-footed goose genes (ASM259213v1)\n2     acalliptera_gene_ensembl      Eastern happy genes (fAstCal1.2)\n3   acarolinensis_gene_ensembl       Green anole genes (AnoCar2.0v2)\n4    acchrysaetos_gene_ensembl       Golden eagle genes (bAquChr1.2)\n5    acitrinellus_gene_ensembl        Midas cichlid genes (Midas_v5)\n6    amelanoleuca_gene_ensembl       Giant panda genes (ASM200744v2)\n      version\n1 ASM259213v1\n2  fAstCal1.2\n3 AnoCar2.0v2\n4  bAquChr1.2\n5    Midas_v5\n6 ASM200744v2\n\n\nY ya seleccionariamos la versión que quisieramos.\nContinuando con la creación del listado de códigos de equivalencias de Códigos de Ensembl con GeneSymbol, el siguiente paso consistiría en crear el listado\n\n#Definimos el DataSet que vamos a utilizar\nensembl = useEnsembl(biomart=\"ensembl\", dataset=\"hsapiens_gene_ensembl\")\n#Creamos un listado con getBM\nGeneSymbolList &lt;-getBM(attributes=c('ensembl_gene_id','hgnc_symbol'), mart = ensembl)\n#Visualizamos el listado\nhead(GeneSymbolList)\n\n  ensembl_gene_id hgnc_symbol\n1 ENSG00000210049       MT-TF\n2 ENSG00000211459     MT-RNR1\n3 ENSG00000210077       MT-TV\n4 ENSG00000210082     MT-RNR2\n5 ENSG00000209082      MT-TL1\n6 ENSG00000198888      MT-ND1\n\n\nAhora podemos incorporar esta info al Dataset donde tenemos los datos de Fold change con los que haremos las gráficas de representación de datos\n\nsig_Gene_Symbol&lt;-merge (sig, GeneSymbolList, by.x=\"gene\", by.y=\"ensembl_gene_id\", all.x=TRUE)\n#Ahora renombramos la columna que acabamos de añadir\ncolnames(sig_Gene_Symbol)[7]&lt;-c(\"Gene_Symbol\")\n#Visualizamos el listado\nhead(sig_Gene_Symbol)\n\n             gene baseMean log2FoldChange     lfcSE       pvalue         padj\n1 ENSG00000000003 4040.437      1.1276341 0.2288288 1.923117e-08 5.899186e-07\n2 ENSG00000000457 2263.842      0.7348141 0.2054399 3.872069e-05 4.482583e-04\n3 ENSG00000001036 1677.821      0.6195882 0.2363429 1.409314e-03 9.224009e-03\n4 ENSG00000001497 2323.912     -0.7344059 0.3315479 2.619123e-03 1.532309e-02\n5 ENSG00000001561 3887.750      1.7062280 0.3304577 4.630871e-09 1.694177e-07\n6 ENSG00000001626 4004.007      1.6784524 0.9423249 1.189341e-03 8.031261e-03\n  Gene_Symbol\n1      TSPAN6\n2       SCYL3\n3       FUCA2\n4       LAS1L\n5       ENPP4\n6        CFTR\n\n\n\n\n\n3.4.2.6 Representación de los genes más expresados o de una maquinaria en concreto\nEsto suele requerir primero un poco de manipulación de los datos.\nVamos a trazar los valores de recuento normalizados para (por ejemplo) los 20 genes más expresados diferencialmente (por valores padj).\nPara ello, primero tenemos que determinar los nombres de los 20 genes principales ordenando nuestros resultados y extrayendo los 20 genes principales (por valores padj):\n\ntop20_sig_genes &lt;-  sig_Gene_Symbol %&gt;% \n        arrange(padj) %&gt;%   #Arrange rows by padj values\n        pull(gene) %&gt;%      #Extract character vector of ordered genes\n        head(n=20)      #Extract the first 20 genes\n\nhead(top20_sig_genes)\n\n[1] \"ENSG00000236699\" \"ENSG00000116299\" \"ENSG00000170961\" \"ENSG00000148677\"\n[5] \"ENSG00000156966\" \"ENSG00000171812\"\n\n\n\nSi queremos hacer la exploración de una maquinaria en concreto tenemos que crear un .csv que contenga el listado de los nombres de los genes que queremos extraer para cargarlos en esta variable que acabamos de crear.\n\nAhora extraemos los valores counts normalizadas de estos genes seleccionados:\n\ntop20_sig_norm &lt;- as.data.frame(normalized_counts) %&gt;%\n  rownames_to_column(var = \"gene\") %&gt;%\n  dplyr::filter(gene %in% top20_sig_genes)\n\nhead(top20_sig_norm)\n\n             gene    Basal_1    Basal_2    Basal_3  Luminal_1  Luminal_2\n1 ENSG00000004468   86.85545   47.82078   59.56635  836.43688  738.94772\n2 ENSG00000101335 2401.50847 2922.04865 2619.89247  301.07740  333.37584\n3 ENSG00000116299 1050.32417  832.87851  899.65731 6605.75777 7693.12526\n4 ENSG00000140945 3908.49533 2657.04185 3016.31681   51.84114   78.56628\n5 ENSG00000143416  694.84361  615.69249  600.79855 3716.61107 2966.40795\n6 ENSG00000148677  131.62630  190.28684  131.45678 1638.97763 1794.28398\n  Luminal_3\n1 1062.3894\n2  428.5948\n3 7779.3994\n4  138.4846\n5 2878.8630\n6 2040.8793\n\n\nAhora tenemos que poner los valores en disposición x e y interpretable por ggplot:\n\ngathered_top20_sig &lt;- top20_sig_norm %&gt;%\n  gather(colnames(top20_sig_norm)[2:ncol(top20_sig_norm)], key = \"samplename\", value = \"normalized_counts\")\n#como estos son los datos que vamos a representar, añadimos los genenames oficiales\ngathered_top20_sig &lt;- merge(gathered_top20_sig, GeneSymbolList, by.x=\"gene\", by.y=\"ensembl_gene_id\", all.x=TRUE)\n#Ahora renombramos la columna que acabamos de añadir\ncolnames(gathered_top20_sig)[ncol(gathered_top20_sig)]&lt;-c(\"Gene_Symbol\")\n\nhead(gathered_top20_sig)\n\n             gene samplename normalized_counts Gene_Symbol\n1 ENSG00000004468    Basal_1          86.85545        CD38\n2 ENSG00000004468    Basal_3          59.56635        CD38\n3 ENSG00000004468  Luminal_2         738.94772        CD38\n4 ENSG00000004468    Basal_2          47.82078        CD38\n5 ENSG00000004468  Luminal_1         836.43688        CD38\n6 ENSG00000004468  Luminal_3        1062.38940        CD38\n\n\nAhora, si queremos nuestros “counts” coloreados por grupo de muestra, entonces necesitamos combinar la información de metadatos con los datos de recuentos normalizados fundidos en el mismo marco de datos para introducirlos en ggplot():\n\ngathered_top20_sig &lt;- inner_join(metaData %&gt;%\n  rownames_to_column(var = \"samplename\"), gathered_top20_sig)\n\nJoining with `by = join_by(samplename)`\n\n# inner_join() fusionará 2 marcos de datos con respecto a la columna \"samplename\" \n#(por eso convertimos los roenames en una columna), es decir, una columna con \n#el mismo nombre de columna en ambos marcos de datos.\n\nhead(gathered_top20_sig)\n\n  samplename cell_type            gene normalized_counts Gene_Symbol\n1    Basal_1     Basal ENSG00000004468          86.85545        CD38\n2    Basal_1     Basal ENSG00000101335        2401.50847        MYL9\n3    Basal_1     Basal ENSG00000116299        1050.32417     ELAPOR1\n4    Basal_1     Basal ENSG00000140945        3908.49533       CDH13\n5    Basal_1     Basal ENSG00000143416         694.84361    SELENBP1\n6    Basal_1     Basal ENSG00000148677         131.62630      ANKRD1\n\n\nY ahora realizamos un gráfico de la expresión de los genes\n\nggplot(gathered_top20_sig) +\n        geom_boxplot(aes(x = Gene_Symbol, y = normalized_counts, fill = cell_type)) +\n        scale_y_log10() +\n        xlab(\"Genes\") +\n        ylab(\"log10 Normalized Counts\") +\n        ggtitle(\"Top 20 Significant DE Genes\") +\n  theme_bw() +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 6)) +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\nComo se puede ver, esta gráfica es un jaleo porque contiene mucha info muy junta por lo que puede venir bien separar cada gen en una gráfica independiente:\n\nggplot(gathered_top20_sig) +\n        geom_boxplot(aes(x = Gene_Symbol, y = normalized_counts, fill = cell_type)) +\n        scale_y_log10() +\n        xlab(\"Genes\") +\n        ylab(\"log10 Normalized Counts\") +\n        ggtitle(\"Top 20 Significant DE Genes\") +\n  facet_wrap(~gene, scale=\"free\")+ \n  theme(axis.text.x = element_text( size = 7),\n        axis.text.y = element_text( size = 5),\n    strip.text.x = element_text(size = 4, face = \"bold\"), \n    legend.key.size=unit(2, \"mm\"))\n\n\n\n\n\n\n3.4.2.7 Heatmap\nTambién vamos a hacer un heatmap, en este caso de todos los genes desregulados de forma significativa. Para ello volveremos a unsar el paquete pheatmap. Primero tenemos que extraer todos los genes que estén significativamente desregulados:\n\nnorm_sig &lt;- as.data.frame(normalized_counts) %&gt;% \n  rownames_to_column(var = \"gene\") %&gt;%\n              dplyr::filter(gene %in% sig$gene) %&gt;% \n          data.frame() %&gt;%\n  column_to_rownames(var=\"gene\")\n  \n\n\nhead(norm_sig)\n\n                 Basal_1   Basal_2   Basal_3 Luminal_1 Luminal_2 Luminal_3\nENSG00000000003 2743.558 2586.3070 1909.2043  5468.243  6195.057  5340.250\nENSG00000000457 1798.893 1606.9773 1458.3486  3374.659  2550.219  2793.953\nENSG00000001036 1204.336 1148.6949 1379.2691  2542.210  1661.571  2130.844\nENSG00000001497 4052.657 2257.5391 2979.3446  1766.587  1105.236  1782.105\nENSG00000001561 1782.775 2048.3232 1300.1897  6561.892  7375.675  4257.644\nENSG00000001626 2484.782  410.4617  429.2885 13469.724  2706.290  4523.494\n\n\nA continuación vamos a crear la anotation para las muestras a partir de la metadata:\n\nannotation &lt;- metaData %&gt;% \n  rownames_to_column(var=\"samplename\") %&gt;%\n    dplyr::select(samplename, cell_type) %&gt;% \n    data.frame(row.names = \"samplename\")\n\nhead(annotation)\n\n          cell_type\nBasal_1       Basal\nBasal_2       Basal\nBasal_3       Basal\nLuminal_1   Luminal\nLuminal_2   Luminal\nLuminal_3   Luminal\n\n\nA continuación hacemos el Heatmap:\n\npheatmap(norm_sig, \n         color = colorRampPalette(brewer.pal(6, \"YlOrRd\"))(100), \n         cluster_rows = T, \n         show_rownames = F,\n         show_colnames = F,\n         annotation = annotation, \n         border_color = NA, \n         fontsize = 10, \n         scale = \"row\", \n         fontsize_row = 10, \n         height = 20)\n\n\n\n\nSi tuvieramos menos genes y quisieramos visualizar el heatmap con los nombres de estos genes podríamos ponerles un label:\n\n#primero vamos a filtrar solamente los 20 más diferencialemnte expresados:\nnorm_sig_genes &lt;- as.data.frame(normalized_counts) %&gt;% \n  rownames_to_column(var = \"gene\") %&gt;%\n              dplyr::filter(gene %in% top20_sig_norm$gene) %&gt;% \n          data.frame() %&gt;%\n  column_to_rownames(var=\"gene\")\n#Creamos la anotación para los genes (para las muestras vamos a utilizar la que hemos creado antes en la variable \"annotation\")\nrow_annotation&lt;-norm_sig_genes%&gt;%\n  rownames_to_column(var=\"gene\")%&gt;%\n        inner_join(GeneSymbolList, by=c(\"gene\"=\"ensembl_gene_id\")) %&gt;%\n  dplyr::rename(\"Gene_Symbol\"=\"hgnc_symbol\") %&gt;%\n  #aquí he tenido que definir la función rename con \"dplyr::\" como prefijo. Esto es porque hay otros paquetes que utilizan esta función y crea conflicto. Al utilizar este prefijo hacemos que solo busque la función en ese paquete\n  mutate(Gene_Symbol = ifelse(is.na(Gene_Symbol) | Gene_Symbol == \"\", gene, Gene_Symbol))%&gt;%\n  dplyr::select(gene,Gene_Symbol)%&gt;%\n column_to_rownames(var=\"gene\")\n\nrow_annotation&lt;-as.data.frame(row_annotation)\n#Ahora se hace el gráfico\npheatmap(norm_sig_genes, \n         color = colorRampPalette(brewer.pal(6, \"YlOrRd\"))(100), \n         cluster_rows = T, \n         show_rownames = T,\n         labels_row = row_annotation[,1],\n         show_colnames = F,\n         annotation = annotation, \n         border_color = NA, \n         fontsize = 10, \n         scale = \"row\", \n         fontsize_row = 10, \n         height = 20)\n\n\n\n\n\n\n3.4.2.8 PCA\nEn este caso, para realizar el PCA vamos a utilizar una herramienta llamada PCAtools. Hay numerosas gráficas que podemos hacer con esta herramienta. De hecho a más variables tengamos, mayor cantidad de herramientas tendremos (enlace a la página oficial). Primero creamos la variable p con la función pca para juntar la metadata con la matriz de datos, eliminando aqullos genes que presenten una varianza inferior al 10%:\n\np&lt;-pca(normalized_counts, metadata = metaData, removeVar=0.1)\n\n-- removing the lower 10% of variables based on variance\n\n\nA continuación podemos explorar diferentes gráficos. Por ejemplo, podemos empezar con un “biplot” sencillo:\n\nPCAtools::biplot(p,\n                 title = \"PCA Results\",\n                 lab=NULL,\n                 axisLabSize = 8,\n                 colby=\"cell_type\")\n\n\n\n\nY vamos a añadir distintas varibales para tenerlas en cuenta:\n\nPCAtools::biplot(p,\n                 title = \"PCA Results\",\n                 lab=NULL,\n                 axisLabSize = 8,\n                 colby=\"cell_type\",\n                 colkey = c(\"Basal\"=\"forestgreen\", \"Luminal\"=\"lightblue\"),\n                 encircle = TRUE,\n                 encircleFill = TRUE,\n                 legendPosition = \"right\")\n\n\n\n\nY la que tanto nos gusta del metaboanalyst:\n\nPCAtools::biplot(p,\n                 title = \"PCA Results\",\n                 lab=NULL,\n                 axisLabSize = 8,\n                 colby=\"cell_type\",\n                 colkey = c(\"Basal\"=\"forestgreen\", \"Luminal\"=\"blue\"),\n                 ellipse = TRUE,# hacemos la elipse\n                 ellipseType = \"t\",\n                 ellipseLevel = 0.95,\n                 ellipseFill = TRUE,\n                 ellipseAlpha= 1/3,\n                 ellipseLineSize = 0,\n                 ellipseFillKey = c(\"Basal\"=\"lightgreen\", \"Luminal\"=\"lightblue\"),\n                 legendPosition = \"right\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nToo few points to calculate an ellipse\nToo few points to calculate an ellipse\n\n\n\n\n#En este caso sale que hay pocos puntos para generar un buen intervalo de confianza\n\nTambién podemos hacer la representación de varias gráficas PCA de forma simultánea para así poder ver más de una opción:\n\npairsplot(p,\n    components = getComponents(p, c(1:4)),\n    triangle = TRUE, \n    trianglelabSize = 16,\n    hline = 0, \n    vline = 0,\n    pointSize = 2,\n    gridlines.major = FALSE, \n    gridlines.minor = FALSE,\n    colby = 'cell_type',\n    title = 'Pairs plot',\n    titleLabSize = 12,\n    plotaxes = FALSE,\n    margingaps = unit(c(-0.01, -0.01, -0.01, -0.01), 'cm'))\n\n\n\n\nPara ver correlaciones entre variables es recomendable explorar el paquete\n\n\n3.4.2.9 Volcano plot\nPara generar un volcano plot, primero necesitamos tener una columna en nuestros datos de resultados que indique si el gen se considera o no diferencialmente expresado en función de los p valores ajustados:\n\nres_table_tb &lt;- res_table_tb %&gt;% \n                  mutate(threshold = padj &lt; 0.05 & abs(log2FoldChange) &gt;= 0.58)\n\n\n\nhead(res_table_tb)\n\n# A tibble: 6 × 7\n  gene            baseMean log2FoldChange lfcSE       pvalue      padj threshold\n  &lt;chr&gt;              &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt; &lt;lgl&gt;    \n1 ENSG00000000003   4040.           1.13  0.229 0.0000000192   5.90e-7 TRUE     \n2 ENSG00000000419   3955.          -0.255 0.222 0.154          3.42e-1 FALSE    \n3 ENSG00000000457   2264.           0.735 0.205 0.0000387      4.48e-4 TRUE     \n4 ENSG00000000460    566.           0.337 0.245 0.0778         2.12e-1 FALSE    \n5 ENSG00000000938     31.3         -0.376 0.601 0.156          3.45e-1 FALSE    \n6 ENSG00000000971   3784.           0.157 0.334 0.470          7.05e-1 FALSE    \n\n\nUna vez generada esta matriz ya podemos pasar a la representación de los datos:\n\nggplot(res_table_tb) +\n        geom_point(aes(x = log2FoldChange, y = -log10(padj), colour = threshold)) +\n        ggtitle(\"Luminal vs Basal\") +\n        xlab(\"log2 fold change\") + \n        ylab(\"-log10 adjusted p-value\") +\n        #scale_y_continuous(limits = c(0,50)) +\n        theme(legend.position = \"none\",\n              plot.title = element_text(size = rel(1.5), hjust = 0.5),\n              axis.title = element_text(size = rel(1.25)))  \n\n\n\n\nPodemos poner etiquetas a los nombres de los genes con el argumento geom_text_repel (hay que instalarlo), pero para ello tenemos que crear una columna en la que indiquemos que genes vamos a hacer que se etiqueten:\n\nres_table_tb &lt;- res_table_tb %&gt;% arrange(padj) %&gt;% mutate(genelabels = \"\")\n\nres_table_tb$genelabels[1:10] &lt;- res_table_tb$gene[1:10]\n\nhead(res_table_tb)\n\n# A tibble: 6 × 8\n  gene      baseMean log2FoldChange lfcSE   pvalue     padj threshold genelabels\n  &lt;chr&gt;        &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;lgl&gt;     &lt;chr&gt;     \n1 ENSG0000…    2461.           3.12 0.184 1.01e-65 1.70e-61 TRUE      ENSG00000…\n2 ENSG0000…    4144.           2.95 0.185 2.26e-58 1.91e-54 TRUE      ENSG00000…\n3 ENSG0000…   14383.          -3.12 0.220 8.19e-47 4.61e-43 TRUE      ENSG00000…\n4 ENSG0000…     988.           3.52 0.249 1.19e-46 5.04e-43 TRUE      ENSG00000…\n5 ENSG0000…    2816.           2.34 0.167 2.46e-45 8.31e-42 TRUE      ENSG00000…\n6 ENSG0000…    1953.          -2.78 0.211 1.55e-40 4.35e-37 TRUE      ENSG00000…\n\n\nAhora podemos poner este argumento adicional a ggplot:\n\n#para este apartado hay que tener cargado el paquete ggrepel\nggplot(res_table_tb, aes(x = log2FoldChange, y = -log10(padj))) +\n        geom_point(aes(colour = threshold)) +\n        geom_text_repel(aes(label = genelabels)) +\n        ggtitle(\"Luminal vs Basal\") +\n        xlab(\"log2 fold change\") + \n        ylab(\"-log10 adjusted p-value\") +\n        theme(legend.position = \"none\",\n              plot.title = element_text(size = rel(1.5), hjust = 0.5),\n              axis.title = element_text(size = rel(1.25)))  \n\n\n\n\n\n\n3.4.2.10 Explorar un Único gen de interés\nPara esto, está la función integrada en DESeq2 de plotCount(), que lo podemos combinar con ggplot:\n\nd &lt;- plotCounts(dds, gene=\"ENSG00000236699\", intgroup=\"cell_type\", returnData=TRUE)\n\n# Plotting the MOV10 normalized counts, using the samplenames (rownames of d as labels)\nggplot(d, aes(x = cell_type, y = count, color = cell_type)) + \n  geom_point(position=position_jitter(w = 0.1,h = 0)) +\n  theme_bw() +\n  ggtitle(\"ENSG00000236699\") +\n  theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "RNAseq.html#formato-de-datos",
    "href": "RNAseq.html#formato-de-datos",
    "title": "Bulk RNAseq",
    "section": "4.1 Formato de datos",
    "text": "4.1 Formato de datos\nPara realizar los análsis de enriquecimiento tenemos que tener una lista de genes “rankeada” que contenga el Fold Change de cada gen, teniendo cada gen un ID único. Este listado de genes debe de cumplir las siguientes condiciones:\n\nVector numérico: cambio de pliegue u otro tipo de variable numérica\nVector con nombre: cada número tiene un nombre, el ID del gen correspondiente\nVector numérico ordenado: los números deben ordenarse de forma decreciente.\n\nSi importamos los datos desde un archivo .csv, el archivo debería contener dos columnas, una para el ID del gen (no se permiten ID duplicados) y otra para el Fold Change. Podemos preparar nuestra propia geneList mediante el siguiente comando:\n\nd = read.csv(your_csv_file)\n## Asumimos que la primera columna es el ID\n## La segunda columna es el Fold Change\n\n## Caracaterística 1: numeric vector\ngeneList = d[,2]\n\n## Caracaterística 2: named vector\nnames(geneList) = as.character(d[,1])\n\n## Caracaterística 3: decreasing orde\ngeneList = sort(geneList, decreasing = TRUE)\n\nEn nuestro caso, como procedemos del análisis anterior vamos a ver la preparación de la GeneList para que tenga estas características:\n\ngeneList&lt;-round(res_table_tb$log2FoldChange, digits = 5)\nnames(geneList)&lt;-res_table_tb$gene\ngeneList&lt;- sort(geneList,decreasing = T)\n\nhead(geneList)\n\nENSG00000274542 ENSG00000162040 ENSG00000211689 ENSG00000109182 ENSG00000188257 \n        7.67977         5.31934         4.65300         4.54901         4.32895 \nENSG00000219814 \n        4.23851 \n\n\nTambien, por agilizar el tratameinto de datos, es recomendable pasar los códigos de “Ensembl” a códdigos de “EntrezGeneID” porque es el código que usan por defecto todos los paquetes y funciones que vamos a utilizar a continuación. Esto lo vamos a hacer con el paquete org.Hs.eg.db (que nos aporta el nombre de todos los genes de humano en todos los formatos) gracias a la función bitr del propio paquete de clusterProfiler:\n\n#Primero hacemos la conversión\nGeneNames&lt;-names(geneList)\nGeneNames_drop &lt;- bitr(GeneNames, fromType = \"ENSEMBL\", toType = \"ENTREZID\", OrgDb=\"org.Hs.eg.db\", drop=TRUE)\n\n'select()' returned 1:many mapping between keys and columns\n\n\nWarning in bitr(GeneNames, fromType = \"ENSEMBL\", toType = \"ENTREZID\", OrgDb =\n\"org.Hs.eg.db\", : 6.67% of input gene IDs are fail to map...\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAl hacer la conversión entramos en el jodido mundo de las anotaciones de genes. Hemos podido ver que nos sale un mensaje de que se han mapeado un % de las anotaciones de ENSEMBL que ah fallado al mapear con a ENTREZ y se han rellenado con NAs (realmente se han eliminado las filas que contengan estos NA porque hemos puesto drop=TRUE). También, si nos damos cuenta, en la conversión anterior se crean duplicados de los “ENTEZ_ID” para la misma anotación de ENSEMBL (esto es normal porque el ENSEMBL es una anotación del genoma y el el ENTREZID es una antotación de genes propiamente dichos de manera que que hay regiones del genoma anotadas a las que todavía no se han dado un código ENTREZ; de igual manera puede haber un ENTREZID que tenga mas de una anotación de ENSMBL, pero esto no es un problema por el tratamiento de datos que vamos a hacer).\n\n\nEl siguiente código extrae los códigos ENSEMBL y los FC de nuestro dataframe geneList, y lo vamos a ir viendo paso a paso (realmente esto es para ver lo que va haciendo el código, lo que hay que escribir es directamente el último código completo y lo hace todo del tirón). Primero definimos geneList como el dataframe que vamos a modificar:\n\ngeneList_treat&lt;-geneList\nhead(geneList_treat)\n\nENSG00000274542 ENSG00000162040 ENSG00000211689 ENSG00000109182 ENSG00000188257 \n        7.67977         5.31934         4.65300         4.54901         4.32895 \nENSG00000219814 \n        4.23851 \n\n\n%&gt;% lo convertimos en un tibble estableciendo como nombre de filas el la columna del “ENSEMBL_ID”:\n\ngeneList_treat&lt;-geneList %&gt;% \n  as_tibble(rownames=\"ENSEMBL\")\nhead(geneList_treat)\n\n# A tibble: 6 × 2\n  ENSEMBL         value\n  &lt;chr&gt;           &lt;dbl&gt;\n1 ENSG00000274542  7.68\n2 ENSG00000162040  5.32\n3 ENSG00000211689  4.65\n4 ENSG00000109182  4.55\n5 ENSG00000188257  4.33\n6 ENSG00000219814  4.24\n\n\n%&gt;% le unimos (como una especie de merge) la columna de “ENTREZ_ID” que se encuentra en el dataset de las conversiones GeneNames_drop en función de la columna “ENSEMBL”,\n\ngeneList_treat&lt;-geneList %&gt;% \n  as_tibble(rownames=\"ENSEMBL\") %&gt;% \n  left_join(GeneNames_drop, by=\"ENSEMBL\")\nhead(geneList_treat)\n\n# A tibble: 6 × 3\n  ENSEMBL         value ENTREZID\n  &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;   \n1 ENSG00000274542  7.68 1139    \n2 ENSG00000162040  5.32 64711   \n3 ENSG00000211689  4.65 6966    \n4 ENSG00000211689  4.65 445347  \n5 ENSG00000109182  4.55 80157   \n6 ENSG00000188257  4.33 5320    \n\n\n%&gt;% a continuación se queda solo con aquellas filas que no tienen NA en la columna de “ENTREZ_ID”,\n\ngeneList_treat&lt;-geneList %&gt;% \n  as_tibble(rownames=\"ENSEMBL\") %&gt;% \n  left_join(GeneNames_drop, by=\"ENSEMBL\") %&gt;% \n  dplyr::filter(!is.na(ENTREZID))\nhead(geneList_treat)\n\n# A tibble: 6 × 3\n  ENSEMBL         value ENTREZID\n  &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;   \n1 ENSG00000274542  7.68 1139    \n2 ENSG00000162040  5.32 64711   \n3 ENSG00000211689  4.65 6966    \n4 ENSG00000211689  4.65 445347  \n5 ENSG00000109182  4.55 80157   \n6 ENSG00000188257  4.33 5320    \n\n\n%&gt;% agrupamos los valores de todss las filas que tengan el mismo “ENTREZ_ID” (genera como una especie de almacenamiento de datos por capas de manera que tenemos también una tercera dimensión de almacenamiento de datos como en el lenguaje SQL),\n\ngeneList_treat&lt;-geneList %&gt;% \n  as_tibble(rownames=\"ENSEMBL\") %&gt;% \n  left_join(GeneNames_drop, by=\"ENSEMBL\") %&gt;% \n  dplyr::filter(!is.na(ENTREZID)) %&gt;% \n  group_by(ENTREZID)\nhead(geneList_treat)\n\n# A tibble: 6 × 3\n# Groups:   ENTREZID [6]\n  ENSEMBL         value ENTREZID\n  &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;   \n1 ENSG00000274542  7.68 1139    \n2 ENSG00000162040  5.32 64711   \n3 ENSG00000211689  4.65 6966    \n4 ENSG00000211689  4.65 445347  \n5 ENSG00000109182  4.55 80157   \n6 ENSG00000188257  4.33 5320    \n\n\n%&gt;% a continuación redefinimos la columna value (que contiene los FC) como la media de los FC que correspondan al mismo ENTREZID (en este paso no definimos qué hacer con la columna de los ENSEMBL_ID de manera que se eliminan y nos quedamos con dos columnas: una primera columna de “ENTREZ_ID” y una segunda con los valores de los FC):\n\ngeneList_treat&lt;-geneList %&gt;% \n  as_tibble(rownames=\"ENSEMBL\") %&gt;% \n  left_join(GeneNames_drop, by=\"ENSEMBL\") %&gt;% \n  dplyr::filter(!is.na(ENTREZID)) %&gt;% \n  group_by(ENTREZID) %&gt;% \n  reframe(log2FC=mean(value))\nhead(geneList_treat)\n\n# A tibble: 6 × 2\n  ENTREZID   log2FC\n  &lt;chr&gt;       &lt;dbl&gt;\n1 1         -0.143 \n2 1000      -1.12  \n3 10000      0.101 \n4 10001     -0.0244\n5 10002      0.0923\n6 100037417  0.301 \n\n\n%&gt;% y por úlimo ordenamos de forma desdendente porque es el imput que necesitamos. NOTA: este es el único código final que hay que poner para que haga todo lo anterior:\n\ngeneList_treat&lt;-geneList %&gt;% \n  as_tibble(rownames=\"ENSEMBL\") %&gt;% \n  left_join(GeneNames_drop, by=\"ENSEMBL\") %&gt;% \n  dplyr::filter(!is.na(ENTREZID)) %&gt;% \n  group_by(ENTREZID) %&gt;% \n  reframe(log2FC=mean(value)) %&gt;% \n  arrange(desc(log2FC))\nhead(geneList_treat)\n\n# A tibble: 6 × 2\n  ENTREZID log2FC\n  &lt;chr&gt;     &lt;dbl&gt;\n1 445347     4.65\n2 6966       4.65\n3 80157      4.55\n4 5320       4.33\n5 729277     4.24\n6 131034     4.23\n\n\nPero todavía no tenemos un listado compatible con los análisis que vamos a hacer de manera que tenemos que hacer que este último resultado esté en formato de vector:\n\nENTREZ_geneList&lt;-setNames(geneList_treat$log2FC,geneList_treat$ENTREZID)\nhead(ENTREZ_geneList)\n\n 445347    6966   80157    5320  729277  131034 \n4.65300 4.65300 4.54901 4.32895 4.23851 4.23195 \n\n\nCon esto tendremos un listado de todos los genes en EntrezID con su correspondiente valor de Fold Change."
  },
  {
    "objectID": "RNAseq.html#gene-ontology-go-analysis",
    "href": "RNAseq.html#gene-ontology-go-analysis",
    "title": "Bulk RNAseq",
    "section": "4.2 Gene Ontology (GO) Analysis",
    "text": "4.2 Gene Ontology (GO) Analysis\n\n4.2.1 Sobreexpresión de GO\nPara comenzar vamos a comenzar haciendo un análisis de enriquecimiento en GO. Tras tener nuestro listado preparado debemos filtrar aquellos genes que tengan un Fold Change elevado (cada uno puede establecer el Fold Change mínimo que quiera, en nuestro caso vamos a utilizar un valor de 2 para buscar cambios fuertes):\n\ngene&lt;-names(ENTREZ_geneList)[abs(ENTREZ_geneList) &gt; 2]\nhead(gene)\n\n[1] \"445347\" \"6966\"   \"80157\"  \"5320\"   \"729277\" \"131034\"\n\n\nY ahora hacemos el análisis GO propiamente dicho (en este ejemplo vamos a haer el análsisi por “biological Process”).\nPrimero podemos generar una tabla que representa todos lo procesos en los que se ven implicados nuestro listado de genes (que no sería el análisis de enriquecimiento propiamente dicho):\n\nego &lt;- enrichGO(gene     = gene,\n                universe = names(ENTREZ_geneList),\n                #Con el argumento \"universe definimos el background. Si no lo defininmos usará el de la base que estamos introduciendo (los mismos que está muy deregulados), de manera que lo más correcto es poner toda la cadena de genes previa al filtro\n                OrgDb         = org.Hs.eg.db,\n                ont           = \"BP\", #One of \"BP\", \"MF\", and \"CC\" subontologies, or \"ALL\" for all three.\n                pAdjustMethod = \"BH\", #one of \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\", \"fdr\", \"none\"\n                pvalueCutoff  = 0.01,\n                qvalueCutoff  = 0.05)\n\nhead(ego)\n\n                   ID                                   Description GeneRatio\nGO:0030198 GO:0030198             extracellular matrix organization    42/503\nGO:0045229 GO:0045229 external encapsulating structure organization    42/503\nGO:0043062 GO:0043062          extracellular structure organization    42/503\nGO:0001525 GO:0001525                                  angiogenesis    43/503\nGO:0099177 GO:0099177        regulation of trans-synaptic signaling    37/503\nGO:0030282 GO:0030282                           bone mineralization    18/503\n             BgRatio       pvalue     p.adjust       qvalue\nGO:0030198 256/13334 5.146233e-16 7.972669e-13 6.676722e-13\nGO:0045229 256/13334 5.146233e-16 7.972669e-13 6.676722e-13\nGO:0043062 257/13334 5.940886e-16 7.972669e-13 6.676722e-13\nGO:0001525 429/13334 4.610318e-09 4.640285e-06 3.886012e-06\nGO:0099177 357/13334 2.392500e-08 1.926441e-05 1.613300e-05\nGO:0030282 100/13334 3.078649e-08 2.065774e-05 1.729985e-05\n                                                                                                                                                                                                                                       geneID\nGO:0030198         1803/9622/183/1297/27035/55512/55790/3549/92949/3936/9806/4316/7837/3908/5268/4312/9510/4313/4321/1294/1282/7092/1284/1296/7373/1287/857/6624/11095/11096/144165/3037/4319/50509/165/1288/10631/4318/91522/10630/4314/1308\nGO:0045229         1803/9622/183/1297/27035/55512/55790/3549/92949/3936/9806/4316/7837/3908/5268/4312/9510/4313/4321/1294/1282/7092/1284/1296/7373/1287/857/6624/11095/11096/144165/3037/4319/50509/165/1288/10631/4318/91522/10630/4314/1308\nGO:0043062         1803/9622/183/1297/27035/55512/55790/3549/92949/3936/9806/4316/7837/3908/5268/4312/9510/4313/4321/1294/1282/7092/1284/1296/7373/1287/857/6624/11095/11096/144165/3037/4319/50509/165/1288/10631/4318/91522/10630/4314/1308\nGO:0001525 1139/354/183/54567/27035/10267/3549/6376/1950/290/7837/1636/154796/144455/54922/2316/154810/2246/2069/3592/9510/4313/140862/57007/6422/5054/1282/4897/3552/1893/1284/1296/857/6678/7058/83700/4804/1464/7476/3553/8091/1012/147372\nGO:0099177                                1128/1139/594855/952/4852/183/22999/8564/9066/5764/388336/6376/79772/55607/2852/10718/2904/1636/2914/3908/2534/1268/5924/22854/140730/2171/3814/440279/1009/6507/6622/9148/9162/4804/7476/3553/2903\nGO:0030282                                                                                                                              84059/5764/100533183/144347/55512/4057/658/9365/4745/1594/54361/5744/655/359845/1893/2719/144165/2261\n           Count\nGO:0030198    42\nGO:0045229    42\nGO:0043062    42\nGO:0001525    43\nGO:0099177    37\nGO:0030282    18\n\n\n\n\n4.2.2 Análisis de enriquecimiento\nY a continuación hacemos el análsis de enriquecimiento de GO. Para este análisis sí usamos el geneList completo porque vamos a comparar todos los genes y ver qué rutas se enriquecen más en función del Fold Change de todos ellos:\n\nego3 &lt;- gseGO(geneList     = ENTREZ_geneList,\n              OrgDb        = org.Hs.eg.db,\n              ont          = \"BP\",\n              minGSSize    = 100,\n              maxGSSize    = 400,\n              #Con este argumento definimos el tamaño máximo del GeneSet que se va a utilizar (los más generales tiene más genes y son menos informativos)\n              pvalueCutoff = 0.05,\n              verbose      = FALSE)\n\ngoplot(ego3)"
  },
  {
    "objectID": "RNAseq.html#kegg-analysis",
    "href": "RNAseq.html#kegg-analysis",
    "title": "Bulk RNAseq",
    "section": "4.3 Kegg Analysis",
    "text": "4.3 Kegg Analysis\nEl paquete clusterProfiler es compatible con todos los organismos que disponen de datos de anotación KEGG en la base de datos KEGG. Los usuarios deben pasar una abreviatura del nombre académico al parámetro organism. Como argumento podemos utilizar cualquier organimo disponible en la página oficial de Kegg. De igual manera que para el análisis de GO, para Kegg también tenemos dos tipos de análisis: análisis de sobre-representación de ruta Kegg o análisis de enriquecimiento de ruta Kegg.\n\n4.3.1 Análisis de sobre-representación de ruta Kegg\nSe realiza de igual forma que el análisis GO, solo cambian algunos argumentos:\n\nkk &lt;- enrichKEGG(gene         = gene,\n                 organism     = 'hsa',\n                 pvalueCutoff = 0.05)\n\nReading KEGG annotation online: \"https://rest.kegg.jp/link/hsa/pathway\"...\n\n\nWarning in utils::download.file(url, quiet = TRUE, method = method, ...): the\n'wininet' method is deprecated for http:// and https:// URLs\n\n\nReading KEGG annotation online: \"https://rest.kegg.jp/list/pathway/hsa\"...\n\n\nWarning in utils::download.file(url, quiet = TRUE, method = method, ...): the\n'wininet' method is deprecated for http:// and https:// URLs\n\nhead(kk)\n\n               ID                                          Description\nhsa04974 hsa04974                     Protein digestion and absorption\nhsa04512 hsa04512                             ECM-receptor interaction\nhsa04933 hsa04933 AGE-RAGE signaling pathway in diabetic complications\nhsa04510 hsa04510                                       Focal adhesion\nhsa04614 hsa04614                             Renin-angiotensin system\nhsa04972 hsa04972                                 Pancreatic secretion\n         GeneRatio  BgRatio       pvalue     p.adjust       qvalue\nhsa04974    14/254 103/8622 1.717518e-06 0.0004894926 0.0004429388\nhsa04512    11/254  89/8622 5.585111e-05 0.0079587828 0.0072018533\nhsa04933    11/254 100/8622 1.627960e-04 0.0154656239 0.0139947474\nhsa04510    16/254 203/8622 3.155103e-04 0.0224801093 0.0203421119\nhsa04614     5/254  23/8622 4.643925e-04 0.0264703711 0.0239528751\nhsa04972    10/254 102/8622 8.116272e-04 0.0330448219 0.0299020549\n                                                                                  geneID\nhsa04974          1803/1360/1297/486/1294/1282/1284/1296/7373/1287/50509/1288/91522/1308\nhsa04512                          1297/3908/3691/3655/1282/1284/1287/7058/1288/3371/3676\nhsa04933                          183/27035/7056/4313/5054/1282/3552/1284/1287/1288/3553\nhsa04510 1297/1950/3908/3691/2534/2316/3655/1282/1284/10398/1287/857/7058/1288/3371/3676\nhsa04614                                                          3817/183/3816/290/1636\nhsa04972                                  5320/952/885/1360/64600/489/5874/1056/486/3778\n         Count\nhsa04974    14\nhsa04512    11\nhsa04933    11\nhsa04510    16\nhsa04614     5\nhsa04972    10\n\n\nYa tenemos un listado de las listas más significativas, ahora podemos hacer cosas como habrír una ruta KEGG on line en la cual se nos indicarán nuestros genes en rojo. Tenemos que seleccionar alguna ruta que nos haya salido en el análisis de over-representation\n\nbrowseKEGG(kk, 'hsa04974')\n\n\n\n4.3.2 Análisis de enriquecimiento (GSEA) de ruta Kegg\nAhora haríamos el enriquecimiento:\n\nmkk2 &lt;- gseMKEGG(geneList = ENTREZ_geneList,\n                 organism = 'hsa',\n                 pvalueCutoff = 1)\n\nReading KEGG annotation online: \"https://rest.kegg.jp/link/hsa/module\"...\n\n\nWarning in utils::download.file(url, quiet = TRUE, method = method, ...): the\n'wininet' method is deprecated for http:// and https:// URLs\n\n\nReading KEGG annotation online: \"https://rest.kegg.jp/list/module\"...\n\n\nWarning in utils::download.file(url, quiet = TRUE, method = method, ...): the\n'wininet' method is deprecated for http:// and https:// URLs\n\n\npreparing geneSet collections...\n\n\nGSEA analysis...\n\n\nWarning in preparePathwaysAndStats(pathways, stats, minSize, maxSize, gseaParam, : There are ties in the preranked stats (5.53% of the list).\nThe order of those tied genes will be arbitrary, which may produce unexpected results.\n\n\nleading edge analysis...\n\n\ndone...\n\nhead(mkk2)\n\n           ID                                               Description setSize\nM00034 M00034                                Methionine salvage pathway      12\nM00912 M00912        NAD biosynthesis, tryptophan =&gt; quinolinate =&gt; NAD      10\nM00001 M00001 Glycolysis (Embden-Meyerhof pathway), glucose =&gt; pyruvate      19\nM00158 M00158                                 F-type ATPase, eukaryotes      17\nM00087 M00087                                            beta-Oxidation      12\nM00056 M00056                    O-glycan biosynthesis, mucin type core      22\n       enrichmentScore       NES      pvalue  p.adjust    qvalue rank\nM00034      -0.7783792 -1.663671 0.007399354 0.2811754 0.2726078 1249\nM00912       0.7626680  1.578876 0.016801718 0.3192326 0.3095053  729\nM00001      -0.6566308 -1.607879 0.025448676 0.3223499 0.3125276 4010\nM00158      -0.6162543 -1.459105 0.068464730 0.5000000 0.4847645 3945\nM00087       0.6450831  1.404235 0.086705202 0.5000000 0.4847645 3219\nM00056       0.5389875  1.381657 0.086080586 0.5000000 0.4847645 3022\n                         leading_edge\nM00034  tags=33%, list=8%, signal=31%\nM00912  tags=30%, list=5%, signal=29%\nM00001 tags=74%, list=26%, signal=55%\nM00158 tags=59%, list=26%, signal=44%\nM00087 tags=50%, list=21%, signal=40%\nM00056 tags=50%, list=20%, signal=40%\n                                                             core_enrichment\nM00034                                                  58478/4507/6723/4143\nM00912                                                        8564/3620/8942\nM00001 3098/5230/226/7167/5315/2821/2027/83440/2597/5214/2023/5223/2645/5213\nM00158                             521/498/509/515/4508/516/4509/506/518/513\nM00087                                              1962/33/10449/51/8310/37\nM00056     442117/117248/8693/51809/374378/192134/56913/9245/55568/2590/2589\n\n\nY podremos hacer cosas como la siguiente:\n\nhsa04110 &lt;- pathview(gene.data  = ENTREZ_geneList,\n                     pathway.id = \"hsa04974\",\n                     species    = \"hsa\",\n                     limit      = list(gene=max(abs(ENTREZ_geneList)), cpd=1))\n\n'select()' returned 1:1 mapping between keys and columns\n\n\nInfo: Working in directory E:/Accesos directos Importantes/R_Projects/Learning\n\n\nInfo: Writing image file hsa04974.pathview.png\n\n\nInfo: some node width is different from others, and hence adjusted!\n\nimage &lt;- image_read(\"E:/Accesos directos Importantes/Estancia CRG/Apuntes/3 Bulk RNAseq/R_workspace/hsa04974.pathview.png\")\nprint(image, info=FALSE)"
  },
  {
    "objectID": "RNAseq.html#gsea-analisis-msigdb",
    "href": "RNAseq.html#gsea-analisis-msigdb",
    "title": "Bulk RNAseq",
    "section": "4.4 GSEA Analisis (MSigDb)",
    "text": "4.4 GSEA Analisis (MSigDb)\nEste es el GSEA que conocemos de usarlo en el laboratorio. Creo que estabamos todos errados creyendo que erea el único GSEA que que existía porque ya estamos viendo que se puede hacer con cualquier base de datos. Este está basado en Molecular Signatures Database (MSigDb), que consiste en una colección gene sets con annotaciones a rutas. Como sabeis hay varias categorías de GSEA:\n\nH: hallmark gene sets\nC1: Gene Sets posicionales\nC2: Gene Sets curados\nC3: Gene Sets con motivos\nC4: Gene Sets computacionales\nC5: Gene Sets GO\nC6: signatures oncogénicas\nC7: signatures inmunológicas\n\nDe manera que antes de comezar a hacer cualquier tipo de análisis hay que definir la categoría que queremos analizar:\n\nGSEA_H &lt;- msigdbr(species = \"Homo sapiens\", category = \"H\") %&gt;% \n  dplyr::select(gs_name, entrez_gene)\n\n\nOver-representation\n\n\nem &lt;- enricher(gene, TERM2GENE=GSEA_H)\nhead(em)\n\n                                                                                   ID\nHALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION HALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION\nHALLMARK_MYOGENESIS                                               HALLMARK_MYOGENESIS\nHALLMARK_APICAL_JUNCTION                                     HALLMARK_APICAL_JUNCTION\nHALLMARK_COAGULATION                                             HALLMARK_COAGULATION\n                                                                          Description\nHALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION HALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION\nHALLMARK_MYOGENESIS                                               HALLMARK_MYOGENESIS\nHALLMARK_APICAL_JUNCTION                                     HALLMARK_APICAL_JUNCTION\nHALLMARK_COAGULATION                                             HALLMARK_COAGULATION\n                                           GeneRatio  BgRatio       pvalue\nHALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION    36/191 200/4383 6.292591e-14\nHALLMARK_MYOGENESIS                           19/191 200/4383 9.709807e-04\nHALLMARK_APICAL_JUNCTION                      18/191 200/4383 2.438629e-03\nHALLMARK_COAGULATION                          14/191 138/4383 2.474245e-03\n                                               p.adjust       qvalue\nHALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION 2.768740e-12 2.252085e-12\nHALLMARK_MYOGENESIS                        2.136158e-02 1.737544e-02\nHALLMARK_APICAL_JUNCTION                   2.721669e-02 2.213798e-02\nHALLMARK_COAGULATION                       2.721669e-02 2.213798e-02\n                                                                                                                                                                                                                            geneID\nHALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION 290/6641/3908/2817/3487/4232/2316/4312/10085/1462/5744/4313/6586/6422/3485/5054/1294/1282/26577/1893/1284/627/1296/1009/10398/11010/6678/7058/7169/3624/6424/50509/10631/3371/6876/4314\nHALLMARK_MYOGENESIS                                                                                                              25803/8912/4151/1837/11156/29970/3908/3691/6261/4842/10468/1284/6678/7169/165/2273/6876/3490/1012\nHALLMARK_APICAL_JUNCTION                                                                                                            1297/247/6376/3691/1825/84552/8745/1462/4313/5010/1009/10398/6624/11096/83700/143903/4318/1308\nHALLMARK_COAGULATION                                                                                                                                         1803/3158/4316/2534/2161/7056/4312/4313/5055/5054/6678/4319/4318/4314\n                                           Count\nHALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION    36\nHALLMARK_MYOGENESIS                           19\nHALLMARK_APICAL_JUNCTION                      18\nHALLMARK_COAGULATION                          14\n\n\n\nGSEA\n\n\nem2 &lt;- GSEA(ENTREZ_geneList, TERM2GENE = GSEA_H)\nhead(em2)\n\n                                                                                   ID\nHALLMARK_MYC_TARGETS_V1                                       HALLMARK_MYC_TARGETS_V1\nHALLMARK_MYC_TARGETS_V2                                       HALLMARK_MYC_TARGETS_V2\nHALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION HALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION\nHALLMARK_INTERFERON_GAMMA_RESPONSE                 HALLMARK_INTERFERON_GAMMA_RESPONSE\nHALLMARK_E2F_TARGETS                                             HALLMARK_E2F_TARGETS\nHALLMARK_BILE_ACID_METABOLISM                           HALLMARK_BILE_ACID_METABOLISM\n                                                                          Description\nHALLMARK_MYC_TARGETS_V1                                       HALLMARK_MYC_TARGETS_V1\nHALLMARK_MYC_TARGETS_V2                                       HALLMARK_MYC_TARGETS_V2\nHALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION HALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION\nHALLMARK_INTERFERON_GAMMA_RESPONSE                 HALLMARK_INTERFERON_GAMMA_RESPONSE\nHALLMARK_E2F_TARGETS                                             HALLMARK_E2F_TARGETS\nHALLMARK_BILE_ACID_METABOLISM                           HALLMARK_BILE_ACID_METABOLISM\n                                           setSize enrichmentScore       NES\nHALLMARK_MYC_TARGETS_V1                        196      -0.6838009 -2.489573\nHALLMARK_MYC_TARGETS_V2                         56      -0.7829536 -2.414040\nHALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION     186      -0.6521398 -2.375884\nHALLMARK_INTERFERON_GAMMA_RESPONSE             183       0.5484440  1.958478\nHALLMARK_E2F_TARGETS                           197      -0.5122329 -1.864917\nHALLMARK_BILE_ACID_METABOLISM                   98       0.5695655  1.879411\n                                                 pvalue     p.adjust\nHALLMARK_MYC_TARGETS_V1                    1.000000e-10 1.666667e-09\nHALLMARK_MYC_TARGETS_V2                    1.000000e-10 1.666667e-09\nHALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION 1.000000e-10 1.666667e-09\nHALLMARK_INTERFERON_GAMMA_RESPONSE         5.430636e-08 6.788294e-07\nHALLMARK_E2F_TARGETS                       2.693936e-07 2.693936e-06\nHALLMARK_BILE_ACID_METABOLISM              1.914285e-05 1.595237e-04\n                                                 qvalue rank\nHALLMARK_MYC_TARGETS_V1                    7.017544e-10 4003\nHALLMARK_MYC_TARGETS_V2                    7.017544e-10 1673\nHALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION 7.017544e-10 1033\nHALLMARK_INTERFERON_GAMMA_RESPONSE         2.858229e-07 3922\nHALLMARK_E2F_TARGETS                       1.134289e-06 4265\nHALLMARK_BILE_ACID_METABOLISM              6.716788e-05 2408\n                                                             leading_edge\nHALLMARK_MYC_TARGETS_V1                    tags=76%, list=26%, signal=57%\nHALLMARK_MYC_TARGETS_V2                    tags=71%, list=11%, signal=64%\nHALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION  tags=34%, list=7%, signal=32%\nHALLMARK_INTERFERON_GAMMA_RESPONSE         tags=51%, list=25%, signal=38%\nHALLMARK_E2F_TARGETS                       tags=52%, list=28%, signal=38%\nHALLMARK_BILE_ACID_METABOLISM              tags=36%, list=16%, signal=30%\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          core_enrichment\nHALLMARK_MYC_TARGETS_V1                    5230/6637/5887/6164/6626/5683/6434/65005/890/8894/9377/6428/11335/6175/5704/7514/26354/10935/4999/6629/5709/23435/3183/7419/2079/7555/6634/6141/10213/4176/3838/26986/2935/7411/6627/8454/9868/57819/4686/1977/5688/5496/6204/5707/23196/3608/8669/7458/220988/26121/22916/6146/6194/10907/5478/2058/4706/3066/3735/7307/4173/2806/6128/2547/6188/10155/7965/7203/8664/6427/10921/7284/10549/10971/6432/10728/3178/1965/1537/22948/23016/9045/6741/10054/3184/3192/3336/10574/2107/10399/10575/5634/6193/51690/11331/6633/54107/11260/1964/7416/23450/10576/10528/51020/6418/3837/1207/26156/4953/7027/6950/10856/8886/3326/6632/1973/8662/3615/8761/6059/26135/11137/1933/5245/5901/10146/5425/55651/5036/3251/3329/4830/708/4869/4673/10492/9188/51491/1503/9221/2091/1019/4609/4175/4171/790/5902/9136/6723\nHALLMARK_MYC_TARGETS_V2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       3336/3177/6832/83743/64216/9238/79077/2193/4839/10528/81887/8886/29078/705/92856/23481/5245/10171/5036/56915/23160/10196/3329/6949/51388/27340/80324/4869/51491/56342/9221/51154/1019/6573/4609/10514/23223/10244/9136/6723\nHALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION                                                                                                                                                                                                                                                                                                                                                                                                                                                                             7980/3909/2014/3688/25878/1647/79709/5654/2192/30008/10272/1000/6382/4016/1303/2882/649/374/4035/3491/2697/284217/22943/3956/7040/667/6591/7078/800/3908/2817/3487/4232/2316/4312/10085/1462/5744/4313/6586/6422/3485/5054/1294/1282/26577/1893/1284/627/1296/1009/10398/11010/6678/7058/7169/3624/6424/50509/10631/3371/6876/4314\nHALLMARK_INTERFERON_GAMMA_RESPONSE                                                                                                                                                                                                                                                                                                               952/6398/3620/3108/8743/629/219285/81030/55024/972/4261/5142/57674/716/10906/10875/669/3569/710/5359/94240/8767/8673/3430/5777/1439/3627/837/84159/10628/840/80830/4283/3394/4939/10561/3123/115361/91543/3429/55601/5699/6373/54625/3717/3091/3431/6772/9246/55008/3383/3665/9111/7127/6773/5743/6774/129607/5698/10964/3600/3669/4600/8202/23424/10437/9961/3117/7130/10791/684/6775/84166/27348/23586/9021/3455/4061/57169/3434/836/841/57162/10135/6347/3437/116071/10379/8082/64761/567/7453/317649\nHALLMARK_E2F_TARGETS                                                                                                                                                                                                                                                                            11004/9700/3159/6426/79075/4085/332/3014/675/5511/6434/6839/11200/9126/5347/10733/6790/9212/10274/5982/7514/4999/983/1164/6241/5395/147841/51155/55635/4176/3838/2935/9837/7374/23468/7884/5631/4678/11340/27338/23649/3930/84844/10527/580/51747/4173/2547/9972/6427/7153/10212/5411/10549/11051/29893/10111/57122/84312/204/1965/79677/9125/23165/1633/701/6628/3609/3184/1111/3070/5424/9238/54962/79077/4172/1786/10460/10528/10797/64785/6749/5591/1434/5901/5425/5036/7037/4830/4673/10492/10606/1503/9221/1019/4609/4175/55646/4171/5902/9319/9232\nHALLMARK_BILE_ACID_METABOLISM                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         8630/9963/189/27232/51170/51302/367/1718/8800/1593/654/24/3417/3418/2053/3992/9415/51703/2180/4306/3295/847/92960/1734/6342/3932/5825/5194/10133/2730/11001/50640/23461/80270/23600"
  },
  {
    "objectID": "RNAseq.html#network-of-cancer-genes-ncg-analisis",
    "href": "RNAseq.html#network-of-cancer-genes-ncg-analisis",
    "title": "Bulk RNAseq",
    "section": "4.5 Network of Cancer Genes (NCG) Analisis",
    "text": "4.5 Network of Cancer Genes (NCG) Analisis\nNetwork of Cancer Gene (NCG) (A. et al. 2016) es un repositorio generado de forma naualde genes implicados en cáncer. La versión 5.0 de NCG (agosto de 2015) recoge 1.571 genes del cáncer de 175 estudios publicados. El paquete DOSE permite analizar la lista de genes y determinar si están enriquecidos en genes que se sabe que están mutados en un determinado tipo de cáncer.\nTambién podemos realizar los dos tipos de análisis:\n\nOver-representation\n\n\nedo&lt;-enrichNCG(gene)\nhead(edo)\n\n[1] ID          Description GeneRatio   BgRatio     pvalue      p.adjust   \n[7] qvalue      geneID      Count      \n&lt;0 rows&gt; (or 0-length row.names)\n\n\n\nGSEA\n\n\nncg &lt;- gseNCG(ENTREZ_geneList,\n              pvalueCutoff  = 0.5,\n              pAdjustMethod = \"BH\",\n              verbose       = FALSE)\nncg &lt;- setReadable(ncg, 'org.Hs.eg.db')\nhead(ncg, 3)\n\n                                                       ID\nchronic_myeloid_leukemia         chronic_myeloid_leukemia\nlung_squamous_cell_carcinoma lung_squamous_cell_carcinoma\noral_squamous_cell_carcinoma oral_squamous_cell_carcinoma\n                                              Description setSize\nchronic_myeloid_leukemia         chronic_myeloid_leukemia      25\nlung_squamous_cell_carcinoma lung_squamous_cell_carcinoma      20\noral_squamous_cell_carcinoma oral_squamous_cell_carcinoma      10\n                             enrichmentScore       NES      pvalue  p.adjust\nchronic_myeloid_leukemia          -0.6899982 -1.814588 0.001463396 0.1184472\nlung_squamous_cell_carcinoma      -0.6855268 -1.697221 0.004298044 0.1184472\noral_squamous_cell_carcinoma      -0.7839883 -1.682306 0.005573988 0.1184472\n                                qvalue rank                  leading_edge\nchronic_myeloid_leukemia     0.1056124  209 tags=36%, list=1%, signal=36%\nlung_squamous_cell_carcinoma 0.1056124 1398 tags=30%, list=9%, signal=27%\noral_squamous_cell_carcinoma 0.1056124  609 tags=20%, list=4%, signal=19%\n                                                                  core_enrichment\nchronic_myeloid_leukemia     MSH6/FGF2/UCHL5/NR3C1/SETBP1/COL7A1/FAT3/CSPG4/CSMD2\nlung_squamous_cell_carcinoma                  ZNF521/EPB41L3/FAT4/NAV3/WIF1/CDH11\noral_squamous_cell_carcinoma                                            HRAS/TP63"
  },
  {
    "objectID": "RNAseq.html#graficando-los-análisis-de-over-representation-y-gsea",
    "href": "RNAseq.html#graficando-los-análisis-de-over-representation-y-gsea",
    "title": "Bulk RNAseq",
    "section": "4.6 Graficando los análisis de Over-representation y GSEA",
    "text": "4.6 Graficando los análisis de Over-representation y GSEA\nTambién podemos hacer la representación de los datos con distintos tipos de gráficas, que por ejemplo lo vamos a hacer con el dataset que hemos creado para KEGG: - Barplot\n\n#imput Over-representatition\nbarplot(kk, showCategory = 20)\n\n\n\n\n\n#imput Over-representatition\nmutate(kk, q_score = -log(p.adjust, base=10)) %&gt;% \n    barplot(x=\"q_score\")\n\n\n\n\n\nDot plot (bubble-plot)\n\n\n#imput Over-representation y GSEA\n#En este caso, imput over-representation\ndotplot(kk, showCategory=10) + ggtitle(\"dotplot for Kegg GSEA \\n Analisis\")\n\n\n\n\n\n#imput GSEA\ndotplot(mkk2, showCategory=10) + ggtitle(\"dotplot for Kegg GSEA \\n Analisis\")\n\n\n\n\n\nGene-Concept Network:\n\n\n#imput Over-representatition y GSEA\n## convert gene ID to Symbol\nedox &lt;- setReadable(mkk2, 'org.Hs.eg.db', 'ENTREZID')\ncnetplot(edox, foldChange=ENTREZ_geneList)\n\n\n\n\n\n## categorySize can be scaled by 'pvalue' or 'geneNum'\ncnetplot(edox, categorySize=\"pvalue\", foldChange=geneList)\n\n\n\n\n\ncnetplot(edox, foldChange=ENTREZ_geneList, circular = TRUE, colorEdge = TRUE,\n         cex.params = list(category_node = 0.5, gene_node = 0.25, category_label = 1, gene_label = 0.3)) \n\n\n\n\n\nHeatmap-like functional classification\n\n\n#imput Over-representatition y GSEA\nheatplot(edox, foldChange=ENTREZ_geneList, showCategory=5)\n\n\n\n\nTree plot: realiza un clasificación no supervisada de los téminos enriquecidos en base a las similitudes entre términos\n\n#imput Over-representatition y GSEA\nedox2 &lt;- pairwise_termsim(edox)\ntreeplot(edox2, hclust_method = \"average\")\n\n\n\n\n\nRidgeline\n\n\n#imput GSEA\nridgeplot(\n  mkk2,\n  showCategory = 8,\n  fill = \"p.adjust\",\n  core_enrichment = TRUE,\n  label_format = 40,\n  orderBy = \"NES\",\n  decreasing = FALSE\n)\n\nPicking joint bandwidth of 0.325"
  },
  {
    "objectID": "AS_Analysis.html",
    "href": "AS_Analysis.html",
    "title": "Alternative Splicing",
    "section": "",
    "text": "Matt es un paquete diseñado por Dr. Manuel Irimia para el análisis de eventos de splicing alternativo. Incluye funciones básicas para la manipulación de tablas, extracción de características relacionadas con exones e intrones, análisis de características discriminantes, mapas de motivos para proteínas de unión a ARN, etc. Cita:\n\nGohr, A., & Irimia, M. (2019). Matt: Unix tools for alternative splicing analysis. Bioinformatics (Oxford, England), 35(1), 130–132. https://doi.org/10.1093/bioinformatics/bty606\n\n\n\n\n\n\n\nTrabajamos en Terminal\n\n\n\n\n\n\n\n\nEn el terminal, nos movemos a la carpeta donde queramos guardar Matt en nuestro ordenador o superordenador. Una vez ahí tenemos que crear un clon del repositorio de git:\n\ngit clone https://gitlab.com/aghr/matt.git\n\nA continuación, tenemos que ejecutar el script de instalación:\n\nchmod u+rwx ./INSTALL\n\nY corremos el script:\n\n./INSTALL\n\nUna vez tengamos instalado Matt temenos que hacer que sus funciones formen parte del PATH para que se pueda ejecutar desde cualquier carpeta. Esto lo hacemos con la siguiente línea de comandos:\n\nexport PATH=~/directorio/donde/hayas/guardado/matt:$PATH\necho 'export PATH=~ directorio/donde/hayas/guardado/matt:$PATH' &gt;&gt; ~/.bashrc\n\nPara comprobar que temenos matt instalado Podemos hacer la prueba de esctibir en el terminal el propio nombre:\n\nmatt\n\nY el output que nos debe devolver es el siguiente:\n\nMatt v. 1.3.1\n\nUsage: matt &lt;command&gt; ...\n\nCommands:\n\n*Import data / check table                             *Maths and statistics\n  chk_nls:  check newlines in table                      col_calc:  apply calculations to columns\n.\n.\n..\n.\n.\n  test_regexp_enrich: test REGEXP enrichment\n\nAttention: Tables processed by Matt must contain a header with column names and must not contain \" characters with exception of regular expressions. All other \" characters will be ignored and removed. When using MS Excel for table generation, please save tables in format Windows Text. Matt recognizes Windows newlines, but not DOS nor old-style MacOS newlines (CR or \\r only). Use command chk_nls to see and check newlines in tables.\n\nUna vez instalado matt, es necesario comprobar que temenos instalado una de las herramientas del NCBI que es la que utiliza para funcionar: SRA-Tool Kit.\n\n\n\nPara comprobar si la temenos, en debemos hacer la prueba de esctibir en el terminal una de sus funciones, como por ejemplo:\n\nsra\n\nY el output que nos debe devolver es el siguiente:\n\nsra-pileup             sra-search.3           sra-sort-cg.3.0.7      sra-stat.3.0.7         sratools.3.0.7\nsra-pileup-orig.3.0.7  sra-search.3.0.7       sra-sort.3             srapath\nsra-pileup.3           sra-sort               sra-sort.3.0.7         srapath-orig.3.0.7\nsra-pileup.3.0.7       sra-sort-cg            sra-stat               srapath.3\nsra-search             sra-sort-cg.3          sra-stat.3             srapath.3.0.7\n\nTambién debemos comprobar la versión de que tenemos instalada (debe de ser superior a la 2.8.0):\n\nvdb-config –version\n\nEl output será el siguiente:\n\nSRA-Toolkit 3.0.7\n\nSi tienes la última versión guay, sino tienes que instalarla mediante los siguientes comandos en el terminal (comando cogidos de la página oficial para Linux, si tienes Mac o Windows busca en la página principal de SRA (enlace) la forma de instalarlo).\nPrimero descargamos la herramienta (recomendable crear una carpeta donde meterlo)\n\nwget --output-document sratoolkit.tar.gz https://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-ubuntu64.tar.gz\n\nA continuación lo instalamos:\n\ntar -vxzf sratoolkit.tar.gz\n\nA continuación metemos la herramienta en el PATH:\n\nexport PATH=~/directorio/donde/hayas/guardado/sratoolkit.current-ubuntu64.tar.gz/bin:$PATH\necho 'export PATH=~ directorio/donde/hayas/guardado/sratoolkit.current-ubuntu64.tar.gz/bin:$PATH' &gt;&gt; ~/.bashrc\n\nA continuación es recommendable comprobar que funciona:\n\nwhich fastq-dump\n\nEl output será el siguiente:\n\n/Users/JoeUser/sratoolkit.current-ubuntu64.tar.gz/bin /fastq-dump\n\nTambién podemos probar que sea funcional:\n\nfastq-dump --stdout -X 2 SRR390728\n\nEl output será el siguiente:\n\nRead 2 spots for SRR390728\nWritten 2 spots for SRR390728\n@SRR390728.1 1 length=72\nCATTCTTCACGTAGTTCTCGAGCCTTGGTTTTCAGCGATGGAGAATGACTTTGACAAGCTGAGAGAAGNTNC\n+SRR390728.1 1 length=72\n;;;;;;;;;;;;;;;;;;;;;;;;;;;9;;665142;;;;;;;;;;;;;;;;;;;;;;;;;;;;;96&&&&(\n@SRR390728.2 2 length=72\nAAGTAGGTCTCGTCTGTGTTTTCTACGAGCTTGTGTTCCAGCTGACCCACTCCCTGGGTGGGGGGACTGGGT\n+SRR390728.2 2 length=72\n;;;;;;;;;;;;;;;;;4;;;;3;393.1+4&&5&&;;;;;;;;;;;;;;;;;;;;;&lt;9;&lt;;;;;;464262\n\n\n\n\n\n\n\nNote\n\n\n\nTodo lo hecho a partir de aquí está en:\nTerminal_9-14-23.txt\n\n\n\n\n\nPara cargar los datos vamos a usar una función de matt (retr_rnaseq) que permite al usuario recuperar datos de ARN-seq del Gene Expression Omnibus (GEO), un repositorio público donde muchos investigadores almacenan sus datos de ARN-seq relacionados con sus publicaciones. Teniendo a mano los números de acceso GEO de los conjuntos de datos RNA-seq, este comando descarga los archivos SRA, extrae las lecturas de ARN-seq como archivos FASTQ o FASTA y, si lo desea renombra los archivos FASTA/FASTQ extraídos como especifique el usuario.\nPara ello tenemos que crear un .txt (con los nombres separados por un tab) como en el ejemplo:\n\n\n\nImagen 1\n\n\nUna vez que lo tenemos creado tenemos que subirlo a la misma carpeta en la que vayamos a hacer la descarga de los datos y los análisis. El siguiente paso es descargar de GEO los .gz de las muestras seleccionadas:\n\nmatt retr_rnaseq accession_numbers.txt -keepsra -o rnaseq_data -p 6\n\nCon este comando lo que hacemos es que se descarguen lo indicado (indicando el documento en el que se encuentran los datos, sin borrar los archivos SRA (-keepsra) en una carpeta nueva (-o rnaseq_data) y que el trabajo se divida entre 6 cores del superordenador (-p 6)\nEste comando tarda bastante por lo que es recomendable usar los siguientes comandos para poner en segundo plano un trabajo y desvincularlos de la sesión de trabajo, lo cual es recomendable porque nos permitirá continuar trabajando en el servidor mientras se están ejecutando los trabajos mandados. Otra ventaja es que, al desvincularlos de la sesión de trabajo podremos cerrar el terminal sin preocuparnos de que se paren los procesos. Si cerráramos el terminal sin desvincular el trabajo de nuestra sesión (la sesión está asociada al terminal de trabajo) este trabajo se interrumpiría en el momento de cerrar el terminal (y, por lo tanto, la sesión). Para ello debemos ejecutar lo siguientes comandos:\n\nEjecutamos el trabajo que queramos hacer, en nuestro caso usaremos el ejemplo anterior:\n\n\nmatt retr_rnaseq accession_numbers.txt -keepsra -o rnaseq_data -p 6\n\n\nTras esto comenzará a ejecutarse. En este momento tenemos que parar el proceso con la combinación de teclas Control + z. El output debe ser el siguiente:\n\n\n[1]+  Stopped                 matt retr_rnaseq accession_numbers.txt -keepsra -o rnaseq_data -p 6\n\n\nEn este punto tendremos el proceso parado y podremos escribir comandos. Lo siguiente que debemos hacer es mandar el trabajo a ejecutarse en segundo plano (mandar al background) con el siguiente comando:\n\n\nbg\n\n#Output:\n\n[1]+ matt retr_rnaseq accession_numbers.txt -keepsra -o rnaseq_data -p 6 &\n  \n#Y significará que se ha reanudado la ejecución en segundo plano. \n\n\n\n\n\n\n\nTip\n\n\n\nY significará que se ha reanudado la ejecución en segundo plano.\n\nmatt retr_rnaseq accession_numbers.txt -keepsra -o rnaseq_data -p 6 &\n\n\n\n\nUna vez que hayamos ejecutado el proceso en segundo plano pasamos al siguiente paso que es desvincular el proceso del terminal (sesión) en el que lo hemos corrido para que continúe ejecutándose si cerramos sesión. Para ello usamos el comando:\n\n\ndisown\n\nEl output del terminal no se guardará en ningún lado si los cerramos (el terminal) de manera que si queremos dejar un proceso funcionando y luego poder consultar qué mensajes nos ha dado el proceso (para chequear si ha ido bien o ha habido algún error durante el procesamiento). Podemos hacer que los mensajes que saldrían en el terminal se guarden en un .txt para luego poder consultarlos utilizando el siguiente comando:\n\nProceso_mandado_a_ejecutar 1&gt;Nombre_que_le_quieras_poner_al_documento.out\n\nEste comando debe de utilizarse de la siguiente manera (en el siguiente ejemplo mi documento se llamará documento_ejemplo.out y lo voy a ejecutar directamente en segundo plano con el comando “&” previamente explicado):\n\nmatt retr_rnaseq accession_numbers.txt -keepsra -o rnaseq_data -p 6 1&gt;documento_ejemplo.out &\n\nCon esto haremos que se guarde un documento .out (que se puede leer como .txt) en la carpeta en la que estemos trabajando y que el proceso se lance directamente en segundo plano por lo que solo necesitaríamos aplicar el comando disown para desvincularlo de la sesión y podremos descuidarnos.\nLos datos se nos descargaran en la carpeta rnaseq_data que hemos escrito en el código ejecutado. Cuando finalice, accedemos a esa carpeta y ejecutamos el comando ls (para ver el listado de archivos que contiene esta carpeta) veremos lo siguiente:\n\nBasal_2_1.fastq.gz      Luminal_1_1.fastq.gz        Luminal_2_1.fastq.gz    SRR1919599.sra      SRR1919603.sra\nBasal_2_2.fastq.gz      Luminal_2_2.fastq.gz    SRR1919600.sra          SRR1919604.sra  dataset_info.tab\nBasal_1_1.fastq.gz              Basal_3_1.fastq.gz          Luminal_3_1.fastq.gz    SRR1919601.sra      Basal_1_2.fastq.gz          \nBasal_3_2.fastq.gz      Luminal_1_2.fastq.gz        Luminal_3_2.fastq.gz    SRR1919602.sra  \n\nUna vez en este punto comenzaremos el alineamiento con Vast-Tools."
  },
  {
    "objectID": "AS_Analysis.html#instalación-de-matt",
    "href": "AS_Analysis.html#instalación-de-matt",
    "title": "Alternative Splicing",
    "section": "",
    "text": "En el terminal, nos movemos a la carpeta donde queramos guardar Matt en nuestro ordenador o superordenador. Una vez ahí tenemos que crear un clon del repositorio de git:\n\ngit clone https://gitlab.com/aghr/matt.git\n\nA continuación, tenemos que ejecutar el script de instalación:\n\nchmod u+rwx ./INSTALL\n\nY corremos el script:\n\n./INSTALL\n\nUna vez tengamos instalado Matt temenos que hacer que sus funciones formen parte del PATH para que se pueda ejecutar desde cualquier carpeta. Esto lo hacemos con la siguiente línea de comandos:\n\nexport PATH=~/directorio/donde/hayas/guardado/matt:$PATH\necho 'export PATH=~ directorio/donde/hayas/guardado/matt:$PATH' &gt;&gt; ~/.bashrc\n\nPara comprobar que temenos matt instalado Podemos hacer la prueba de esctibir en el terminal el propio nombre:\n\nmatt\n\nY el output que nos debe devolver es el siguiente:\n\nMatt v. 1.3.1\n\nUsage: matt &lt;command&gt; ...\n\nCommands:\n\n*Import data / check table                             *Maths and statistics\n  chk_nls:  check newlines in table                      col_calc:  apply calculations to columns\n.\n.\n..\n.\n.\n  test_regexp_enrich: test REGEXP enrichment\n\nAttention: Tables processed by Matt must contain a header with column names and must not contain \" characters with exception of regular expressions. All other \" characters will be ignored and removed. When using MS Excel for table generation, please save tables in format Windows Text. Matt recognizes Windows newlines, but not DOS nor old-style MacOS newlines (CR or \\r only). Use command chk_nls to see and check newlines in tables.\n\nUna vez instalado matt, es necesario comprobar que temenos instalado una de las herramientas del NCBI que es la que utiliza para funcionar: SRA-Tool Kit."
  },
  {
    "objectID": "AS_Analysis.html#instalación-de-sra-toolkit",
    "href": "AS_Analysis.html#instalación-de-sra-toolkit",
    "title": "Alternative Splicing",
    "section": "",
    "text": "Para comprobar si la temenos, en debemos hacer la prueba de esctibir en el terminal una de sus funciones, como por ejemplo:\n\nsra\n\nY el output que nos debe devolver es el siguiente:\n\nsra-pileup             sra-search.3           sra-sort-cg.3.0.7      sra-stat.3.0.7         sratools.3.0.7\nsra-pileup-orig.3.0.7  sra-search.3.0.7       sra-sort.3             srapath\nsra-pileup.3           sra-sort               sra-sort.3.0.7         srapath-orig.3.0.7\nsra-pileup.3.0.7       sra-sort-cg            sra-stat               srapath.3\nsra-search             sra-sort-cg.3          sra-stat.3             srapath.3.0.7\n\nTambién debemos comprobar la versión de que tenemos instalada (debe de ser superior a la 2.8.0):\n\nvdb-config –version\n\nEl output será el siguiente:\n\nSRA-Toolkit 3.0.7\n\nSi tienes la última versión guay, sino tienes que instalarla mediante los siguientes comandos en el terminal (comando cogidos de la página oficial para Linux, si tienes Mac o Windows busca en la página principal de SRA (enlace) la forma de instalarlo).\nPrimero descargamos la herramienta (recomendable crear una carpeta donde meterlo)\n\nwget --output-document sratoolkit.tar.gz https://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-ubuntu64.tar.gz\n\nA continuación lo instalamos:\n\ntar -vxzf sratoolkit.tar.gz\n\nA continuación metemos la herramienta en el PATH:\n\nexport PATH=~/directorio/donde/hayas/guardado/sratoolkit.current-ubuntu64.tar.gz/bin:$PATH\necho 'export PATH=~ directorio/donde/hayas/guardado/sratoolkit.current-ubuntu64.tar.gz/bin:$PATH' &gt;&gt; ~/.bashrc\n\nA continuación es recommendable comprobar que funciona:\n\nwhich fastq-dump\n\nEl output será el siguiente:\n\n/Users/JoeUser/sratoolkit.current-ubuntu64.tar.gz/bin /fastq-dump\n\nTambién podemos probar que sea funcional:\n\nfastq-dump --stdout -X 2 SRR390728\n\nEl output será el siguiente:\n\nRead 2 spots for SRR390728\nWritten 2 spots for SRR390728\n@SRR390728.1 1 length=72\nCATTCTTCACGTAGTTCTCGAGCCTTGGTTTTCAGCGATGGAGAATGACTTTGACAAGCTGAGAGAAGNTNC\n+SRR390728.1 1 length=72\n;;;;;;;;;;;;;;;;;;;;;;;;;;;9;;665142;;;;;;;;;;;;;;;;;;;;;;;;;;;;;96&&&&(\n@SRR390728.2 2 length=72\nAAGTAGGTCTCGTCTGTGTTTTCTACGAGCTTGTGTTCCAGCTGACCCACTCCCTGGGTGGGGGGACTGGGT\n+SRR390728.2 2 length=72\n;;;;;;;;;;;;;;;;;4;;;;3;393.1+4&&5&&;;;;;;;;;;;;;;;;;;;;;&lt;9;&lt;;;;;;464262\n\n\n\n\n\n\n\nNote\n\n\n\nTodo lo hecho a partir de aquí está en:\nTerminal_9-14-23.txt"
  },
  {
    "objectID": "AS_Analysis.html#cargar-los-datos-del-dataset-seleccionados",
    "href": "AS_Analysis.html#cargar-los-datos-del-dataset-seleccionados",
    "title": "Alternative Splicing",
    "section": "",
    "text": "Para cargar los datos vamos a usar una función de matt (retr_rnaseq) que permite al usuario recuperar datos de ARN-seq del Gene Expression Omnibus (GEO), un repositorio público donde muchos investigadores almacenan sus datos de ARN-seq relacionados con sus publicaciones. Teniendo a mano los números de acceso GEO de los conjuntos de datos RNA-seq, este comando descarga los archivos SRA, extrae las lecturas de ARN-seq como archivos FASTQ o FASTA y, si lo desea renombra los archivos FASTA/FASTQ extraídos como especifique el usuario.\nPara ello tenemos que crear un .txt (con los nombres separados por un tab) como en el ejemplo:\n\n\n\nImagen 1\n\n\nUna vez que lo tenemos creado tenemos que subirlo a la misma carpeta en la que vayamos a hacer la descarga de los datos y los análisis. El siguiente paso es descargar de GEO los .gz de las muestras seleccionadas:\n\nmatt retr_rnaseq accession_numbers.txt -keepsra -o rnaseq_data -p 6\n\nCon este comando lo que hacemos es que se descarguen lo indicado (indicando el documento en el que se encuentran los datos, sin borrar los archivos SRA (-keepsra) en una carpeta nueva (-o rnaseq_data) y que el trabajo se divida entre 6 cores del superordenador (-p 6)\nEste comando tarda bastante por lo que es recomendable usar los siguientes comandos para poner en segundo plano un trabajo y desvincularlos de la sesión de trabajo, lo cual es recomendable porque nos permitirá continuar trabajando en el servidor mientras se están ejecutando los trabajos mandados. Otra ventaja es que, al desvincularlos de la sesión de trabajo podremos cerrar el terminal sin preocuparnos de que se paren los procesos. Si cerráramos el terminal sin desvincular el trabajo de nuestra sesión (la sesión está asociada al terminal de trabajo) este trabajo se interrumpiría en el momento de cerrar el terminal (y, por lo tanto, la sesión). Para ello debemos ejecutar lo siguientes comandos:\n\nEjecutamos el trabajo que queramos hacer, en nuestro caso usaremos el ejemplo anterior:\n\n\nmatt retr_rnaseq accession_numbers.txt -keepsra -o rnaseq_data -p 6\n\n\nTras esto comenzará a ejecutarse. En este momento tenemos que parar el proceso con la combinación de teclas Control + z. El output debe ser el siguiente:\n\n\n[1]+  Stopped                 matt retr_rnaseq accession_numbers.txt -keepsra -o rnaseq_data -p 6\n\n\nEn este punto tendremos el proceso parado y podremos escribir comandos. Lo siguiente que debemos hacer es mandar el trabajo a ejecutarse en segundo plano (mandar al background) con el siguiente comando:\n\n\nbg\n\n#Output:\n\n[1]+ matt retr_rnaseq accession_numbers.txt -keepsra -o rnaseq_data -p 6 &\n  \n#Y significará que se ha reanudado la ejecución en segundo plano. \n\n\n\n\n\n\n\nTip\n\n\n\nY significará que se ha reanudado la ejecución en segundo plano.\n\nmatt retr_rnaseq accession_numbers.txt -keepsra -o rnaseq_data -p 6 &\n\n\n\n\nUna vez que hayamos ejecutado el proceso en segundo plano pasamos al siguiente paso que es desvincular el proceso del terminal (sesión) en el que lo hemos corrido para que continúe ejecutándose si cerramos sesión. Para ello usamos el comando:\n\n\ndisown\n\nEl output del terminal no se guardará en ningún lado si los cerramos (el terminal) de manera que si queremos dejar un proceso funcionando y luego poder consultar qué mensajes nos ha dado el proceso (para chequear si ha ido bien o ha habido algún error durante el procesamiento). Podemos hacer que los mensajes que saldrían en el terminal se guarden en un .txt para luego poder consultarlos utilizando el siguiente comando:\n\nProceso_mandado_a_ejecutar 1&gt;Nombre_que_le_quieras_poner_al_documento.out\n\nEste comando debe de utilizarse de la siguiente manera (en el siguiente ejemplo mi documento se llamará documento_ejemplo.out y lo voy a ejecutar directamente en segundo plano con el comando “&” previamente explicado):\n\nmatt retr_rnaseq accession_numbers.txt -keepsra -o rnaseq_data -p 6 1&gt;documento_ejemplo.out &\n\nCon esto haremos que se guarde un documento .out (que se puede leer como .txt) en la carpeta en la que estemos trabajando y que el proceso se lance directamente en segundo plano por lo que solo necesitaríamos aplicar el comando disown para desvincularlo de la sesión y podremos descuidarnos.\nLos datos se nos descargaran en la carpeta rnaseq_data que hemos escrito en el código ejecutado. Cuando finalice, accedemos a esa carpeta y ejecutamos el comando ls (para ver el listado de archivos que contiene esta carpeta) veremos lo siguiente:\n\nBasal_2_1.fastq.gz      Luminal_1_1.fastq.gz        Luminal_2_1.fastq.gz    SRR1919599.sra      SRR1919603.sra\nBasal_2_2.fastq.gz      Luminal_2_2.fastq.gz    SRR1919600.sra          SRR1919604.sra  dataset_info.tab\nBasal_1_1.fastq.gz              Basal_3_1.fastq.gz          Luminal_3_1.fastq.gz    SRR1919601.sra      Basal_1_2.fastq.gz          \nBasal_3_2.fastq.gz      Luminal_1_2.fastq.gz        Luminal_3_2.fastq.gz    SRR1919602.sra  \n\nUna vez en este punto comenzaremos el alineamiento con Vast-Tools."
  },
  {
    "objectID": "AS_Analysis.html#instalación-de-vast-tools",
    "href": "AS_Analysis.html#instalación-de-vast-tools",
    "title": "Alternative Splicing",
    "section": "2.1 Instalación de Vast-Tools",
    "text": "2.1 Instalación de Vast-Tools\nEn el terminal, tenemos que crear un clon del repositorio de git:\n\ngit clone https://github.com/vastgroup/vast-tools.git\n\nEsto nos va a crear una carpeta en el directorio donde hagamos la clonación que se llamará vast-tools. Debemos acceder a esta carpeta y tenemos que crear una nueva carpeta que se llame “VASTDB” (con el comando mkdir VASTDB) con el cual tenemos que ejecutar los siguientes comandos:\n\nwget https://vastdb.crg.eu/libs/vastdb.hs2.23.06.20.tar.gz\n\nwget https://vastdb.crg.eu/libs/vastdb.mm2.23.06.20.tar.gz\n\nwget https://vastdb.crg.eu/libs/vastdb.rno.23.06.20.tar.gz\n\nCon esto hemos instalado las librerías para hacer el alineamiento en humano (última vesión del genoma), en ratón y en rata, respectivamente. Si necesitamos realizar alineamientos con otras especies hay que acceder el github de Vast-Tolols.\nUna vez hemos instalado esto tenemos que añadir Vast-Tools al PATH para que se pueda ejecutar desde cualquier carpeta. Esto lo hacemos con la siguiente línea de comandos:\n\nexport PATH=~/directorio/donde/hayas/guardado/vast-tools:$PATH\n\necho 'export PATH=~ directorio/donde/hayas/guardado/ vast-tools:$PATH' &gt;&gt; ~/.bashrc\n\nPara comprobar que temenos matt instalado Podemos hacer la prueba de esctibir en el terminal el propio nombre:\n\nVast-tools\n\nY el output que nos debe devolver es el siguiente:\n\nVAST-TOOLS v2.5.1\n\nUsage: vast-tools sub-commands [options]\n\n[sub-commands]\n        align           :       Align RNA-Seq reads to exon-exon junctions and quantify AS\n        merge           :       Merge vast-tool outputs from multiple sub-samples\n        combine         :       Combine two or more 'aligned' RNA-Seq samples into summary tables.\n.\n..\n.\n.\nPerformance:\n  -o/--offrate &lt;int&gt; override offrate of index; must be &gt;= index's offrate\n  -p/--threads &lt;int&gt; number of alignment threads to launch (default: 1)\n  --mm               use memory-mapped I/O for index; many 'bowtie's can share\n  --shmem            use shared mem for index; many 'bowtie's can share\nOther:\n  --seed &lt;int&gt;       seed for random number generator\n  --verbose          verbose output (for debugging)\n  --version          print version information and quit\n  -h/--help          print this usage message\n\nTambién tenemos que instalar una serie de paquetes para R con los siguientes comandos:\n\nR -e 'install.packages(c(\"optparse\", \"RColorBrewer\", \"reshape2\", \"ggplot2\", \"devtools\"))'\n\nR -e 'devtools::install_github(\"kcha/psiplot\")'\n\n\n\n\n\n\n\nContinuamos trabajando en Terminal aunque sea con R\n\n\n\n\n\n\nLa instalación de estos paquetes pueden necesitar de la actualización e instalación de otros, de manera que tendremos que ir comprobando cuales son necesarios y e instalarlos (buscando en internet como instalarlos). Tuve bastantes problemas con esto así que podéis encontrar la solución en el documento del terminal de este día. Una vez instalado vast-tools, es necesario comprobar que tenemos instalado una herramienta de alineamiento: bowtie.\n\n\n\n\n\n\nNote\n\n\n\nTodo lo hecho a partir de aquí está en:\nTerminal_9-15-23.txt"
  },
  {
    "objectID": "AS_Analysis.html#instalación-de-bowtie",
    "href": "AS_Analysis.html#instalación-de-bowtie",
    "title": "Alternative Splicing",
    "section": "2.2 Instalación de bowtie",
    "text": "2.2 Instalación de bowtie\nPara comprobar si la temenos, en debemos hacer la prueba de esctibir en el terminal una de sus funciones, como por ejemplo:\n\nNo index, query, or output file specified!\nUsage:\nbowtie [options]* &lt;ebwt&gt; {-1 &lt;m1&gt; -2 &lt;m2&gt; | --12 &lt;r&gt; | --interleaved &lt;i&gt; | &lt;s&gt;} [&lt;hit&gt;]\n\n  &lt;m1&gt;    Comma-separated list of files containing upstream mates (or the\n.\n.\n Performance:\n  -o/--offrate &lt;int&gt; override offrate of index; must be &gt;= index's offrate\n  -p/--threads &lt;int&gt; number of alignment threads to launch (default: 1)\n  --mm               use memory-mapped I/O for index; many 'bowtie's can share\n  --shmem            use shared mem for index; many 'bowtie's can share\nOther:\n  --seed &lt;int&gt;       seed for random number generator\n  --verbose          verbose output (for debugging)\n  --version          print version information and quit\n  -h/--help          print this usage message\n\nTambién debemos comprobar la versión de que tenemos instalada (debe de ser la versión 1, tener cuidado porque también existe bowtie2 y esa nos va a dar error). Para instalarlo tenemos que escribir los siguientes comandos:\n\nsudo apt-get update -y\nsudo apt-get install -y bowtie\n\nSi está correctamente instalado todo pasamos al alineamiento con Vast-Tools."
  },
  {
    "objectID": "AS_Analysis.html#alineamineto-para-splicing-alternativo-sa",
    "href": "AS_Analysis.html#alineamineto-para-splicing-alternativo-sa",
    "title": "Alternative Splicing",
    "section": "2.4 Alineamineto para Splicing Alternativo (SA)",
    "text": "2.4 Alineamineto para Splicing Alternativo (SA)\n\n2.4.1 Definiciones\nEn este paso, para aumentar la fracción de lecturas de unión de mapeo dentro de cada muestra de RNA-Seq, vast-tools divide automáticamente cada lectura en grupos de lectura de 50 nucleótidos (nt), utilizando por defecto una ventana deslizante de 25 nt (opción --stepSize). Por ejemplo, una lectura de 100 nt produciría 3 lecturas superpuestas (de las posiciones 1-50, 26-75 y 51-100). Además, se combinan las dos lecturas de la secuenciación por pares, si están disponibles. Para la cuantificación, sólo se considera un recuento aleatorio por grupo de lecturas (es decir, todas las sublecturas procedentes de la misma lectura original) para evitar el recuento múltiple de la misma molécula secuenciada original.\n\n\n\n\n\n\nTip\n\n\n\nEs muy recomendable que los caracteres especiales (‘-’, ‘.’, etc.) no formen parte de los nombres de los archivos fastq, ya que pueden causar problemas imprevistos; utilice ’_’ en su lugar. (El uso de ‘-’ está reservado para proporcionar la longitud de lectura (legado) o especificar que las lecturas han sido sustraídas del genoma; ver más abajo).\n\n\nActualmente, vast-tools soporta múltiples especies y ensamblajes y está en constante crecimiento en coordinación con VastDB. A partir de la v2.4.0, la especie se proporciona utilizando el ensamblaje estándar (por ejemplo, hg38, mm9, etc).\nLos eventos de splicing vendrán definidos como:\n\nPSI (Percent Splice-In), que define los diferentes eventos de “Exon-Exon Junction”.\nPSU (Percent Splice-site usage), que define los eventos de “alternative splice sites”\nPIR PIR (Percent of Intron Retention), que define los eventos de “intrón retention”\n\nEstas medidas son porcentajes que dependen del número de veces que ha ocurrido un evento y se calcula como nº de veces que ocurre un evento en un gen con respecto al número de transcritos cuantificados:\n\n\n\nImagen 3\n\n\nPara habilitar el análisis de expresión génica, utilizar la opción “–expr“ (cálculos PSI/PSU/PIRs y cRPKM (lecturas corregidas por aplicabilidad por Kbp y millones de lecturas mapeadas)]o “–exprONLY” (solo cRPKMs). Los cRPKMs se obtienen mapeando solo los primeros 50 nucleótidos de cada lectura, o solo los primeros 50 nucleótidos de la lectura directa si se proporcionan lecturas de extremo pareado.\nA continuación hay se muestra un esquema del funcionamiento y posibilidades de vast-tools:\n\n\n\nImagen 4\n\n\n\n\n2.4.2 Alineamiento\nComo hemos repetido, para el alineamiento vamos a utilizar la herramienta Vast-Tools. Para ello vamos a la carpeta en la que tengamos los archivos a analizar (tras procesarlos en matt) y allí ejecutamos el comando vast-tool align (que lo explicaré con sus argumentos a continuación con la imgen 2):\n\nvast-tools align Luminal_1_1.fastq.gz Luminal_1_2.fastq.gz -sp Hs2 -o Vast-Tool_Align --expr --IR_version 2 -c 8 -n Luminal_1 \n\n\n\n\nImagen 5\n\n\n\n\n\n\n\n\nNota 1\n\n\n\nEste ejemplo es para cuando tenemos análisis Pair-end, de manera que tendremos un archivo (“Luminal_1_1.fastq.gz”) para la secuenciación 3’-&gt;5’ y otro (“Luminal_1_2.fastq.gz”) para la secuenciación 5’-&gt;3’. Si tuviéramos un análisis Single-end solo tendríamos que poner el único archivo que se nos hubiera descargado para esa muestra.\n\n\n\n\n\n\n\n\nNota 2\n\n\n\nCuidado de no excedernos en el argumento -c porque si vamos a lanzar varios procesos a la vez podemos colapsar el superordenador.\n\n\n\n\n\n\n\n\nNota 3\n\n\n\nLa expresión génica la calcula como corrected-RPKM values (cRPKM) (es decir, que la normaliza e función de la “effective length, la cual consiste en la media de la longitud de todos los transcritos de un gene poderada por la proporción de la expresión de cada transcrito.\n\n\nRealmente el código que yo he corrido es el siguiente para añadir funciones (previamente explicadas):\n\nvast-tools align Luminal_1_1.fastq.gz Luminal_1_2.fastq.gz -sp Hs2top -o Vast-Tool_Align --expr --IR_version 2 -c 8 -n Luminal_1 1&gt;Alineamiento_luminal_1.out &\n\nCon esto le añado al final el comando 1&gt;Alineamiento_luminal_1.out para que me genere un archivo con los mensajes del terminal t así luego poder chequearlos y el comando & para que lo ejecute en segundo plano y así poder seguir usando el terminal (si quisiera desvincularlo a mi sesión ahora podría utilizar disown y podría cerrar el terminal sin miedo a parar el proceso)."
  },
  {
    "objectID": "AS_Analysis.html#generación-de-los-psis-percent-spliced-in",
    "href": "AS_Analysis.html#generación-de-los-psis-percent-spliced-in",
    "title": "Alternative Splicing",
    "section": "2.4 Generación de los PSIs (Percent Spliced-In)",
    "text": "2.4 Generación de los PSIs (Percent Spliced-In)\n\n\n\n\n\n\nNote\n\n\n\nTodo lo hecho a partir de aquí está en Terminal_9-18-23.txt\n\n\nEl siguiente paso es combinar en una tabla todos los eventos de cada muestra. Para ello usaremos el comando vast-tools combine. Para utilizar este comando tenemos que estar en la carpeta que contenga la carpeta donde se han generado los alineamientos (la generada tiene que contener la subcarpeta llamada to_compare):\n\nvast-tools combine -sp Hs2 -o Vast-Tool_Aling –cores 6\n\nEl comando combinará teniendo en cuenta la versión del genoma humano -hg38- (-sp Hs2). Con el argumento -o &lt;directorio&gt; indicamos la carpeta que contiene los archivos a analizar. Tiene que ser la carpeta previamente mencionada, la que contiene la subcarpeta llamada “to_compare” (que coincide con la que pusimos en el argumento -o en el comando del alineamiento (el paso anterior). Con el argumento –cores &lt;nº_cores&gt; indicamos el número de cores o CPUs del superordenador que queremos que se utilicen para este proceso (por defecto se utiliza 1, con 6 va bastante rápido y en 3-5 min está hecho). Para más opciones siempre podemos consultar la ayuda del comando con\n\nvast-tools combine -h"
  },
  {
    "objectID": "AS_Analysis.html#comparaicón-entre-grupos",
    "href": "AS_Analysis.html#comparaicón-entre-grupos",
    "title": "Alternative Splicing",
    "section": "2.6 Comparaicón entre grupos",
    "text": "2.6 Comparaicón entre grupos\n\n2.6.1 Definiciones\nVast-tools genera comparaciones entre grupos principalmente mediante la comparación de las medias de sus respectivos percent inclusión levels del evento (PSI, PSU o PIR, dependiendo del evento). Un detalle importante es que a partir de ahora vamos a referirnos a todos los inclusión levels como PSI independientemente del evento que sea, aunque si quieres ser purista, para las gráficas deberías de poner el percent inclusión level correspondiente\n\nRecordamos que PSI es para Exon-Exon Juction (EEJ, que incluye todos los tipos de exón skipping), el PSU hace referencia a los Alternative Splice Aites (5’ y 3’) y el PIR hace referencia a los eventos de Intron retention\n\nPara eventos AS válidos, vast-tools compare requiere que el valor absoluto de ΔPSI sea superior a un umbral proporcionado como --min_dPSI. Además, requiere que la distribución PSI de los dos grupos no se superponga. Esto puede modificarse con la opción --min_range, para proporcionar un mayor o menor rigor. A mayor diferencia mayor rigor. Estos valores los vemos definidos en la siguiente imagen:\n También es posible imprimir otros conjuntos de eventos AS de especial interés para comparaciones de características (por ejemplo, utilizando Matt). Esto puede hacerse utilizando la opción --print_sets. Producirá tres conjuntos de eventos AS:\n\nEventos constitutivos (CS), que corresponden a aquellos con PSI &lt; 5 (para IR) o PSI &gt; 95 (para todos los demás tipos) en todas las muestras comparadas;\nEventos crípticos (CR), que corresponden a aquellos con PSI &gt; 95 (para IR) o PSI &lt; 5 (para todos los demás tipos) en todas las muestras comparadas;\nEventos AS no cambiantes (AS_NC), que corresponden a aquellos con 10 &lt; av_PSI &lt; 90 en al menos uno de los grupos (o un rango de PSI &gt; 10) y que no cambian entre las dos condiciones. Esto último se especifica con la opción --max_dPSI. Por defecto, se toma 1/5 del --min_dPSI proporcionado.\n\nEsto último hay que tenerlo en cuenta si vamos a descargar los datos (la “inclusion table” que generamos en el paso anterior). Los eventos de splicing constitutivos son aquellos que van se van a dar siempre por lo cual, su PSI va a ser de 100, mientras que los que no se dan nunca van a tener un valor de PSI de 0. Esto se conoce como eventos de tipo “switch” (ON/OFF). El resto son más fluctuantes y son a los que les podemos evaluar verdaderamente un Splicing Diferencial. Es por ello por lo que al comenzar el procedimiento si lo hacemos en R tenemos que establecer filtros como veremos posteriormente.\n\n\n2.6.2 Procedimiento en terminal\nPara la comparación entre grupos y las consecutivas gráficas tendremos que instalar-actualizar bastantes paquetes de R que se nos habrá indicado en el output del proceso anterior. Instalarlos todos antes de continuar. Una vez instalados todos los paquetes que necesitaremos procedemos al proceso de comparación con el comando “vast-tools compare”, el cual lo tenemos que ejecutar en la carpeta en la que hemos generado la combinación (en nuestro caso, y siguiendo con el ejemplo, tendremos que acceder a la carpeta Vast-Tool_Aling):\n\nvast-tools compare INCLUSION_LEVELS_FULL-hg38-6.tab -a Basal_1,Basal_2,Basal_3 -name_A Basal_Cells \n-b Luminal_1,Luminal_2,Luminal_3 -name_B Luminal_Cells -sp Hs2 --print_dPSI \n--GO --print_sets --min_dPSI 25 --min_range 5\n\nLos argumentos utilizados definen lo siguiente:\n\nINCLUSION_LEVELS_FULL-especie_y_version que hayamos utilizado-nº_muestras_procesadas.tab, Este primer argumento se utiliza para indicar dónde se encuentran los datos. Estos datos se encuentran en un archivo que se ha generado con la función to_compare previamente en la carpeta que habíamos indicado, por eso teníamos que acceder a dicha carpeta (en nuestro caso Vast-Tool_Aling)\n-a muestra_1,muestra_2,muestra_3, en este argumento tenemos que añadir todas las muestras que pertenezcan a este grupo, separadas por comas y sin espacios.\n-name_A Nombre_Grupo_A, Nombre que le queremos dar al grupo de muestras incluidas en el grupo “a”.\n-b muestra_1,muestra_2,muestra_3, en este argumento tenemos que añadir todas las muestras que pertenezcan a este grupo, separadas por comas y sin espacios.\n-name_B Nombre_Grupo_B, Nombre que le queremos dar al grupo de muestras incluidas en el grupo “b”.\n-Hs2\n--print_dPSI, ya lo he mos visto previamente\n--GO, ya lo hemos visto previamente\n--print_sets, ya lo hemos visto previamente\n--min_dPSI, ya lo hemos visto previamente\n--min_range, ya lo hemos visto previamente\n\n\n\n\n\n\n\nImportant\n\n\n\nA partir de ahora, lo que vamos a ver es trabajando en R pero siguiendo el flujo de trabajo del capítulo de libro de Vast-tools (citado al principio de esta guía). Los resultados trabajando en termial (que lo iré haciendo de forma paralela) se mostrarán en:\nTerminal_VT.txt\n\n\n\n\n2.6.3 Procedimiento en R\nHemos de tener en cuenta dos cosas principales para realizar un prefiltrado de los datos generados con vast-tool combine:\n\n\n\n\n\n\nTip\n\n\n\nEsta parte del proceso la voy hacer en R pero en el terminal porque los archivos pesan mucho y tardan en descargarse. Mostraré los códigos que he seguido matizando al inicio de los mismos que se ha hecho en R (de la siguiente manera: #Hecho en R de terminal)\n\n\nComenzamos leyendo la tabla INCLUSION_table.tab que hemos generado:\n\nInclusion_table&lt;-read.delim(\"INCLUSION_LEVELS_FULL-hg38-6.tab\", header = TRUE, sep = \"\\t\")\n\n\nEliminar las muestras de poca calidad. Las muestras con calidad “N” deben ser eliminadas (o no consideradas para crear la media del grupo para ese evento). El considerar los VLOW queda más a nuestra decisión.\n\n\n\n\n\n\n\nImportant\n\n\n\nPara eso, el Dr. Luis Pedro Íñiguez (CRG) me ha proveeido de las siguientes funciones que había que definirlas antes de hacer este paso si no las tenemos defininas:\n\n#remove Ns and VLOW from vast-tools INCLUCION TABLE\nremoveNVLOW &lt;- function(x){\n  scores &lt;- grep(\".Q\",names(x),fixed = T)\n  score2 &lt;- scores - 1\n  for(i in score2){x[,i] &lt;- ifelse(grepl(\"^N|^VLOW\",x[,i+1]),NA,x[,i])}\n  return(x)\n}\n\n#remove Ns from vast-tools INCLUSION TABLE\nremoveNonly &lt;- function(x){\n  scores &lt;- grep(\".Q\",names(x),fixed = T)\n  score2 &lt;- scores - 1\n  for(i in score2){\n    x[,i] = ifelse(grepl(\"^N\",x[,i+1]),NA,x[,i])\n  }\n  return(x)\n}\n\n\n\nAplicado a nuestra INCLUSION_Table de manera muy restrictiva sería de la siguiente manera:\n\nrmdf&lt;-removeNVLOW(Inclusion_table)\n#Para ser menos restrictivos usaríamos \n#\n#     rmdf&lt;-removeNonly(df)\n\nUna vez hemos hecho el filtro de calidad tenemos que hacer la media de los componentes de cada grupo.\n\nEstablecer los thresolds.\n\n\nDifrencia entre las medias. Tenemos que buscar lo mismo que se busca con la varibale --min_dPSIen vast-tool combine.\nDiferencia mínima entre el menor valor de la que tenga media más alta y mayor valor de la que tenga la media más baja. Tenemos que buscar lo mismo que se busca con la varibale --min_range en vast-tool combine.\nEliminar eventos constitutivos. Como explicamos previamente, hay eventos de tipo “switch”. Según este parámetro deben ser excluidos aquellos eventos que en un grupo tenga un PSI&gt;90 y en el otro tengan un PSI&lt;10 (voy a considerar aquellos que NO pasan este threshold aquellos eventos que en uno de los grupos cumpla la condición de 10&lt;PSI&lt;90 pero en el otro no).\n\nPara todo este apartado 2 he desarrollado un código que para usarlo tenemos que definir nuestros grupos muestrales:\n\nGroup_1&lt;-\"Basal\"\nSamples_1&lt;-c(\"Basal_1\", \"Basal_2\", \"Basal_3\")\n\nGroup_2&lt;-\"Luminal\"\nSamples_2&lt;-c(\"Luminal_1\", \"Luminal_2\", \"Luminal_3\")\n\nTambién tenemos que definir los thresholds que vamos a poner (a, b, c):\n\n#thresholds para la diferencia entre grupos\nmin_range=5\nmin_dPSI=25\n\n#Valores de PSI/PSU/PIR a considerar splicing constitutivo\nConst_max=90\nConst_min=10\n\nY ya comienza el código (que postermiomente desglorasaré para explicarlo):\n\ndPSI_table&lt;-data.frame(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"pval\", \"qval\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\")\ncolnames(dPSI_table)&lt;-c(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"pval\", \"qval\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\") #definimos el nombre de las columnas\n\n#Y también creamos la tabla en la que se van a pasar aquellos que pasen el threshold\ndPSI_PASS&lt;-data.frame(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"pval\", \"qval\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\")\ncolnames(dPSI_PASS)&lt;-c(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"pval\", \"qval\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\") #definimos el nombre de las columnas\n\n#Por último creamos otra para aquellos que pasen el threshold y cumplan la condición de que 10&gt;PSI&gt;90\ndPSI_df&lt;-data.frame(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"pval\", \"qval\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\")\ncolnames(dPSI_df)&lt;-c(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"pval\", \"qval\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\") #definimos el nombre de las columnas\n\n#Establecemos los valores mínimos para la definición de las filas\nfila_PASS=1\nfila_df=1\nporcentaje=0.02\n\nHora_inicio&lt;-Sys.time()\n\n\nfor (i in c(1:nrow(rmdf))){\n\n\n############################################\n##### guardar variables a mantener #########\ndPSI_table[i, c(1:2) ]&lt;-rmdf[i,c(1:2)]\ndPSI_table[i, c(10:13) ]&lt;-rmdf[i,c(3:6)]\n\n\n#######################\n##### Medias  #########\n\nGroup_1_mean&lt;-as.numeric(rmdf[i, Samples_1]) %&gt;% mean() %&gt;% round(, digits=5)\nGroup_2_mean&lt;-as.numeric(rmdf[i, Samples_2]) %&gt;% mean() %&gt;% round(, digits=5)\n\ndPSI_table[i, c(3:4) ]&lt;-c(Group_1_mean, Group_2_mean)\n\n####################\n##### dPSI #########\n\nDiff&lt;-Group_2_mean - Group_1_mean\n#y ahora hacemos que salga FALSE para aquellos valores que sean inferior al rango mínimo establecido\nDiff_threshold&lt;-ifelse(abs(Diff)&gt;min_dPSI, TRUE, FALSE)\n\n##########################\n##### Overlaping #########\n\n\nRang&lt;-ifelse(Diff&gt;0, min(Group_2_mean)-max(Group_1_mean), min(Group_1_mean)-max(Group_2_mean))\n#y vemos si pasa el threshold\nRang_threshold&lt;-ifelse(Diff&gt;0 & min(Group_2_mean)-max(Group_1_mean)&gt;min_range | Diff&lt;0 & min(Group_1_mean)-max(Group_2_mean)&gt;min_range, TRUE, FALSE)\n\n##################################\n##### Paso del threshold #########\n\nPASS&lt;-ifelse(Rang_threshold & Diff_threshold, TRUE, FALSE)\n\n#En la columna threshold añadimos si se cumplen los cutoffs que hemos establecido\ndPSI_table[i, c(5:7)]&lt;-c(Diff ,Rang, PASS)\n\n######################################\n##### cáculo de los pvalores #########\n\n#Si hay NAs  va a dar error para el test estadístico de manera que tenemos que poner el condicional de que solo pasena test los que no sean NAs\n\nif (!is.na(Diff) & !Diff==0){ \nGroup_1_comp&lt;-as.numeric(rmdf[i, Samples_1])\nGroup_2_comp&lt;-as.numeric(rmdf[i, Samples_2])\n\n#priemro hacemos el test estadístico de U de Mann-Whitney\nresult_U &lt;- wilcox.test(Group_1_comp, Group_2_comp, exact=FALSE)\npU&lt;-result_U$p.value\n#ahora calculamos la T de Student\nresult_T &lt;- t.test(Group_1_comp, Group_2_comp, exact=FALSE)\npT&lt;-result_T$p.value\n\np&lt;-ifelse(pU&lt;0.05 & pT&lt;0.05, pU, ifelse(pU&gt;pT,pU,pT))\n\n#y ahora metemos el valor en su correspondiente casilla de la tabla\ndPSI_table[i, 8]&lt;-c(p)\n} else {dPSI_table[i, 8]&lt;-NA}\n\n######################################\n#####                        #########\n#####   tabla de thresholds  #########\n#####                        #########\n######################################\n\n#Ahora solo eventos que han pasado el threshold se van a pasar a una nueva tabla con la que tabajaremos para representar los eventos desregulados\n\nif(!is.na(PASS) & PASS==1){\n  \ndPSI_PASS[fila_PASS,]&lt;-dPSI_table[i,]\n\n#Una vez hemos acabado la línea\nfila_PASS=fila_PASS+1\n}\n\n######################################\n#####                        #########\n#####   tabla de thresholds  #########\n#####     + 10&lt;PSI&lt;90        #########\n######################################\n######################################\n\n#Ahora  nuevo df en el que se acumularán solo eventos que han pasado el threshold\n#y hacemos el bucle\n\nif(!is.na(PASS) & PASS==1 & \n   ((Group_1_mean&lt;Const_max & Group_2_mean&gt;Const_min) |  \n    (Group_2_mean&lt;Const_max & Group_1_mean&gt;Const_min) |\n    (Group_1_mean&lt;Const_max & Group_2_mean&gt;Const_max) |  \n    (Group_2_mean&lt;Const_max & Group_1_mean&gt;Const_max) | \n    (Group_1_mean&lt;Const_min & Group_2_mean&gt;Const_min) | \n    (Group_2_mean&lt;Const_min & Group_1_mean&gt;Const_min))){\n  \ndPSI_df[fila_df,]&lt;-dPSI_table[i,]\n\n#Una vez hemos acabado la línea\nfila_df=fila_df+1\n\n}\n\n###########################\n#####             #########\n#####  p val adj  #########\n#####             #########\n###########################\n###########################\n\n#if(i==nrow(rmdf)){\n\n  #calcular pval adj para dPSI_table\n  \n  #calcular pval adj para dPSI_PASS\n  \n  #calcular pavl adj para dPSI_df\n  \n#}\n\n\n\n#Se imprime el porcentaje de procesado y la hora\nif(i==round(nrow(rmdf)*porcentaje)){\n  \n  Hora_porcentaje&lt;-Sys.time()\n  \n  diferencia_segundos &lt;- as.numeric(difftime(Hora_porcentaje, Hora_inicio, units = \"secs\"))\n  tiempo_restante_segundos &lt;- diferencia_segundos / (porcentaje) \n  tiempo_restante_minutos &lt;- tiempo_restante_segundos / 60\n  tiempo_restante_horas &lt;- tiempo_restante_minutos / 60\n  \n    \n  print(paste(porcentaje*100, \"% (hora:\", format(Sys.time(), \"%X, %d/%b/%Y) ---  Tiempo restante estimado: \"), round(tiempo_restante_horas), \"h \", round(tiempo_restante_minutos %% 60), \"min\"))\n  \n  if(porcentaje==1){ \n         print(\"-------------------------------   Proceso finalizado   --------------------------------------\")\n  }\n  \n  porcentaje&lt;-porcentaje+0.02\n  \n  }\n\n}\n\n\n\n\n\n\n\nExpliación del código\n\n\n\n\n\n\nComenzamos definiendo las tablas que se van a generar y las filas en las que se van a ir incorporando los resultados:\n\n\ndPSI_table&lt;-data.frame(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"pval\", \"qval\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\")\ncolnames(dPSI_table)&lt;-c(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"pval\", \"qval\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\")\n\n#Y también creamos la tabla en la que se van a pasar aquellos que pasen el threshold\ndPSI_PASS&lt;-data.frame(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"pval\", \"qval\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\")\ncolnames(dPSI_df)&lt;-c(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"pval\", \"qval\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\")\n\n#Por último creamos otra para aquellos que pasen el threshold y cumplan la condición de que 10&gt;PSI&gt;90\ndPSI_df&lt;-data.frame(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"pval\", \"qval\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\")\ncolnames(dPSI_df)&lt;-c(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"pval\", \"qval\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\")\n#Establecemos los valores mínimos para la definición de las filas\nfila_PASS=1\nfila_df=1\nporcentaje=0.02\n#guardamos la hora de inicio del proceso para finalmente estimar el tiempo que falta de proceso (ver paso 11)\nHora_inicio&lt;-Sys.time()\n\n\n\n\n\n\n\nGeneración de tablas\n\n\n\nEn este caso vamos a generar varias tablas para comparar los resultado y tener la opción de verlo todo porque estamos practicando, si fueramos a trabaja sabiendo lo que queremos tendríamos que modificar este código para hacerlo más eficiente y que solo genere la tabla que nos interesa\n\n\nA continuación creamos un bucle para ir aplicando el procedimiento siguiente a cada una de las filas de rmdf.\n\nPasamos los valores que nos interesa mantener al new dataframe dPSI_table que se utilizará como base para todas las operaciones\n\n\ndPSI_table[fila, c(1:2) ]&lt;-rmdf[i,c(1:2)]\ndPSI_table[fila, c(10:13) ]&lt;-rmdf[i,c(3:6)]\n\n\nCalculamos la media de los dos grupos y las guardamos en las columnas corresponientes.\n\n\nGroup_1_mean&lt;-as.numeric(rmdf[fila, Samples_1]) %&gt;% mean()\nGroup_2_mean&lt;-as.numeric(rmdf[fila, Samples_2]) %&gt;% mean()\n\ndPSI_table[fila, c(3:4) ]&lt;-c(Group_1_mean, Group_2_mean)\n\n\nCalculamos la diferencia (equivalente a min_dPSI) entre las medias de los grupos y establecemos si pasa o no pasa el threshold:\n\n\n#La diferencia es simplemente la resta de las medias\nDiff&lt;-Group_2_mean - Group_1_mean\n#y ahora hacemos que salga FALSE para aquellos valores que sean inferior al rango mínimo establecido\nDiff_threshold&lt;-ifelse(abs(Diff)&gt;min_dPSI, TRUE, FALSE)\n\n\nPara el rango (equivalente a min_range) primero definimos que que el rango mínimo se calcula como el valor mínimo del grupo con mayor expresión y el valor máximo del grupo con menor expresión:\n\n\nRang&lt;-ifelse(Diff&gt;0, min(Group_2_mean)-max(Group_1_mean), min(Group_1_mean)-max(Group_2_mean))\n#y vemos si pasa el threshold\nRang_threshold&lt;-ifelse(Diff&gt;0 & min(Group_2_mean)-max(Group_1_mean)&gt;min_range | Diff&lt;0 & min(Group_1_mean)-max(Group_2_mean)&gt;min_range, TRUE, FALSE)\n\n\nDamos valor a la columna de Pass_threshold en función de si se pasan ambos thresholds. Si ambos threshold pasan se define como 1 y alguno o uno de ellos no pasan se definen como 0):\n\n\nPASS&lt;-ifelse(Rang_threshold & Diff_threshold, TRUE, FALSE)\n\n#En la columna threshold añadimos si se cumplen los cutoffs que hemos establecido\ndPSI_table[fila, c(5:7)]&lt;-c(Diff ,Rang, PASS)\n\n\n\n\n\n\n\nEstadística para Splicing\n\n\n\n\n\nTras una interesante conversación con el Dr. Manuel Irimia he comprendido que realizar un test estadístico para 3 muestras no tiene sentido porque el pvalor va a dar como poco 0.05 de manera que él, en Vast-Tools, no realiza estadística sino que se basa en los thresholds (de diferencia mínima de las medias y que no exista overlapping entre la distribución de las muestras) así que podríamos dejarlo aquí. sin embargo, es posible que queramos realizar algún tipo de test estadístico de manera que si tenemos 3 muestras podemos hacer un test de wilkinson + un Test de Student de manera que si ambos están por debajo de 0.05 podemos justificar en la sección de materiales y métodos que estamos haciendo ambos test y cuando consideramos significativa una diferencia (que ambos test pasen,). Según un físico muy reputado, Dr. Nuno L Barbosa-Morais, con el que ha colaborado en muchas ocasiones si se justifica de manera correcta en el test estadístico es adecuado (tiene que tener sentido claro). Un ejemplo de esto que os comento ocurre en la estadística del artículo “Hong Han et al. (2013). Nature”, en la Figura-4G.\nDebido al tipo de distribución del splicing alternativo (que luce similar a lo inverso a una campana de Gauss), el tipo de test estadístico tiene que basarse en el parámtro beta. Por eso, lo más recomendabel es utilizar el paquete de R betAS (de Dr. Nuno L Barbosa-Morais) en el cual se estiman pval de las diferencias en el splicing entre dos grupos muestrales (aunque sean pequeños)\nTambién hemos debatido sobre cuándo utilizar el pvalor ajustado, si antes o después de utilizar el filtro (porque el valor del pval ajustado depende directamente del número de eventos a los que le has calculado el pval). Su opinión es que, para ser más restrictivo se puede utilizar después de aplicar el threshold.\nLos cálculos estadísticos que usaré ahora se harán considerando U de Mann-Whitney (Wilcoxon-Test) y el test de la T de Student. Para considerar significativo un evento ambos deberán pasar el threshold de 0.05 y como valor se utilizará el de la U de Mann-Whitney (para ser más precavido). Posteriormetnte se hará el filtrado y a los valores que pasen el filtrado se realizará el p val adj.\nEsto es para practicar tratamiento de datos y para entender como funciona todo, en cuanto pueda usaré el test correcto que es el que utiliza betAS para calcular el pvalor\n\n\n\n\nSi lo hemos considerado, calculamos la estadística (en este caso como se ha explicado en el aviso anterior):\n\n\n#Si hay NAs  va a dar error para el test estadístico de manera que tenemos que poner el condicional de que solo pasena test los que no sean NAs\n\nif (!is.na(Diff) & !Diff==0){ \nGroup_1_comp&lt;-as.numeric(rmdf[i, Samples_1])\nGroup_2_comp&lt;-as.numeric(rmdf[i, Samples_2])\n\n#priemro hacemos el test estadístico de U de Mann-Whitney\nresult_U &lt;- wilcox.test(Group_1_comp, Group_2_comp, exact=FALSE)\npU&lt;-result_U$p.value\n#ahora calculamos la T de Student\nresult_T &lt;- t.test(Group_1_comp, Group_2_comp, exact=FALSE)\npT&lt;-result_T$p.value\n\np&lt;-ifelse(pU&lt;0.05 & pT&lt;0.05, pU, ifelse(pU&gt;pT,pU,pT))\n\n#y ahora metemos el valor en su correspondiente casilla de la tabla\ndPSI_table[i, 8]&lt;-c(p)\n} else {dPSI_table[i, 8]&lt;-NA}\n\n\nSolo eventos que han pasado el threshold a y b (por comprobar los datos que se generan y poder explorar los constitutivos que se comportan como tal) se van a pasar a una nueva tabla dPSI_PASS (se podría haber puesto antes porque no considera los pvalores calculados, pero primero quería hacer los cálculos y finalmente definir las tablas):\n\n\nif(!is.na(PASS) & PASS==1){\n  \ndPSI_PASS[fila_PASS,]&lt;-dPSI_table[i,]\n\n#Una vez hemos acabado la línea\nfila_PASS=fila_PASS+1\n}\n\n\nSolo eventos que han pasado el threshold a, b y c (por comprobar los datos que se generan y poder explorar los constitutivos que se comportan como tal) se van a pasar a una nueva tabla dPSI_df (se podría haber puesto antes porque no considera los pvalores calculados, pero primero quería hacer los cálculos y finalmente definir las tablas):\n\n\nif(!is.na(PASS) & PASS==1 & \n   ((Group_1_mean&lt;Const_max & Group_2_mean&gt;Const_min) |  \n    (Group_2_mean&lt;Const_max & Group_1_mean&gt;Const_min) |\n    (Group_1_mean&lt;Const_max & Group_2_mean&gt;Const_max) |  \n    (Group_2_mean&lt;Const_max & Group_1_mean&gt;Const_max) | \n    (Group_1_mean&lt;Const_min & Group_2_mean&gt;Const_min) | \n    (Group_2_mean&lt;Const_min & Group_1_mean&gt;Const_min))){\n  \ndPSI_df[fila_df,]&lt;-dPSI_table[i,]\n\n#Una vez hemos acabado la línea\nfila_df=fila_df+1\n\n}\n\n\nSolo para cuando acabe el proceso completo se calculará el pval adj para cada que hemos generado:\n\n\nif(i==nrow(rmdf)){\n  print(\"Estimando pval adj\")\n  #calcular pval adj para dPSI_table\n  \n  #calcular pval adj para dPSI_PASS\n  \n  #calcular pavl adj para dPSI_df\n  \n}\n\n\nAl final de cada bucle, se calculará el porcentaje de proceso que llevamos realizado en función del nº de filas que se han procesado con respecto a las totales y en función del tiempo que llevamos de proceso se estime el tiempo que queda de procesamiento [en función del tiempo que ha tardado en procesar el nº de filas que llevamos en cada momento del bucle (por lo que va ir fluctuando porque si, por ejemplo, hay muchos NAs al principio va a tardar poco en procesarlos ya que no tiene que hacer ninguna operación y nos puede dar un tiempo estimado bajo, a medida que pase el bucle y vaya haciendo cálculos tardará más y por lo tanto la estimación cambiará)]:\n\n\n#Se imprime el porcentaje de procesado y la hora\nif(i==round(nrow(rmdf)*porcentaje)){\n  \n  Hora_porcentaje&lt;-Sys.time()\n  \n  diferencia_segundos &lt;- as.numeric(difftime(Hora_porcentaje, Hora_inicio, units = \"secs\"))\n  tiempo_restante_segundos &lt;- diferencia_segundos / (porcentaje) * (1-porcentaje) \n  tiempo_restante_minutos &lt;- tiempo_restante_segundos / 60\n  tiempo_restante_horas &lt;- tiempo_restante_minutos / 60\n  \n    \n  print(paste(porcentaje*100, \" % (hora: \", format(Sys.time(), \"%X, %d/%b/%Y) ---  Tiempo restante estimado: \"), round(tiempo_restante_horas), \"h \", round(tiempo_restante_minutos %% 60), \"min\"))\n  \n  if(porcentaje==1){ \n         print(\"-------------------------------   Proceso finalizado   --------------------------------------\")\n  }\n  #definimos el siguiente porcentaje que se imprimirá\n  porcentaje&lt;-porcentaje+0.02\n  \n  }\n\n\n\n\n\n\n\nNote\n\n\n\nEsto es totalmente opcional pero viene bien para comprobar que el código sigue funcionando El output será el siguiente:\n[1] \"30 % (hora: 12:25:35, 11/Oct/2023) ---  Tiempo restante estimado:  4 h  50 min\"\n\n\nY aquí concluye el código. Cuando acabe el proceso se imprimirá el siguiente mensaje:\n[1] \"-------------------------------   Proceso finalizado   --------------------------------------\""
  },
  {
    "objectID": "AS_Analysis.html#teoría-sobre-el-splicing-alternativo",
    "href": "AS_Analysis.html#teoría-sobre-el-splicing-alternativo",
    "title": "Alternative Splicing",
    "section": "2.3 Teoría sobre el Splicing Alternativo",
    "text": "2.3 Teoría sobre el Splicing Alternativo\nEl splicing alternativo genera múltiples ARNm diferentes y proteínas derivadas a partir de un único gen mediante la inclusión o exclusión de exones específicos. Este proceso ocurre en el 95% de los genes multiexónicos y está catalizado por el spliceosoma, un complejo formado por un núcleo de cinco pequeñas ribonucleoproteínas nucleares (U1, U2, U4, U5 y U6). El espliceosoma cuenta con la ayuda de más de 200 factores trans-actores que reconocen secuencias reguladoras cis dentro del pre-ARNm y dirigen el spliceosoma para incluir o excluir exones específicos. Así pues, las variantes de empalme pueden surgir de mecanismos que incluyen promotores alternativos, uso preferente de exones o sitios de splicing, alteración del orden de los exones y poliadenilación alternativa\n\n\n\nImagen 2\n\n\nEl splicing alternativo ofrece una importante ventaja evolutiva al proporcionar una gran fuente de diversidad proteómica. El splicing alternativo suele estar regulado a nivel tisular, y las variantes específicas de tejido cooperan para modular las redes de interacción proteína-proteína. Las células madre expresan variantes de empalme específicas en cada etapa de diferenciación, siendo las células madre indiferenciadas las que mantienen los niveles más altos de diversidad de isoformas de empalme. El empalme alternativo también es crítico en el desarrollo y puede responder a estímulos externos normales. Al igual que otras vías relacionadas con el desarrollo, el splicing alternativo puede ser regulado de forma aberrante por las células cancerosas para su beneficio. en beneficio propio. Los estudios del genoma completo revelan desde hace tiempo la existencia de patrones de splicing específicos del cáncer.\n\nChen, J., Weiss, W. Alternative splicing in cancer: implications for biology and therapy. Oncogene 34, 1–14 (2015). https://doi.org/10.1038/onc.2013.570"
  },
  {
    "objectID": "AS_Analysis.html#creación-de-tabla-de-datos-conjunta",
    "href": "AS_Analysis.html#creación-de-tabla-de-datos-conjunta",
    "title": "Alternative Splicing",
    "section": "2.5 Creación de tabla de datos conjunta",
    "text": "2.5 Creación de tabla de datos conjunta\n\n\n\n\n\n\nNote\n\n\n\nTodo lo hecho a partir de aquí está en:\nTerminal_9-18-23.txt\n\n\nEn el paso anterior hemos generado los PSI para cada una de la muestras por lo que ahora tendremos que mergear esas tablas para crear una única tabla de trabajo\nEl siguiente paso es combinar en una tabla todos los eventos de cada muestra. Para ello usaremos el comando vast-tools combine. Para utilizar este comando tenemos que estar en la carpeta que contenga la carpeta donde se han generado los alineamientos (la generada tiene que contener la subcarpeta llamada to_compare):\n\nvast-tools combine -sp Hs2 -o Vast-Tool_Aling –cores 6\n\nEl comando combinará teniendo en cuenta la versión del genoma humano -hg38- (-sp Hs2). Con el argumento -o &lt;directorio&gt; indicamos la carpeta que contiene los archivos a analizar. Tiene que ser la carpeta previamente mencionada, la que contiene la subcarpeta llamada “to_compare” (que coincide con la que pusimos en el argumento -o en el comando del alineamiento (el paso anterior). Con el argumento –cores &lt;nº_cores&gt; indicamos el número de cores o CPUs del superordenador que queremos que se utilicen para este proceso (por defecto se utiliza 1, con 6 va bastante rápido y en 3-5 min está hecho).\n\n\n\n\n\n\nTip\n\n\n\nPara más opciones siempre podemos consultar la ayuda del comando con\n\nvast-tools combine -h\n\n\n\nUna vez que hemos corrido el código se genera un archivo llamado INCLUCION_table.tab (con especificaciones de nuestra muestra en el nombre) la cual la podemos extraer del servidos para leerla en R:\n\nInclusion_table&lt;-read.delim(\"INCLUSION_LEVELS_FULL-hg38-6.tab\", header = TRUE, sep = \"\\t\")\n\nView(Inclusion_table)\n\n\nDonde cada una de estas columnas nos da la siguiente información:\n\nColumna 1 (GENE). Official Gene Symbol\nCOlumna 2 (EVENT). ID del evento en VAST-DB compuesto por:\n\nIdentificador de Especie: Hsa (human), Mmu (ratón), Gga (pollo)\nTipo de evento de splicing: alternative exon skipping (EX), retained intron (INT), alternative splice site donor choice (ALTD), or alternative splice site acceptor choice (ALTA). En el caso de ALTD/ALTA, cada uno de los sitions de spling está indicado (desde el interior del exon hacia afuera) sobre el total de número de sitios de splicing en el evento (e.g. HsaALTA0000011-1/2)\nIdentificador numérico\n\nColumna 3 (COORD). Coordenada en el genoma de la secuencia\nColumna 4 (LENGHTH). Longitud de la secuencia, En evntos ALTF/ALTA el primer sitio de splicing para cada evento se asume como nucleótido 0.\nColumna 5 (FullCO). Conjunto completo de coordenadas de la secuencia del evento de splicing alternativo.\n\nPara EX: chromosome:C1donor,Aexon,C2acceptor. Donde C1donor es el donante del exón “de referencia” aguas arriba, C2acceptor es el aceptor del exón “de referencia” aguas abajo y A es el exón alternativo. La cadena es “+” si C1donor &lt; C2acceptor. Si existen múltiples aceptores/donantes en cualquiera de los exones, se muestran separados por “+”. NOTA: Las coordenadas C1/C2 “de referencia” aguas arriba y aguas abajo no son necesariamente los exones C1/C2 aguas arriba y aguas abajo más cercanos, sino los más externos con suficiente soporte (para facilitar el diseño de cebadores, etc.). Si desea realizar análisis de las características de los exones y/o dibujar mapas de unión a ARN, se recomienda utilizar Matt.\nPara ALTD: chromosome:Aexon,C2acceptor. Los múltiples donor del evento se separan con “+”.\nPara ALTA: chromosome:C1donor,Aexon. Multiples acceptors del evento se separan con “+”.\nPara INT: chromosome:C1exon=C2exon:strand.\n\nColumna 6 (COMPLEX): Tipo de evento:\n\nS, C1, C2, C3: Eventos de Exon-EXON Junction (EEJ) se cuantifican mediante splice site-based or transcript-based modules, con un incremento de los grados de complejidad (basado en Score 5 de un amplio panel de muestras de RNA-seq).\nANN: exon skipping (EX) events quantified by the ANNOTATION module. Their IDs also start by ≥ 6 (e.g. HsaEX6000001).\nMIC: exon skipping (EX) que son microexones.\nIR: eventos intron retention.\nAlt3: eventos ALTA.\nAlt5: eventos ALTD.\n\nA continuación, para cada muestra compilada hay una pareja de columnas que indican:\nColumna 7 (Name_Sample): Porcentaje estimado de inclusión en la secuencia (PSI/PSU/PIR). PSI: percent spliced-in (para EEJ y EX). PSU: percent splice site usage (para ALTD y ALTA). PIR: percent intron retention (para INT).\nColumna 8 (Name_Sample.Q): Puntuaciones de calidad y número de lecturas de inclusión y exclusión corregidas (qual@inc,exc):\n\nScore 1. Cobertura de lectura, basada en lecturas reales (como la utilizada en Irimia et al, Cell 2014). Esta es la única puntuación de cobertura utilizada por compare, tidy y plot\n\nPara EX (excepto módulo microexón): OK/LOW/VLOW: (i) ≥20/15/10 lecturas reales (es decir, antes de la corrección de mapeabilidad) mapeadas a todas las uniones de empalme de exclusión, O (ii) ≥20/15/10 lecturas reales mapeadas a uno de los dos grupos de uniones de empalme de inclusión (aguas arriba o aguas abajo del exón alternativo), y ≥15/10/5 al otro grupo de uniones de empalme de inclusión.\nPara EX (módulo de microexón): OK/LOW/VLOW: (i) ≥20/15/10 lecturas reales asignadas a la suma de uniones de empalme de exclusión, O (ii) ≥20/15/10 lecturas reales asignadas a la suma de uniones de empalme de inclusión.\nPara INT: OK/LOW/VLOW: (i) ≥20/15/10 lecturas reales mapeadas a la suma de uniones de empalme de exclusión, O (ii) ≥20/15/10 lecturas reales mapeadas a una de las dos uniones de inclusión exón-intrón (el 5’ o 3’ del intrón), y ≥15/10/5 a las otras uniones de empalme de inclusión.\nPara ALTD y ALTA: OK/LOW/VLOW: (i) ≥40/25/15 lecturas reales mapeadas a la suma de todas las uniones de empalme implicadas en el evento específico.\nPara cualquier tipo de evento: SOK: los mismos umbrales que OK, pero un número total de lecturas ≥100.\nPara cualquier tipo de evento: N: no alcanza el umbral mínimo (VLOW).\n\nScore 2. Read coverage, based on corrected reads (similar values as per Score 1).\nScore 3.Esta puntuación se ha reciclado para contener información diferente de la versión v2.2.2:\n\nEX (excepto módulo microexón): recuentos de lecturas totales en bruto que admiten inclusión aguas arriba, inclusión aguas abajo y omisión (formato INC1=INC2=EXC).\nEX (módulo de microexones): recuentos de lecturas totales sin procesar que admiten inclusión y exclusión (formato INC=EXC).\nALTD y ALTA: valor tipo PSI del exón que alberga el evento ALTD/ALTA. Esta puntuación se utiliza para filtrar eventos en compare basándose en la opción --min_ALT_use.\nIR (a partir de v2.1.3): número corregido de lecturas del cuerpo del intrón (en una muestra de 200 pb en la mitad del intrón, o de todo el intrón si es más corto), y el número de posiciones mapeables en esa muestra (máximo 151 posiciones) (formato READS=POSICIONES).\nAntes de la v2.1.3: Cobertura de lectura, basada en lecturas no corregidas que corresponden únicamente a las uniones de empalme C1A, AC2 o C1C2 de referencia (valores similares a los de la puntuación 1).\n\nScore 4. Esta puntuación tiene un significado diferente según el tipo de evento AS:\n\nEX (excepto para el módulo microexon): Desequilibrio de lecturas asignadas a las uniones de empalme de inclusión.\n\nOK: la relación entre el número total de lecturas corregidas que apoyan la inclusión de uniones de empalme aguas arriba y aguas abajo del exón alternativo es &lt; 2.\nB1: la relación entre el número total de lecturas corregidas que apoyan la inclusión de los empalmes de empalme aguas arriba y aguas abajo del exón alternativo es &gt; 2 pero &lt; 5.\nB2: la relación entre el número total de lecturas corregidas que apoyan la inclusión de empalmes de empalme aguas arriba y aguas abajo del exón alternativo es &gt; 5 (pero ninguna es 0).\nB3: cuando las lecturas corregidas para la inclusión de un lado son al menos 15 y 0 para el otro. Se utiliza para filtrar eventos en compare cuando la opción --noB3 está activada.\nBl/Bn: baja (entre 10 y 14)/ninguna cobertura de lectura (entre 1 y 9) para las uniones de empalme que apoyan la inclusión.\n\nEX (módulo de microexones): “na” (no se proporciona información).\nALTD y ALTA: recuentos de lecturas brutas para el sitio de empalme específico, para todos los sitios de empalme del evento juntos (=lecturas totales) y para los que admiten la omisión del exón anfitrión. En versiones anteriores a la v2.2.2: lecturas totales del evento para todas las combinaciones o sólo para el aceptor de referencia (para ALTD) o donante (para ALTA).\nIR: recuentos de lecturas brutas que corresponden a la unión exón-intrón aguas arriba, intrón-exón aguas abajo y exón-exón en el formato EIJ=IEJ=EEJ). En versiones anteriores a la v2.2.2, se mostraban los recuentos corregidos en lugar de los recuentos de lecturas en bruto.\n\nScore 5.Esta puntuación tiene un significado diferente según el tipo de evento:\n\nEX (excepto para el módulo microexon): Complejidad del evento. La puntuación se refiere al número de lecturas que proceden de las uniones “de referencia” C1A, AC2 y C1C2. La complejidad aumenta a medida que: S &lt; C1 &lt; C2 &lt; C3.\n\nS: el porcentaje de lecturas complejas (es decir, las lecturas de inclusión y exclusión que no corresponden a las uniones de empalme C1A, AC2 o C1C2 de referencia) es &lt; 5%.\nC1: el porcentaje de lecturas complejas es &gt; 5% pero &lt; 20%.\nC2: el porcentaje de lecturas complejas es &gt; 20% pero &lt; 50%.\nC3: el porcentaje de lecturas complejas es &gt; 50%.\nNA: evento de baja cobertura.\n\nEX (módulo de microexones): “na” (no se proporciona información).\nALTD y ALTA: puntuación de complejidad similar a la de los exones. En este caso, un determinado donante (para ALTA) o aceptor (para ALTD) se considera el sitio “de referencia”, y las lecturas complejas son las procedentes de cualquier otro donante/aceptor.\nIR: valor p de una prueba binomial de equilibrio entre las lecturas asignadas a las uniones exón-intrón aguas arriba y aguas abajo, modificado por las lecturas asignadas a una ventana de 200 pb en el centro del intrón (véase Braunschweig et al., 2014).\n\ninc,exc. número total de lecturas, corregido para la mapeabilidad, que admiten inclusión y exclusión, de forma que PSI = inc/(inc+exc). Así, cuando las lecturas de inclusión implican conjuntos de uniones aguas arriba y aguas abajo, inc y exc se escalan.\n\nPero nos podemos quedar con el primer score como referencia."
  },
  {
    "objectID": "AS_Analysis.html#procedimiento",
    "href": "AS_Analysis.html#procedimiento",
    "title": "Alternative Splicing",
    "section": "2.7 Procedimiento",
    "text": "2.7 Procedimiento\nPara la comparación entre grupos y las consecutivas gráficas tendremos que instalar-actualizar bastantes paquetes de R que se nos habrá indicado en el output del proceso anterior. Instalarlos todos antes de continuar. Una vez instalados todos los paquetes que necesitaremos procedemos al proceso de comparación con el comando “vast-tools compare”, el cual lo tenemos que ejecutar en la carpeta en la que hemos generado la combinación (en nuestro caso, y siguiendo con el ejemplo, tendremos que acceder a la carpeta Vast-Tool_Aling):\n\nvast-tools compare INCLUSION_LEVELS_FULL-hg38-6.tab -a Basal_1,Basal_2,Basal_3 -name_A Basal_Cells \n-b Luminal_1,Luminal_2,Luminal_3 -name_B Luminal_Cells -sp Hs2 --print_dPSI \n--GO --print_sets --min_dPSI 25 --min_range 5\n\nLos argumentos utilizados definen lo siguiente:\n\nINCLUSION_LEVELS_FULL-especie_y_version que hayamos utilizado-nº_muestras_procesadas.tab, Este primer argumento se utiliza para indicar dónde se encuentran los datos. Estos datos se encuentran en un archivo que se ha generado con la función to_compare previamente en la carpeta que habíamos indicado, por eso teníamos que acceder a dicha carpeta (en nuestro caso Vast-Tool_Aling)\n-a muestra_1,muestra_2,muestra_3, en este argumento tenemos que añadir todas las muestras que pertenezcan a este grupo, separadas por comas y sin espacios.\n-name_A Nombre_Grupo_A, Nombre que le queremos dar al grupo de muestras incluidas en el grupo “a”.\n-b muestra_1,muestra_2,muestra_3, en este argumento tenemos que añadir todas las muestras que pertenezcan a este grupo, separadas por comas y sin espacios.\n-name_B Nombre_Grupo_B, Nombre que le queremos dar al grupo de muestras incluidas en el grupo “b”.\n-Hs2\n--print_dPSI, ya lo he mos visto previamente\n--GO, ya lo hemos visto previamente\n--print_sets, ya lo hemos visto previamente\n--min_dPSI, ya lo hemos visto previamente\n--min_range, ya lo hemos visto previamente\n\n\n\n\n\n\n\nImportant\n\n\n\nA partir de ahora, lo que vamos a ver es trabajando en R pero siguiendo el flujo de trabajo del capítulo de libro de Vast-tools (citado al principio de esta guía). Los resultados trabajando en termial (que lo iré haciendo de forma paralela) se mostrarán en:\nTerminal_VT.txt\n\n\nUna vez que hemos corrido el código se genera un archivo llamado INCLUCION_table.tab (con especificaciones de nuestra muestra en el nombre) la cual la podemos extraer del servidos para leerla en R:\n\nInclusion_table&lt;-read.delim(\"INCLUSION_LEVELS_FULL-hg38-6.tab\", header = TRUE, sep = \"\\t\")\n\nView(Inclusion_table)\n\n\n\n\nView(Inclusion_table)\n\n\nDonde cada una de estas columnas nos da la siguiente información:\n\nColumna 1. Official Gene Symbol\nCOlumna 2. ID del evento en VAST-DB compuesto por:\n\nIdentificador de Especie: Hsa (human), Mmu (ratón), Gga (pollo)\nTipo de evento de splicing: alternative exon skipping (EX), retained intron (INT), alternative splice site donor choice (ALTD), or alternative splice site acceptor choice (ALTA). En el caso de ALTD/ALTA, cada uno de los sitions de spling está indicado (desde el interior del exon hacia afuera) sobre el total de número de sitios de splicing en el evento (e.g. HsaALTA0000011-1/2)\nIdentificador numérico\n\nColumna 3. Coordenada en el genoma de la secuencia\nColumna 4. Longitud de la secuencia, En evntos ALTF/ALTA el primer sitio de splicing para cada evento se asume como nucleótido 0.\nColumna 5. Conjunto completo de coordenadas de la secuencia del evento de splicing alternativo.\n\nPara EX: chromosome:C1donor,Aexon,C2acceptor. Donde C1donor es el donante del exón “de referencia” aguas arriba, C2acceptor es el aceptor del exón “de referencia” aguas abajo y A es el exón alternativo. La cadena es “+” si C1donor &lt; C2acceptor. Si existen múltiples aceptores/donantes en cualquiera de los exones, se muestran separados por “+”. NOTA: Las coordenadas C1/C2 “de referencia” aguas arriba y aguas abajo no son necesariamente los exones C1/C2 aguas arriba y aguas abajo más cercanos, sino los más externos con suficiente soporte (para facilitar el diseño de cebadores, etc.). Si desea realizar análisis de las características de los exones y/o dibujar mapas de unión a ARN, se recomienda utilizar Matt.\nPara ALTD: chromosome:Aexon,C2acceptor. Los múltiples donor del evento se separan con “+”.\nPara ALTA: chromosome:C1donor,Aexon. Multiples acceptors del evento se separan con “+”.\nPara INT: chromosome:C1exon=C2exon:strand.\n\nColumna 6: Tipo de evento:\n\nS, C1, C2, C3: Eventos de Exon skipping (EX) se cuantifican mediante splice site-based or transcript-based modules, con un incremento de los grados de complejidad (basado en Score 5 de un amplio panel de muestras de RNA-seq)\nANN: exon skipping (EX) events quantified by the ANNOTATION module. Their IDs also start by ≥ 6 (e.g. HsaEX6000001).\nMIC: exon skipping (EX) que son microexones.\nIR: eventos intron retention.\nAlt3: eventos ALTA.\nAlt5: eventos ALTD.\n\nA continuación, para cada muestra compilada hay una pareja de columnas que indican:\nColumna 7: Porcentaje estimado de inclusión en la secuencia (PSI/PSU/PIR). PSI: percent spliced-in (para EX). PSU: percent splice site usage (para ALTD y ALTA). PIR: percent intron retention (para INT).\nColumna 8: Puntuaciones de calidad y número de lecturas de inclusión y exclusión corregidas (qual@inc,exc):\n\nScore 1. Cobertura de lectura, basada en lecturas reales (como la utilizada en Irimia et al, Cell 2014). Esta es la única puntuación de cobertura utilizada por compare, tidy y plot\n\nPara EX (excepto módulo microexón): OK/LOW/VLOW: (i) ≥20/15/10 lecturas reales (es decir, antes de la corrección de mapeabilidad) mapeadas a todas las uniones de empalme de exclusión, O (ii) ≥20/15/10 lecturas reales mapeadas a uno de los dos grupos de uniones de empalme de inclusión (aguas arriba o aguas abajo del exón alternativo), y ≥15/10/5 al otro grupo de uniones de empalme de inclusión.\nPara EX (módulo de microexón): OK/LOW/VLOW: (i) ≥20/15/10 lecturas reales asignadas a la suma de uniones de empalme de exclusión, O (ii) ≥20/15/10 lecturas reales asignadas a la suma de uniones de empalme de inclusión.\nPara INT: OK/LOW/VLOW: (i) ≥20/15/10 lecturas reales mapeadas a la suma de uniones de empalme de exclusión, O (ii) ≥20/15/10 lecturas reales mapeadas a una de las dos uniones de inclusión exón-intrón (el 5’ o 3’ del intrón), y ≥15/10/5 a las otras uniones de empalme de inclusión.\nPara ALTD y ALTA: OK/LOW/VLOW: (i) ≥40/25/15 lecturas reales mapeadas a la suma de todas las uniones de empalme implicadas en el evento específico.\nPara cualquier tipo de evento: SOK: los mismos umbrales que OK, pero un número total de lecturas ≥100.\nPara cualquier tipo de evento: N: no alcanza el umbral mínimo (VLOW).\n\nScore 2. Read coverage, based on corrected reads (similar values as per Score 1).\nScore 3.Esta puntuación se ha reciclado para contener información diferente de la versión v2.2.2:\n\nEX (excepto módulo microexón): recuentos de lecturas totales en bruto que admiten inclusión aguas arriba, inclusión aguas abajo y omisión (formato INC1=INC2=EXC).\nEX (módulo de microexones): recuentos de lecturas totales sin procesar que admiten inclusión y exclusión (formato INC=EXC).\nALTD y ALTA: valor tipo PSI del exón que alberga el evento ALTD/ALTA. Esta puntuación se utiliza para filtrar eventos en compare basándose en la opción --min_ALT_use.\nIR (a partir de v2.1.3): número corregido de lecturas del cuerpo del intrón (en una muestra de 200 pb en la mitad del intrón, o de todo el intrón si es más corto), y el número de posiciones mapeables en esa muestra (máximo 151 posiciones) (formato READS=POSICIONES).\nAntes de la v2.1.3: Cobertura de lectura, basada en lecturas no corregidas que corresponden únicamente a las uniones de empalme C1A, AC2 o C1C2 de referencia (valores similares a los de la puntuación 1).\n\nScore 4. Esta puntuación tiene un significado diferente según el tipo de evento AS:\n\nEX (excepto para el módulo microexon): Desequilibrio de lecturas asignadas a las uniones de empalme de inclusión.\n\nOK: la relación entre el número total de lecturas corregidas que apoyan la inclusión de uniones de empalme aguas arriba y aguas abajo del exón alternativo es &lt; 2.\nB1: la relación entre el número total de lecturas corregidas que apoyan la inclusión de los empalmes de empalme aguas arriba y aguas abajo del exón alternativo es &gt; 2 pero &lt; 5.\nB2: la relación entre el número total de lecturas corregidas que apoyan la inclusión de empalmes de empalme aguas arriba y aguas abajo del exón alternativo es &gt; 5 (pero ninguna es 0).\nB3: cuando las lecturas corregidas para la inclusión de un lado son al menos 15 y 0 para el otro. Se utiliza para filtrar eventos en compare cuando la opción --noB3 está activada.\nBl/Bn: baja (entre 10 y 14)/ninguna cobertura de lectura (entre 1 y 9) para las uniones de empalme que apoyan la inclusión.\n\nEX (módulo de microexones): “na” (no se proporciona información).\nALTD y ALTA: recuentos de lecturas brutas para el sitio de empalme específico, para todos los sitios de empalme del evento juntos (=lecturas totales) y para los que admiten la omisión del exón anfitrión. En versiones anteriores a la v2.2.2: lecturas totales del evento para todas las combinaciones o sólo para el aceptor de referencia (para ALTD) o donante (para ALTA).\nIR: recuentos de lecturas brutas que corresponden a la unión exón-intrón aguas arriba, intrón-exón aguas abajo y exón-exón en el formato EIJ=IEJ=EEJ). En versiones anteriores a la v2.2.2, se mostraban los recuentos corregidos en lugar de los recuentos de lecturas en bruto.\n\nScore 5.Esta puntuación tiene un significado diferente según el tipo de evento:\n\nEX (excepto para el módulo microexon): Complejidad del evento. La puntuación se refiere al número de lecturas que proceden de las uniones “de referencia” C1A, AC2 y C1C2. La complejidad aumenta a medida que: S &lt; C1 &lt; C2 &lt; C3.\n\nS: el porcentaje de lecturas complejas (es decir, las lecturas de inclusión y exclusión que no corresponden a las uniones de empalme C1A, AC2 o C1C2 de referencia) es &lt; 5%.\nC1: el porcentaje de lecturas complejas es &gt; 5% pero &lt; 20%.\nC2: el porcentaje de lecturas complejas es &gt; 20% pero &lt; 50%.\nC3: el porcentaje de lecturas complejas es &gt; 50%.\nNA: evento de baja cobertura.\n\nEX (módulo de microexones): “na” (no se proporciona información).\nALTD y ALTA: puntuación de complejidad similar a la de los exones. En este caso, un determinado donante (para ALTA) o aceptor (para ALTD) se considera el sitio “de referencia”, y las lecturas complejas son las procedentes de cualquier otro donante/aceptor.\nIR: valor p de una prueba binomial de equilibrio entre las lecturas asignadas a las uniones exón-intrón aguas arriba y aguas abajo, modificado por las lecturas asignadas a una ventana de 200 pb en el centro del intrón (véase Braunschweig et al., 2014).\n\ninc,exc. número total de lecturas, corregido para la mapeabilidad, que admiten inclusión y exclusión, de forma que PSI = inc/(inc+exc). Así, cuando las lecturas de inclusión implican conjuntos de uniones aguas arriba y aguas abajo, inc y exc se escalan."
  },
  {
    "objectID": "AS_Analysis.html#análisis-de-splicing-diferencial",
    "href": "AS_Analysis.html#análisis-de-splicing-diferencial",
    "title": "Alternative Splicing",
    "section": "2.7 Análisis de Splicing diferencial",
    "text": "2.7 Análisis de Splicing diferencial"
  },
  {
    "objectID": "AS_Analysis.html#comparación-entre-grupos-análisis-de-splicing-diferencial",
    "href": "AS_Analysis.html#comparación-entre-grupos-análisis-de-splicing-diferencial",
    "title": "Alternative Splicing",
    "section": "2.6 Comparación entre grupos (Análisis de Splicing diferencial)",
    "text": "2.6 Comparación entre grupos (Análisis de Splicing diferencial)\n\n2.6.1 Definiciones\nVast-tools genera comparaciones entre grupos principalmente mediante la comparación de las medias de sus respectivos percent inclusión levels del evento (PSI, PSU o PIR, dependiendo del evento). Un detalle importante es que a partir de ahora vamos a referirnos a todos los inclusión levels como PSI independientemente del evento que sea, aunque si quieres ser purista, para las gráficas deberías de poner el percent inclusión level correspondiente\n\nRecordamos que PSI es para Exon-Exon Juction (EEJ, que incluye todos los tipos de exón skipping), el PSU hace referencia a los Alternative Splice Aites (5’ y 3’) y el PIR hace referencia a los eventos de Intron retention\n\nPara eventos AS válidos, vast-tools compare requiere que el valor absoluto de ΔPSI sea superior a un umbral proporcionado como --min_dPSI. Además, requiere que la distribución PSI de los dos grupos no se superponga. Esto puede modificarse con la opción --min_range, para proporcionar un mayor o menor rigor. A mayor diferencia mayor rigor. Estos valores los vemos definidos en la siguiente imagen:\n También es posible imprimir otros conjuntos de eventos AS de especial interés para comparaciones de características (por ejemplo, utilizando Matt). Esto puede hacerse utilizando la opción --print_sets. Producirá tres conjuntos de eventos AS:\n\nEventos constitutivos (CS), que corresponden a aquellos con PSI &lt; 5 (para IR) o PSI &gt; 95 (para todos los demás tipos) en todas las muestras comparadas;\nEventos crípticos (CR), que corresponden a aquellos con PSI &gt; 95 (para IR) o PSI &lt; 5 (para todos los demás tipos) en todas las muestras comparadas;\nEventos AS no cambiantes (AS_NC), que corresponden a aquellos con 10 &lt; av_PSI &lt; 90 en al menos uno de los grupos (o un rango de PSI &gt; 10) y que no cambian entre las dos condiciones. Esto último se especifica con la opción --max_dPSI. Por defecto, se toma 1/5 del --min_dPSI proporcionado.\n\nEsto último hay que tenerlo en cuenta si vamos a descargar los datos (la “inclusion table” que generamos en el paso anterior). Los eventos de splicing constitutivos son aquellos que van se van a dar siempre por lo cual, su PSI va a ser de 100, mientras que los que no se dan nunca van a tener un valor de PSI de 0. Esto se conoce como eventos de tipo “switch” (ON/OFF). El resto son más fluctuantes y son a los que les podemos evaluar verdaderamente un Splicing Diferencial. Es por ello por lo que al comenzar el procedimiento si lo hacemos en R tenemos que establecer filtros como veremos posteriormente.\n\n\n2.6.2 Procedimiento en terminal\nPara la comparación entre grupos y las consecutivas gráficas tendremos que instalar-actualizar bastantes paquetes de R que se nos habrá indicado en el output del proceso anterior. Instalarlos todos antes de continuar. Una vez instalados todos los paquetes que necesitaremos procedemos al proceso de comparación con el comando “vast-tools compare”, el cual lo tenemos que ejecutar en la carpeta en la que hemos generado la combinación (en nuestro caso, y siguiendo con el ejemplo, tendremos que acceder a la carpeta Vast-Tool_Aling):\n\nvast-tools compare INCLUSION_LEVELS_FULL-hg38-6.tab -a Basal_1,Basal_2,Basal_3 -name_A Basal_Cells \n-b Luminal_1,Luminal_2,Luminal_3 -name_B Luminal_Cells -sp Hs2 --print_dPSI \n--GO --print_sets --min_dPSI 25 --min_range 5\n\nLos argumentos utilizados definen lo siguiente:\n\nINCLUSION_LEVELS_FULL-especie_y_version que hayamos utilizado-nº_muestras_procesadas.tab, Este primer argumento se utiliza para indicar dónde se encuentran los datos. Estos datos se encuentran en un archivo que se ha generado con la función to_compare previamente en la carpeta que habíamos indicado, por eso teníamos que acceder a dicha carpeta (en nuestro caso Vast-Tool_Aling)\n-a muestra_1,muestra_2,muestra_3, en este argumento tenemos que añadir todas las muestras que pertenezcan a este grupo, separadas por comas y sin espacios.\n-name_A Nombre_Grupo_A, Nombre que le queremos dar al grupo de muestras incluidas en el grupo “a”.\n-b muestra_1,muestra_2,muestra_3, en este argumento tenemos que añadir todas las muestras que pertenezcan a este grupo, separadas por comas y sin espacios.\n-name_B Nombre_Grupo_B, Nombre que le queremos dar al grupo de muestras incluidas en el grupo “b”.\n-Hs2\n--print_dPSI, ya lo he mos visto previamente\n--GO, ya lo hemos visto previamente\n--print_sets, ya lo hemos visto previamente\n--min_dPSI, ya lo hemos visto previamente\n--min_range, ya lo hemos visto previamente\n\n\n\n\n\n\n\nImportant\n\n\n\nA partir de ahora, lo que vamos a ver es trabajando en R pero siguiendo el flujo de trabajo del capítulo de libro de Vast-tools (citado al principio de esta guía). Los resultados trabajando en termial (que lo iré haciendo de forma paralela) se mostrarán en:\nTerminal_VT.txt\n\n\n\n\n2.6.3 Procedimiento en R\nPaquetes necesarios:\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"DT\")\ninstall.packages(\"ggplot2\", dependencies = TRUE)\ninstall.packages(\"pheatmap\", dependencies = TRUE)\ninstall.packages(\"RColorBrewer\", dependencies = TRUE)\nBiocManager::install(\"PCAtools\")\ninstall.packages(\"ggrepel\")\n\nY libraries:\n\nlibrary(tidyverse)\nlibrary(DT)\nlibrary(ggplot2)\nlibrary(pheatmap)\nlibrary(RColorBrewer)\nlibrary(PCAtools)\nlibrary(ggrepel)\n\n\n2.6.3.1 Handmade analysis\nHemos de tener en cuenta dos cosas principales para realizar un prefiltrado de los datos generados con vast-tool combine:\n\n\n\n\n\n\nTip\n\n\n\nEsta parte del proceso la voy hacer en R pero en el terminal porque los archivos pesan mucho y tardan en descargarse. Mostraré los códigos que he seguido matizando al inicio de los mismos que se ha hecho en R (de la siguiente manera: #Hecho en R de terminal)\n\n\nComenzamos leyendo la tabla INCLUSION_table.tab que hemos generado:\n\n#Hecho en R de terminal\nInclusion_table&lt;-read.delim(\"INCLUSION_LEVELS_FULL-hg38-6.tab\", header = TRUE, sep = \"\\t\")\n\n\nEliminar las muestras de poca calidad. Las muestras con calidad “N” deben ser eliminadas (o no consideradas para crear la media del grupo para ese evento). El considerar los VLOW queda más a nuestra decisión.\n\n\n\n\n\n\n\nImportant\n\n\n\nPara eso, el Dr. Luis Pedro Íñiguez (CRG) me ha proveeido de las siguientes funciones que había que definirlas antes de hacer este paso si no las tenemos defininas:\n\n#Hecho en R de terminal\n#remove Ns and VLOW from vast-tools INCLUCION TABLE\nremoveNVLOW &lt;- function(x){\n  scores &lt;- grep(\".Q\",names(x),fixed = T)\n  score2 &lt;- scores - 1\n  for(i in score2){x[,i] &lt;- ifelse(grepl(\"^N|^VLOW\",x[,i+1]),NA,x[,i])}\n  return(x)\n}\n\n#remove Ns from vast-tools INCLUSION TABLE\nremoveNonly &lt;- function(x){\n  scores &lt;- grep(\".Q\",names(x),fixed = T)\n  score2 &lt;- scores - 1\n  for(i in score2){\n    x[,i] = ifelse(grepl(\"^N\",x[,i+1]),NA,x[,i])\n  }\n  return(x)\n}\n\n\n\nAplicado a nuestra INCLUSION_Table de manera muy restrictiva sería de la siguiente manera:\n\n#Hecho en R de terminal\nrmdf&lt;-removeNonly(df)\n\n#Para ser menos restrictivos usaríamos\n\n#rmdf&lt;-removeNVLOW(Inclusion_table)\n\nUna vez hemos hecho el filtro de calidad tenemos que hacer la media de los componentes de cada grupo.\n\nEstablecer los thresolds.\n\n\nDifrencia entre las medias. Tenemos que buscar lo mismo que se busca con la varibale --min_dPSIen vast-tool combine.\nDiferencia mínima entre el menor valor de la que tenga media más alta y mayor valor de la que tenga la media más baja. Tenemos que buscar lo mismo que se busca con la varibale --min_range en vast-tool combine.\nEliminar eventos constitutivos. Como explicamos previamente, hay eventos de tipo “switch”. Según este parámetro deben ser excluidos aquellos eventos que en un grupo tenga un PSI&gt;90 y en el otro tengan un PSI&lt;10 (voy a considerar aquellos que NO pasan este threshold aquellos eventos que en uno de los grupos cumpla la condición de 10&lt;PSI&lt;90 pero en el otro no).\n\nPara todo este apartado 2 he desarrollado un código que para usarlo tenemos que definir nuestros grupos muestrales:\n\n#Hecho en R de terminal\nGroup_1&lt;-\"Basal\"\nSamples_1&lt;-c(\"Basal_1\", \"Basal_2\", \"Basal_3\")\n\nGroup_2&lt;-\"Luminal\"\nSamples_2&lt;-c(\"Luminal_1\", \"Luminal_2\", \"Luminal_3\")\n\nTambién tenemos que definir los thresholds que vamos a poner (a, b, c):\n\n#Hecho en R de terminal\n#thresholds para la diferencia entre grupos\nmin_range=5\nmin_dPSI=25\n\n#Valores de PSI/PSU/PIR a considerar splicing constitutivo\nConst_max=90\nConst_min=10\n\nY ya comienza el código (que postermiomente desglorasaré para explicarlo):\n\n#Hecho en R de terminal\ndPSI_table&lt;-data.frame(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\",  \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\")\ncolnames(dPSI_table)&lt;-c(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\") #definimos el nombre de las columnas\n\n#Y también creamos la tabla en la que se van a pasar aquellos que pasen el threshold\ndPSI_PASS&lt;-data.frame(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\",  \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\")\ncolnames(dPSI_PASS)&lt;-c(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\",  \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\") #definimos el nombre de las columnas\n\n#Por último creamos otra para aquellos que pasen el threshold y cumplan la condición de que 10&gt;PSI&gt;90\ndPSI_df&lt;-data.frame(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\",  \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\")\ncolnames(dPSI_df)&lt;-c(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\",  \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\") #definimos el nombre de las columnas\n\n#Establecemos los valores mínimos para la definición de las filas\nfila_PASS=1\nfila_df=1\nporcentaje=0.02\n\nHora_inicio&lt;-Sys.time()\n\n\nfor (i in c(1:nrow(rmdf))){\n\n\n############################################\n##### guardar variables a mantener #########\ndPSI_table[i, c(1:2) ]&lt;-rmdf[i,c(1:2)]\ndPSI_table[i, c(8:11) ]&lt;-rmdf[i,c(3:6)]\n\n\n#######################\n##### Medias  #########\n\nGroup_1_mean&lt;-as.numeric(rmdf[i, Samples_1]) %&gt;% mean() %&gt;% round(, digits=5)\nGroup_2_mean&lt;-as.numeric(rmdf[i, Samples_2]) %&gt;% mean() %&gt;% round(, digits=5)\n\ndPSI_table[i, c(3:4) ]&lt;-c(Group_1_mean, Group_2_mean)\n\n####################\n##### dPSI #########\n\nDiff&lt;-Group_2_mean - Group_1_mean\n#y ahora hacemos que salga FALSE para aquellos valores que sean inferior al rango mínimo establecido\nDiff_threshold&lt;-ifelse(abs(Diff)&gt;min_dPSI, TRUE, FALSE)\n\n##########################\n##### Overlaping #########\n\n\nRang&lt;-ifelse(Diff&gt;0, min(Group_2_mean)-max(Group_1_mean), min(Group_1_mean)-max(Group_2_mean))\n#y vemos si pasa el threshold\nRang_threshold&lt;-ifelse(Diff&gt;0 & min(Group_2_mean)-max(Group_1_mean)&gt;min_range | Diff&lt;0 & min(Group_1_mean)-max(Group_2_mean)&gt;min_range, TRUE, FALSE)\n\n##################################\n##### Paso del threshold #########\n\nPASS&lt;-ifelse(Rang_threshold & Diff_threshold, TRUE, FALSE)\n\n#En la columna threshold añadimos si se cumplen los cutoffs que hemos establecido\ndPSI_table[i, c(5:7)]&lt;-c(Diff ,Rang, PASS)\n\n######################################\n#####                        #########\n#####   tabla de thresholds  #########\n#####                        #########\n######################################\n\n#Ahora solo eventos que han pasado el threshold se van a pasar a una nueva tabla con la que tabajaremos para representar los eventos desregulados\n\nif(!is.na(PASS) & PASS==1){\n  \ndPSI_PASS[fila_PASS,]&lt;-dPSI_table[i,]\n\n#Una vez hemos acabado la línea\nfila_PASS=fila_PASS+1\n}\n\n######################################\n#####                        #########\n#####   tabla de thresholds  #########\n#####     + 10&lt;PSI&lt;90        #########\n######################################\n######################################\n\n#Ahora  nuevo df en el que se acumularán solo eventos que han pasado el threshold\n#y hacemos el bucle\n\nif(!is.na(PASS) & PASS==1 & \n   ((Group_1_mean&lt;Const_max & Group_2_mean&gt;Const_min) |  \n    (Group_2_mean&lt;Const_max & Group_1_mean&gt;Const_min) |\n    (Group_1_mean&lt;Const_max & Group_2_mean&gt;Const_max) |  \n    (Group_2_mean&lt;Const_max & Group_1_mean&gt;Const_max) | \n    (Group_1_mean&lt;Const_min & Group_2_mean&gt;Const_min) | \n    (Group_2_mean&lt;Const_min & Group_1_mean&gt;Const_min))){\n  \ndPSI_df[fila_df,]&lt;-dPSI_table[i,]\n\n#Una vez hemos acabado la línea\nfila_df=fila_df+1\n\n}\n\n#Se imprime el porcentaje de procesado y la hora\nif(i==round(nrow(rmdf)*porcentaje)){\n  \n  Hora_porcentaje&lt;-Sys.time()\n  \n  diferencia_segundos &lt;- as.numeric(difftime(Hora_porcentaje, Hora_inicio, units = \"secs\"))\n  tiempo_restante_segundos &lt;- diferencia_segundos / (porcentaje) \n  tiempo_restante_minutos &lt;- tiempo_restante_segundos / 60\n  tiempo_restante_horas &lt;- tiempo_restante_minutos / 60\n  \n   \n  print(paste(porcentaje*100, \"% (hora:\", format(Sys.time(), \"%X, %d/%b/%Y) ---  Tiempo restante estimado: \"), round(tiempo_restante_horas), \"h \", round(tiempo_restante_minutos - round(tiempo_restante_horas)*60), \"min\"))\n  \n  \n  \n  porcentaje&lt;-porcentaje+0.02\n  \n}\n\nif(porcentaje&gt;0.9999999999999999999999999999999999999){ \n         print(\"-------------------------------   Proceso finalizado   --------------------------------------\")\n  }\n\n}\n\n\n\n\n\n\n\nExpliación del código\n\n\n\n\n\n\nComenzamos definiendo las tablas que se van a generar y las filas en las que se van a ir incorporando los resultados:\n\n\ndPSI_table&lt;-data.frame(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\")\ncolnames(dPSI_table)&lt;-c(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\")\n\n#Y también creamos la tabla en la que se van a pasar aquellos que pasen el threshold\ndPSI_PASS&lt;-data.frame(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\")\ncolnames(dPSI_df)&lt;-c(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\")\n\n#Por último creamos otra para aquellos que pasen el threshold y cumplan la condición de que 10&gt;PSI&gt;90\ndPSI_df&lt;-data.frame(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\")\ncolnames(dPSI_df)&lt;-c(\"GENE\", \"EVENT\", Group_1, Group_2, \"dPSI\", \"range\", \"Pass_threshold\", \"COORD\", \"LENGTH\", \"FullCO\", \"COMPLEX\")\n#Establecemos los valores mínimos para la definición de las filas\nfila_PASS=1\nfila_df=1\nporcentaje=0.02\n#guardamos la hora de inicio del proceso para finalmente estimar el tiempo que falta de proceso (ver paso 11)\nHora_inicio&lt;-Sys.time()\n\n\n\n\n\n\n\nGeneración de tablas\n\n\n\nEn este caso vamos a generar varias tablas para comparar los resultado y tener la opción de verlo todo porque estamos practicando, si fueramos a trabaja sabiendo lo que queremos tendríamos que modificar este código para hacerlo más eficiente y que solo genere la tabla que nos interesa\n\n\nA continuación creamos un bucle para ir aplicando el procedimiento siguiente a cada una de las filas de rmdf.\n\nPasamos los valores que nos interesa mantener al new dataframe dPSI_table que se utilizará como base para todas las operaciones\n\n\ndPSI_table[fila, c(1:2) ]&lt;-rmdf[i,c(1:2)]\ndPSI_table[fila, c(8:11) ]&lt;-rmdf[i,c(3:6)]\n\n\nCalculamos la media de los dos grupos y las guardamos en las columnas corresponientes.\n\n\nGroup_1_mean&lt;-as.numeric(rmdf[fila, Samples_1]) %&gt;% mean()\nGroup_2_mean&lt;-as.numeric(rmdf[fila, Samples_2]) %&gt;% mean()\n\ndPSI_table[fila, c(3:4) ]&lt;-c(Group_1_mean, Group_2_mean)\n\n\nCalculamos la diferencia (equivalente a min_dPSI) entre las medias de los grupos y establecemos si pasa o no pasa el threshold:\n\n\n#La diferencia es simplemente la resta de las medias\nDiff&lt;-Group_2_mean - Group_1_mean\n#y ahora hacemos que salga FALSE para aquellos valores que sean inferior al rango mínimo establecido\nDiff_threshold&lt;-ifelse(abs(Diff)&gt;min_dPSI, TRUE, FALSE)\n\n\nPara el rango (equivalente a min_range) primero definimos que que el rango mínimo se calcula como el valor mínimo del grupo con mayor expresión y el valor máximo del grupo con menor expresión:\n\n\nRang&lt;-ifelse(Diff&gt;0, min(Group_2_mean)-max(Group_1_mean), min(Group_1_mean)-max(Group_2_mean))\n#y vemos si pasa el threshold\nRang_threshold&lt;-ifelse(Diff&gt;0 & min(Group_2_mean)-max(Group_1_mean)&gt;min_range | Diff&lt;0 & min(Group_1_mean)-max(Group_2_mean)&gt;min_range, TRUE, FALSE)\n\n\nDamos valor a la columna de Pass_threshold en función de si se pasan ambos thresholds. Si ambos threshold pasan se define como 1 y alguno o uno de ellos no pasan se definen como 0):\n\n\nPASS&lt;-ifelse(Rang_threshold & Diff_threshold, TRUE, FALSE)\n\n#En la columna threshold añadimos si se cumplen los cutoffs que hemos establecido\ndPSI_table[fila, c(5:7)]&lt;-c(Diff ,Rang, PASS)\n\n\n\n\n\n\n\nEstadística para Splicing\n\n\n\n\n\nTras una interesante conversación con el Dr. Manuel Irimia he comprendido que realizar un test estadístico para 3 muestras (aunque se haga un no paramétrico) no tiene sentido porque el pvalor va a dar como poco 0.05 de manera que él, en Vast-Tools, no realiza estadística sino que se basa en los thresholds (de diferencia mínima de las medias y que no exista overlapping entre la distribución de las muestras) así que podríamos dejarlo aquí. Esto se debe al tipo de distribución que presentan los splicing (llamada distribución beta), como podemos ver en las siguientes imágenes:\n![Imagen obtenida de betAS\nSin embargo, es posible que queramos realizar algún tipo de aproximación estadística de manera que si tenemos 3 muestras, una vez el Dr. Irima (mirar el ejemplo al final del párrafo) realizó un test de wilkinson + un Test de Student (o algo similar) de manera que si ambos estaban por debajo de 0.05 podemos justificar en la sección de materiales y métodos que estamos haciendo ambos test y cuando consideramos significativa una diferencia (que ambos test pasen). Según un físico muy reputado, Dr. Nuno L Barbosa-Morais, con el que ha colaborado en muchas ocasiones, un test estadístico es adecuado si lo justificas de forma adecuada (tiene que tener sentido, claro). Un ejemplo de esto que os comento ocurre en la estadística del artículo “Hong Han et al. (2013). Nature”, en la Figura-4G.\nDebido al tipo de distribución del splicing alternativo, el tipo de test estadístico tiene que basarse en la propia distribución beta. Por eso, lo más recomendabe es utilizar el paquete de R betAS (de Dr. Nuno L Barbosa-Morais) en el cual se estiman pval de las diferencias en el splicing entre dos grupos muestrales (aunque sean pequeños).\nA modo de curiosidad, también hemos debatido sobre cuándo utilizar el pvalor ajustado, si antes o después de utilizar el filtro (porque el valor del pval ajustado depende directamente del número de eventos a los que le has calculado el pval). Su opinión es que, para ser más restrictivo se puede utilizar después de aplicar el threshold.\nPosteriormente utilizaremos betAS para calcular el pvalor estadístico de nuestros eventos\n\n\n\n\nSolo eventos que han pasado el threshold a y b (por comprobar los datos que se generan y poder explorar los constitutivos que se comportan como tal) se van a pasar a una nueva tabla dPSI_PASS (se podría haber puesto antes porque no considera los pvalores calculados, pero primero quería hacer los cálculos y finalmente definir las tablas):\n\n\nif(!is.na(PASS) & PASS==1){\n  \ndPSI_PASS[fila_PASS,]&lt;-dPSI_table[i,]\n\n#Una vez hemos acabado la línea\nfila_PASS=fila_PASS+1\n}\n\n\nSolo eventos que han pasado el threshold a, b y c (por comprobar los datos que se generan y poder explorar los constitutivos que se comportan como tal) se van a pasar a una nueva tabla dPSI_df (se podría haber puesto antes porque no considera los pvalores calculados, pero primero quería hacer los cálculos y finalmente definir las tablas):\n\n\nif(!is.na(PASS) & PASS==1 & \n   ((Group_1_mean&lt;Const_max & Group_2_mean&gt;Const_min) |  \n    (Group_2_mean&lt;Const_max & Group_1_mean&gt;Const_min) |\n    (Group_1_mean&lt;Const_max & Group_2_mean&gt;Const_max) |  \n    (Group_2_mean&lt;Const_max & Group_1_mean&gt;Const_max) | \n    (Group_1_mean&lt;Const_min & Group_2_mean&gt;Const_min) | \n    (Group_2_mean&lt;Const_min & Group_1_mean&gt;Const_min))){\n  \ndPSI_df[fila_df,]&lt;-dPSI_table[i,]\n\n#Una vez hemos acabado la línea\nfila_df=fila_df+1\n\n}\n\n\nAl final de cada bucle, se calculará el porcentaje de proceso que llevamos realizado en función del nº de filas que se han procesado con respecto a las totales y en función del tiempo que llevamos de proceso se estime el tiempo que queda de procesamiento [en función del tiempo que ha tardado en procesar el nº de filas que llevamos en cada momento del bucle (por lo que va ir fluctuando porque si, por ejemplo, hay muchos NAs al principio va a tardar poco en procesarlos ya que no tiene que hacer ninguna operación y nos puede dar un tiempo estimado bajo, a medida que pase el bucle y vaya haciendo cálculos tardará más y por lo tanto la estimación cambiará)]:\n\n\n#Se imprime el porcentaje de procesado y la hora\nif(i==round(nrow(rmdf)*porcentaje)){\n  \n  Hora_porcentaje&lt;-Sys.time()\n  \n  diferencia_segundos &lt;- as.numeric(difftime(Hora_porcentaje, Hora_inicio, units = \"secs\"))\n  tiempo_restante_segundos &lt;- diferencia_segundos / (porcentaje) * (1-porcentaje) \n  tiempo_restante_minutos &lt;- tiempo_restante_segundos / 60\n  tiempo_restante_horas &lt;- tiempo_restante_minutos / 60\n  \n    \n  print(paste(porcentaje*100, \" % (hora: \", format(Sys.time(), \"%X, %d/%b/%Y) ---  Tiempo restante estimado: \"), round(tiempo_restante_horas), \"h \", round(tiempo_restante_minutos %% 60), \"min\"))\n  \n  if(porcentaje==1){ \n         print(\"-------------------------------   Proceso finalizado   --------------------------------------\")\n  }\n  #definimos el siguiente porcentaje que se imprimirá\n  porcentaje&lt;-porcentaje+0.02\n  \n  }\n\n\n\n\n\n\n\nNote\n\n\n\nEsto es totalmente opcional pero viene bien para comprobar que el código sigue funcionando El output será el siguiente:\n[1] \"30 % (hora: 12:25:35, 11/Oct/2023) ---  Tiempo restante estimado:  4 h  50 min\"\n\n\nY aquí concluye el código. Cuando acabe el proceso se imprimirá el siguiente mensaje:\n[1] \"-------------------------------   Proceso finalizado   --------------------------------------\"\n\n\n\nY el resultado será algo como esto:\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTener en cuenta que te guarda como rowname el nº de la fila de la INCLUSION_table en la que se encontraban los datos. No los vas a ver así en la siguiente gráfica porque lo he eliminado.\n\n\nUna vez tenemos la tabla de datos podemos comenzar a realizar la representación gráfica de los mismos, la cual va a ser muy similar (tanto a nivel de código como visual) al análisis de expresión diferencial, solo que aquí representamos eventos de splicing:\n\n\n\n\n\n\nImportant\n\n\n\nRecuerda que los datos que utilizamos para graficar no son las medias sino los valores individuales de cada muestra. Estos valores no los hemos extraido en ningún momento en nuestro código anterior de manera que tenemos que recuperarlos. No lo he añadido para así poder ver un poco de manipulación de datos, que viene bien. Para recuprar estos valores he diseñado el siguiente código:\n\nPSI_pass_evets&lt;-data.frame(matrix(ncol=2+length(Samples_1)+length(Samples_2)))\ncolnames(PSI_pass_evets)&lt;-c(\"GENE\", \"EVENT\", Samples_1, Samples_2)\n\nfor (n in c(1:nrow(dPSI_df))){\n  \n  PSI_pass_evets[n, c(1, 2)]&lt;- dPSI_PASS[n, c(1, 2)]\n  \n  row_index&lt;- which(df$GENE == dPSI_PASS[n, 1] & df$EVENT == dPSI_PASS[n, 2])\n  \n  for (col in colnames(PSI_pass_evets)[c(3:ncol(PSI_pass_evets))]){\n    \n    col_index&lt;- which(col == colnames(df))\n  \n    PSI_pass_evets[n, col]&lt;- df[row_index, col_index]\n  }  \n  \n}\n\n\n\n\n\n\n\nNote\n\n\n\nTener en cuenta que te guarda como rowname el nº de la fila de la INCLUSION_table en la que se encontraban los datos. No los vas a ver así en la siguiente gráfica porque lo he eliminado.\n\n\nY generamos algo así:\n\n\n\n\n\n\n\nY ahora tendríamos que crear la variable gathered (la matriz larga) para poder realizar las gráficas:\n\ngathered_PSI &lt;- PSI_pass_evets %&gt;%\n  gather(colnames(PSI_pass_evets)[3:ncol(PSI_pass_evets)], key = \"Sample\", value = \"PSI\")\n\nhead(gathered_PSI)\n\n    GENE        EVENT  Sample   PSI\n1  ACOT9 HsaEX0001973 Basal_1 64.37\n2  MACF1 HsaEX0037169 Basal_1 39.58\n3   CD44 HsaEX0013865 Basal_1 45.21\n4   CD44 HsaEX0013866 Basal_1 43.93\n5 NEDD4L HsaEX0042432 Basal_1 21.90\n6  FNIP2 HsaEX0026187 Basal_1 55.87\n\n\n\n\n\n\n\n\nWarning\n\n\n\nEstamos asumiendo que tenemos el metadata cargado porque lo habíamos utilizado para el análisis de expresión diferencial, si necesitáramos cargarlo sería poniendo el siguiente código para cargarlo:\n\nmetaData &lt;- as.data.frame(read.csv('./Data/Metadata_Basal_vs_Luminal.csv', header = TRUE, row.name=1, sep = \",\"))\n\nmetaData %&gt;%  datatable(extensions = \"Buttons\",\n          options = list(paging = TRUE,\n                           scrollX=TRUE,\n                           searching = TRUE,\n                           ordering = TRUE,\n                           dom = 'Bfrtip',\n                           buttons = c( 'csv', 'excel'),\n                           pageLength=5,\n                           lengthMenu=c(3,5,10) ))\n\n\n\n\n\n\n\n\nPor último, le atribuimos el grupo al que pertenece cada una de las muestras a utilizando el metadata:\n\ngathered_PSI &lt;- inner_join(metaData %&gt;%\n  rownames_to_column(var = \"Sample\"), gathered_PSI)\n\nJoining with `by = join_by(Sample)`\n\nhead(gathered_PSI)\n\n   Sample cell_type   GENE        EVENT   PSI\n1 Basal_1     Basal  ACOT9 HsaEX0001973 64.37\n2 Basal_1     Basal  MACF1 HsaEX0037169 39.58\n3 Basal_1     Basal   CD44 HsaEX0013865 45.21\n4 Basal_1     Basal   CD44 HsaEX0013866 43.93\n5 Basal_1     Basal NEDD4L HsaEX0042432 21.90\n6 Basal_1     Basal  FNIP2 HsaEX0026187 55.87\n\n\n\n\n\nBoxplot de los más desregulados\n\n\nggplot(gathered_PSI) +\n        geom_boxplot(aes(x = EVENT, y = PSI, fill = cell_type)) +\n        scale_y_log10() +\n        xlab(\"Events\") +\n        ylab(\"Inclusion levels (PSI)\") +\n        ggtitle(\"Differencial Spliced Events\") +\n  facet_wrap(~GENE, scale=\"free\")+ \n  theme(axis.text.x = element_text( size = 7),\n        axis.text.y = element_text( size = 5),\n    strip.text.x = element_text(size = 4, face = \"bold\"), \n    legend.key.size=unit(2, \"mm\"))\n\n\n\n\nEsto son muchos genes pero si seleccionamos por ejemplo los 9 genes que presenten los eventos más diferencialmente spliceados:\n\n#Extraemos los 9 eventos con mayor diferencia de PSI\ndPSI_df$dPSI&lt;- as.numeric(dPSI_df$dPSI)\neventList&lt;- round(dPSI_df$dPSI, digits= 5)\nnames(eventList)&lt;- dPSI_df$EVENT\nTop_9_eventList&lt;- sort(eventList, decreasing = T) %&gt;% .[c(1:9)]\n                 \n#hacemos el filtro para los 8 eventos con mayor diferencia de PSI\ntop9_PSI&lt;- PSI_pass_evets %&gt;%\n           dplyr::filter(EVENT %in% names(Top_9_eventList)) \n\n#Ahora hacemos el gathered\nTop_9_gathered_events&lt;- top9_PSI %&gt;%\n           gather(colnames(PSI_pass_evets)[3:ncol(PSI_pass_evets)], \n           key = \"Sample\", value = \"PSI\") \n\n#Añadimos el metadata\nTop_9_gathered_events &lt;- inner_join(metaData %&gt;%\n  rownames_to_column(var = \"Sample\"), Top_9_gathered_events)\n\n#y ahora graficamos el heatmap\nggplot(Top_9_gathered_events) +\n        geom_boxplot(aes(x = EVENT, y = PSI, fill = cell_type)) +\n        scale_y_log10() +\n        xlab(\"Events\") +\n        ylab(\"Inclusion levels (PSI)\") +\n        ggtitle(\"Differencial Spliced Events\") +\n  facet_wrap(~GENE, scale=\"free\")+ \n  theme(axis.text.x = element_text( size = 7),\n        axis.text.y = element_text( size = 5),\n    strip.text.x = element_text(size = 7, face = \"bold\"), \n    legend.key.size=unit(2, \"mm\"))\n\n\n\n\n\nHeatmap\n\n\n#Primero vamos a crear un data.frame(a partir de ahora \"df\") que va a ser igual que PSI_pass_events pero con con la columna de eventos como rownames y las columnas van a ser solo las muestras:\nPSI_table&lt;- PSI_pass_evets %&gt;%\n          .[, -1] %&gt;%\n          as.tibble() %&gt;%\n          column_to_rownames(var = \"EVENT\") %&gt;%\n          as.data.frame() %&gt;%\n          mutate_if(is.character, as.numeric)\n\n#Ahora creamos las anotaciones\nannotation &lt;- metaData %&gt;% \n  rownames_to_column(var=\"samplename\") %&gt;%\n    dplyr::select(samplename, cell_type) %&gt;% \n    data.frame(row.names = \"samplename\")\n\n#Y hacemos el heatmap\npheatmap(PSI_table, \n         color = colorRampPalette(brewer.pal(6, \"YlOrRd\"))(100), \n         cluster_rows = T, \n         show_rownames = F,\n         show_colnames = F,\n         annotation = annotation, \n         border_color = NA, \n         fontsize = 10, \n         scale = \"row\", \n         fontsize_row = 10, \n         height = 20)\n\n\n\n\n\nPCA.\n\n\n#definimos la varibale p como el cálculo de los Componentes Principales\np&lt;-pca(PSI_table, metadata = metaData, removeVar=0.1)\n\n#Definimos una matriz de dos columnas para ver las dos gráficas juntas\npar(mflow = c(1, 2))\n\n#Calculamos el PC1vsPC2 bonito\np1&lt;- PCAtools::biplot(p,\n                 title = \"PC1 vs PC2\",\n                 lab=NULL,\n                 axisLabSize = 10,\n                 colby=\"cell_type\",\n                 colkey = c(\"Basal\"=\"forestgreen\", \"Luminal\"=\"lightblue\"),\n                 encircle = TRUE,\n                 encircleFill = TRUE,\n                 legendPosition = \"bottom\",\n                 legendLabSize = 8,\n                 legendIconSize = 4,\n                 legendTitleSize = 10)\n\n#Calculamos múltiples PCAs\np2&lt;- pairsplot(p,\n    components = getComponents(p, c(1:4)),\n    triangle = TRUE, \n    trianglelabSize = 16,\n    hline = 0, \n    vline = 0,\n    pointSize = 2,\n    gridlines.major = FALSE, \n    gridlines.minor = FALSE,\n    colby = 'cell_type',\n    title = 'Pairs plot',\n    titleLabSize = 12,\n    plotaxes = FALSE,\n    margingaps = unit(c(-0.01, -0.01, -0.01, -0.01), 'cm'))\n\ngridExtra::grid.arrange(p1, p2, ncol = 2)\n\n\n\n\n\nUso de VastDB. Podemos buscar información muy útil relacionada con nuestro evento de interés en esta DataBase. Muy recomendable.\n\n\n\n2.6.3.2 Análisis con betAS\nEsta herramienta ha sido desarrollada por Mariana Ascensão-Ferreira y Nuno L. Barbosa-Morais. También se ha publicado el preprint en bioRxiv:\nMariana Ascensão-Ferreira, Rita Martins-Silva, Nuno Saraiva-Agostinho and Nuno L. Barbosa-Morais (2023). betAS: intuitive analysis and visualisation of differential alternative splicing using beta distributions. bioRxiv\nPara analizarlo con betAS podemos ir directamente a su página web interactiva (similar a iDEP.96) o hacerlo en R (lo cual nos da un completo control de los datos). Tenemos que tener en cuenta que todavía es una herramienta en desarrollo.\nLa guía para R está en el siguiente enlace\nPara instalarlo en para R:\n\ninstall.packages(\"devtools\")\ndevtools::install_github(\"marianaferreira/betAS@dev\") #Esto es provisional. El @dev significa que nos estamos descargando un \"branch\" de github en concreto (en este caso el que ellos han llamado \"dev\")\n\nCargamos la libreía:\n\nlibrary(betAS)\n#además hay que instalar otras librerías recomendadas:\nlibrary(ggplot2)\nlibrary(plotly) \nlibrary(dplyr)\nlibrary(ggpubr)\n\nSe pueden utilizar INCLUSION_tables.tab generadas con vast-tools, los MATS.JC.txt genrados con rMATS o los .psi.gz generados para cada muestra mediante whippet mediante el uso de la función getDataset: - Para vast-tools:\n\n# Example to load data from vast-tools\ndataset &lt;- getDataset(pathTables=\"path/to/dataset/*INCLUSION_LEVELS_FULL*.tab\", tool=\"vast-tools\")\n\n# Example to load data from rMATS\ndataset &lt;- getDataset(pathTables=\"path/to/dataset/*MATS.JC.txt\", tool=\"rMATS\")\n\n# Example to load data from whippet\ndataset &lt;- getDataset(pathTables=list(\"path/to/sample1/*.psi.gz\",\n                                      \"path/to/sample2/*.psi.gz\",\n                                      \"path/to/sample3/*.psi.gz\"), tool=\"whippet\")\n\n\n\n\n\n\n\nNote\n\n\n\nDarnos cuenta de que lo último que definimos en esta función (getDataset) es la herramienta que utilizamos mediante el argumento tool =.\nOtra cosa importante a tener en cuenta es que para utilizar la herramienta whippet hay que definir al menos dos archivos .psi.gz.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nVuelvo a trabajar en el terminal porque al tener que manipular la INCLUSION_table, ya vimos que es muy pesada así que es mejor trabajar ahí. Pero todo lo voy a hacer en R osea que se puede hacer en nuestr o ordenador.\nDe igual manera que he hecho anteriormente, dejaré un descargable de los datos tratatos para que podáis practicar\n\n\nPara nuestro caso concreto sería:\n\ndataset &lt;- getDataset(pathTables=\"INCLUSION_LEVELS_FULL-hg38-6.tab\", tool=\"vast-tools\")\ntool &lt;- \"vast-tools\"\ndataset &lt;- getEvents(dataset, tool = tool)\n\nEsto crea un objeto que guarda tanto los valores de PSI como los de calidad en una especie de dataset simultáneos con las mismas características (como hacía DESeq2).\nPodemos realizar un filtro por tipo de evento. Por ejemplo, con el siguiente comando podemos quedarnos con los exon skipping solamente (el N=10hará que solo consideremos aquellos eventos de los que hayamos tenido un mínimo de 10 eventos):\n\ndataset_filtered &lt;- filterEvents(dataset, types=c(\"C1\", \"C2\", \"C3\", \"S\", \"MIC\"), N=10)\n\nUna vez hemos cargado y formateado nuestro dataset para poder utilizarlo, podemos realizar los filtros que queramos, por ejemplo:\n\ndataset_filtered &lt;- alternativeEvents(dataset_filtered, minPsi=1, maxPsi=99)\n\nA continuación podemos hacer una representación de la distribución del PSI por muestra (en el eje de la y tenemos la :\n\nbigPicturePlot &lt;- bigPicturePlot(table = dataset_filtered$PSI)\n#tenemos que indicar que queremos queremos ver la distribución del objeto PSI\nbigPicturePlot + theme_minimal()\n\n\nA continuación tenemos que definir los grupos para así poder hacer el análisis. Para ello:\n\nLeemos el archivo de metadata como un dataframe:\n\n\nmetadata&lt;- as.data.frame(read.csv(\"Data/Metadata_Basal_vs_Luminal.csv\"))\n\n\nDefinimos la variable “cell_type” com la variable con la que vamos a definir los grupos y guardamos los grupos en la variable groups y las muestras en la varieble samples:\n\n\ngroupingVariable &lt;- \"cell_type\"\n\ngroups &lt;- unique(metadata[,groupingVariable])\n#tener cuidado porque esta variable tiene que estar definida como caracter. Si tenemos algún error probar con lo siguiente:\n\n#groups &lt;- as.character(unique(metadata[,groupingVariable]))\n\nsamples &lt;- metadata$id\n\n\nVamos a representar una pie chart de la distribución de las muestras\n\n\ncolors &lt;- c(\"#FF9AA2\", \"#AFAAD1\")\n\ngroupList &lt;- list()\n\nfor(i in 1:length(groups)){\n\n  groupNames &lt;- samples[which(metadata[,groupingVariable] == groups[i])]\n\n  # Assign new group\n  currentNames &lt;- names(groupList)\n  groupList[[length(groupList)+1]] &lt;- list(name = groups[i],\n                                           samples = groupNames,\n                                           color = colors[i])\n  names(groupList) &lt;- make.unique(c(currentNames, groups[i]))\n\n}\n\nslices &lt;- rep(1, length(groups))\n\npie(slices, col = colors[1:length(groups)], border = \"black\", labels=groups, main = \"Color palette for group definition\")\n\n\n\n\n\n\n\n\n\n\nExplicación código del pie chart\n\n\n\n\nComenzamos definiendo los colores que vamos a utilizar. Como tenemos dos grupos solo vamos a definir dos colores:\n\n\ncolors &lt;- c(\"#FF9AA2\", \"#AFAAD1\")\n\n\nA continuación creamos una lista para asignar a cada grupo un color (con el bucle a continuación):\n\n\ngroupList &lt;- list()\n\nfor(i in 1:length(groups)){\n\n  groupNames &lt;- samples[which(metadata[,groupingVariable] == groups[i])]\n\n  # Asignamos un nuevo grupo\n  currentNames &lt;- names(groupList)\n  groupList[[length(groupList)+1]] &lt;- list(name = groups[i],\n                                           samples = groupNames,\n                                           color = colors[i])\n  names(groupList) &lt;- make.unique(c(currentNames, groups[i]))\n\n}\n#Visualicemos como queda la lista\n\n\nDefinimos el tamaño de las slices de las pie chart\n\n\nslices &lt;- rep(1, length(groups))\n\n\nPor úlimo graficamos el pie chart:\n\n\npie(slices, col = colors[1:length(groups)], border = \"black\", labels=groups, main = \"Color palette for group definition\")\n\n\n\n\n\n\nAhora es cuando viene la parte interesante de betAS por que comienza el análisis de splicing diferencial. La estadística del splicing diferencial se basa en la distribución beta de los eventos de splicnig como hemos mencionado anteriormente. Para ello, betAS calcula los siguientes parámetros para calcular la significancia:\n\nPdiff. Este enfoque toma los dos conjuntos de puntos aleatorios por condición y calcula, para el ∆PSI estimado de cada evento AS, la proporción de diferencias entre estos que son mayores que cero, lo que tiene la misma interpretación que preguntarse qué proporción de valores emitidos por la distribución beta para una condición son mayores que los emitidos para la otra, reflejando así la probabilidad de que el AS diferencial de PSIbetAS (grupo A) sea mayor que PSIbetAS (grupo B).\nF-estadística. betAS también permite realizar un análisis de varianza similar al ANOVA, comparando las variabilidades intergrupo e intragrupo. Para cada evento, within se considera el conjunto de diferencias entre cada par de muestras que forman parte del mismo grupo y between el conjunto de diferencias entre cada par de grupos. El cociente de los valores absolutos medios de between e within proporciona, por tanto, un estadístico “tipo F”. Esta métrica proporciona un compromiso entre el tamaño del efecto de las diferencias AS y su significación.\nFDR. Se utiliza la generación aleatoria de puntos a partir de una distribución beta para estimar la distribución nula del PSI y su precisión. A continuación, se selecciona aleatoriamente un punto de cada distribución nula de la muestra y, manteniendo la asignación de grupos de las muestras (es decir, qué muestras pertenecen a cada grupo), se calcula el ∆PSI entre grupos bajo la hipótesis nula. El proceso se repite muchas veces (10 000 por defecto) y el FDR es la proporción de simulaciones aleatorias ∆PSI que son mayores (es decir, más extremas) o iguales que el ∆PSI empírico.\n\nPrimero comenzamos definiendo el nombre de los grupos de forma compatible con las funciones que vamos a utilizar:\n\ngroupA    &lt;- \"Basal\"\ngroupB    &lt;- \"Luminal\"\n\nDefinimos las muestras que hay dentro de cada grupo:\n\nsamplesA    &lt;- groupList[[groupA]]$samples\nsamplesB    &lt;- groupList[[groupB]]$samples\n\nY convertimos las muestras en índices:\n\ncolsGroupA    &lt;- convertCols(dataset_filtered$PSI, samplesA)\ncolsGroupB    &lt;- convertCols(dataset_filtered$PSI, samplesB)\n\n\nPdiff. A continuación calculamos la probabilidad de differential splicing (Pdiff) entre los grupos para cada evento con la función prepareTableVolcano.\n\n\nvolcanoTable_Pdiff &lt;- prepareTableVolcano(psitable = dataset_filtered$PSI,\n                                    qualtable = dataset_filtered$Qual,\n                                    npoints = 500,\n                                    colsA = colsGroupA,\n                                    colsB = colsGroupB,\n                                    labA = groupA,\n                                    labB = groupB,\n                                    basalColor = \"#89C0AE\",\n                                    interestColor = \"#E69A9C\",\n                                    maxDevTable = maxDevSimulationN100)\n\nhead(volcanoTable_Pdiff[,c(\"GENE\",\"EVENT\",\"COORD\",\"Pdiff\",\"deltapsi\")])\n\n\nA continuación podemos graficar por ejemplo un volcano plot (la función plotVolcano está basaada en ggplot2 de manera que podemos aplicar funciones como theme() para modificar la gráfica):\n\nplotVolcano(betasTable = volcanoTable_Pdiff,\n                            labA = groupA,\n                              labB = groupB,\n                            basalColor = \"#89C0AE\",\n                            interestColor = \"#E69A9C\") +\n  ggtitle(\"Volcano plot of Pdiff of ΔPSI\")+\n  #con theme podemos cambiar muchas varibales a nuestro gusto\n  theme(\n    plot.title = element_text(size= 15, hjust = 0.5),\n    axis.title.x= element_text(size = 10),\n    axis.text.x = element_text(size = 10),# Tamaño de los labels en el eje X\n    axis.title.y = element_text(size = 10),\n    axis.text.y = element_text(size = 10)   # Tamaño de los labels en el eje Y\n  )\n#no he encontrado la forma de cambiar los puntos de tamaño\n\n\n\nF-statistic. Para calcular la F-estadística las funciones son similares a la que utilizamos para Pdiff. Comenzamos calculando este parámetro:\n\n\nvolcanoTable_Fstat &lt;- prepareTableVolcanoFstat(psitable = dataset_filtered$PSI,\n                                    qualtable = dataset_filtered$Qual,\n                                    npoints = 500,\n                                    colsA = colsGroupA,\n                                    colsB = colsGroupB,\n                                    labA = groupA,\n                                    labB = groupB,\n                                    basalColor = \"#89C0AE\",\n                                    interestColor = \"#E69A9C\",\n                                    maxDevTable = maxDevSimulationN100)\n\n\nhead(volcanoTable_Fstat[,c(\"GENE\",\"EVENT\",\"COORD\",\"Fstat\",\"deltapsi\")])\n\n\nY ahora podemos representar el volcano plot:\n\nplotVolcanoFstat(betasTable = volcanoTable_Fstat,\n                            labA = groupA,\n                            labB = groupB,\n                            basalColor = \"#89C0AE\",\n                            interestColor = \"#E69A9C\") +\n  ggtitle(\"Volcano plot of F-stat of ΔPSI\")+\n  theme(\n    plot.title = element_text(size= 15, hjust = 0.5),\n    axis.title.x= element_text(size = 10),\n    axis.text.x = element_text(size = 10),# Tamaño de los labels en el eje X\n    axis.title.y = element_text(size = 10),\n    axis.text.y = element_text(size = 10)   # Tamaño de los labels en el eje Y\n  )\n#no he encontrado la forma de cambiar los puntos de tamaño\n\n\n\n\n\n\n\n\nTip\n\n\n\nSe que estas gráficas están muy feas. Podríamos tener el control absoluto con ggplot + geom_point pero no me voy a parar ahora.\n\n\n\nFDR. Para calcular el FDR las funciones vuelven a ser similares a las utilizamos previamente. Comenzamos calculando este parámetro:\n\n\nvolcanoTable_FDR &lt;- prepareTableVolcanoFDR(psitable = dataset_filtered$PSI,\n                                    qualtable = dataset_filtered$Qual,\n                                    npoints = 500,\n                                    colsA = colsGroupA,\n                                    colsB = colsGroupB,\n                                    labA = groupA,\n                                    labB = groupB,\n                                    basalColor = \"#89C0AE\",\n                                    interestColor = \"#E69A9C\",\n                                    maxDevTable = maxDevSimulationN100,\n                                    nsim = 100) \n\nhead(volcanoTable_FDR[,c(\"GENE\",\"EVENT\",\"COORD\",\"FDR\",\"deltapsi\")])\n\n\nY volvemos a utilizar la función prefedefinida para representar un volcano:\n\nplotVolcanoFDR(betasTable = volcanoTable_FDR,\n                            labA = groupA,\n                            labB = groupB,\n                            basalColor = \"#89C0AE\",\n                            interestColor = \"#E69A9C\") +\n  ggtitle(\"Volcano plot of FDR of ΔPSI\")+\n  theme(\n    plot.title = element_text(size= 15, hjust = 0.5),\n    axis.title.x= element_text(size = 10),\n    axis.text.x = element_text(size = 10),# Tamaño de los labels en el eje X\n    axis.title.y = element_text(size = 10),\n    axis.text.y = element_text(size = 10)   # Tamaño de los labels en el eje Y\n  )\n\n\n\nRepresentación de eventos de interés: Vamos a representar el evento “HsaEX0041241” que fue uno de los que nos salió en mi análisis handmade a ver que sale. Con betAS podemos hacer gráficas muy chulas.\n\n\n#primero definimos el evento\neventID&lt;-\"HsaEX0041241\"\n\ntdensities &lt;- plotIndividualDensitiesList(eventID = eventID,\n                                          npoints = 500,\n                                          psitable = dataset$PSI,\n                                          qualtable = dataset$Qual,\n                                          groupList = groupList,\n                                          maxDevTable = maxDevSimulationN100)\n\ntdensities + theme_minimal() + ggtitle(eventID)\n\n\nOtra gráfica chula es la siguiente:\n\nplotPdiff &lt;- prepareTableEvent(eventID = eventID,\n                               psitable = dataset$PSI,\n                               qualtable = dataset$Qual,\n                               npoints = 500,\n                               colsA = colsGroupA,\n                               colsB = colsGroupB,\n                               labA = groupA,\n                               labB = groupB,\n                               basalColor = \"#89C0AE\",\n                               interestColor = \"#E69A9C\",\n                               maxDevTable = maxDevSimulationN100,\n                               nsim = 1000) %&gt;% \n  plotPDiffFromEventObjList()+ theme(\n    plot.title = element_text(size= 15, hjust = 0.5),\n    axis.title.x= element_text(size = 10),\n    axis.text.x = element_text(size = 10),# Tamaño de los labels en el eje X\n    axis.title.y = element_text(size = 10),\n    axis.text.y = element_text(size = 10)   # Tamaño de los labels en el eje Y\n  )\n\n\nplotFstat &lt;- prepareTableEvent(eventID = eventID,\n                               psitable = dataset$PSI,\n                               qualtable = dataset$Qual,\n                               npoints = 500,\n                               colsA = colsGroupA,\n                               colsB = colsGroupB,\n                               labA = groupA,\n                               labB = groupB,\n                               basalColor = \"#89C0AE\",\n                               interestColor = \"#E69A9C\",\n                               maxDevTable = maxDevSimulationN100,\n                               nsim = 1000) %&gt;% \n  plotFstatFromEventObjList()+ theme(\n    plot.title = element_text(size= 15, hjust = 0.5),\n    axis.title.x= element_text(size = 10),\n    axis.text.x = element_text(size = 10),# Tamaño de los labels en el eje X\n    axis.title.y = element_text(size = 10),\n    axis.text.y = element_text(size = 10)   # Tamaño de los labels en el eje Y\n  )\n\n\nplotFDR &lt;- prepareTableEvent(eventID = eventID,\n                               psitable = dataset$PSI,\n                               qualtable = dataset$Qual,\n                               npoints = 500,\n                               colsA = colsGroupA,\n                               colsB = colsGroupB,\n                               labA = groupA,\n                               labB = groupB,\n                               basalColor = \"#89C0AE\",\n                               interestColor = \"#E69A9C\",\n                               maxDevTable = maxDevSimulationN100,\n                               nsim = 1000) %&gt;% \n  plotFDRFromEventObjList()+ theme(\n    plot.title = element_text(size= 15, hjust = 0.5),\n    axis.title.x= element_text(size = 10),\n    axis.text.x = element_text(size = 10),# Tamaño de los labels en el eje X\n    axis.title.y = element_text(size = 10),\n    axis.text.y = element_text(size = 10)   # Tamaño de los labels en el eje Y\n  )\n\nggarrange(plotPdiff,plotFstat,plotFDR, ncol=3)\n\n\n\n\n\n\n\n\nTip\n\n\n\nDe nuevo, estas gráficas están muy feas. Podríamos tener el control absoluto con ggplot + geom_point pero no me voy a parar ahora.\n\n\n\nComparación entre varios grupos. Para esto podemos ir al punto 6 del vignette."
  },
  {
    "objectID": "AS_Analysis.html#analisis-de-enriquecimiento",
    "href": "AS_Analysis.html#analisis-de-enriquecimiento",
    "title": "Alternative Splicing",
    "section": "2.7 Analisis de Enriquecimiento",
    "text": "2.7 Analisis de Enriquecimiento\n\n2.7.1 Paquete 1\n\n\n2.7.2 Paquete 2"
  },
  {
    "objectID": "AS_Analysis.html#paquete-1",
    "href": "AS_Analysis.html#paquete-1",
    "title": "Alternative Splicing",
    "section": "2.8 Paquete 1",
    "text": "2.8 Paquete 1"
  },
  {
    "objectID": "AS_Analysis.html#paquete-2",
    "href": "AS_Analysis.html#paquete-2",
    "title": "Alternative Splicing",
    "section": "2.9 Paquete 2",
    "text": "2.9 Paquete 2"
  },
  {
    "objectID": "AS_Analysis.html#psichomics",
    "href": "AS_Analysis.html#psichomics",
    "title": "Alternative Splicing",
    "section": "3.1 PSIchomics",
    "text": "3.1 PSIchomics\nPSIchomics es un paquete interactivo de R para el análisis integrador del splicing alternativo y la expresión génica basado en The Cancer Genome Atlas (TCGA) (que contiene datos moleculares asociados a 34 tipos de tumores), el proyecto Genotype-Tissue Expression (GTEx) (que contiene datos de múltiples tejidos humanos normales), el Sequence Read Archive (SRA) y datos proporcionados por el usuario. Los datos de los proyectos GTEx, TCGA y SRA seleccionados incluyen información asociada al sujeto/muestra y datos transcriptómicos, como la cuantificación de lecturas RNA-Seq alineadas con uniones de empalme (en adelante, junction quantification) y exones.\nEsta herramienta ha sido desarollada por el Dr. Nuno L. Barbosa-Morais y tiene su aplicación interactiva en internet (para no depender de código) y su correspondiente tutorial, pero como sabeis, aquí hemos venido a jugar.\n\nNuno Saraiva-Agostinho and Nuno L. Barbosa-Morais (2019). psichomics: graphical application for alternative splicing quantification and analysis. Nucleic Acids Research.\n\n\nInstalación\n\n\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(\"psichomics\")\n\n\nAtivamos el paquete:\n\n\nlibrary(psichomics)\n\n\n3.1.1 Descarga y carga de datos del TCGA\nLos datos se descargan de FireBrowse, un servicio que aloja datos procesados de TCGA, según sea necesario para ejecutar los análisis posteriores. Antes de descargar los datos, compruebe las siguientes opciones:\n\nTipos de tumores disponibles\n\n\n# Available tumour types\ncohorts &lt;- getFirebrowseCohorts()\nhead(cohorts)\n\n                                                               ACC \n                                        \"Adrenocortical carcinoma\" \n                                                              BLCA \n                                    \"Bladder Urothelial Carcinoma\" \n                                                              BRCA \n                                       \"Breast invasive carcinoma\" \n                                                              CESC \n\"Cervical squamous cell carcinoma and endocervical adenocarcinoma\" \n                                                              CHOL \n                                              \"Cholangiocarcinoma\" \n                                                              COAD \n                                            \"Colon adenocarcinoma\" \n\n\n\nFechas de las muestras disponibles (suena raro pero es para la curva de supervivencia o recidiva, lo tengo que checkear)\n\n\n# Available sample dates\ndate &lt;- getFirebrowseDates()\nhead(date)\n\n[1] \"2016-01-28\" \"2015-11-01\" \"2015-08-21\" \"2015-06-01\" \"2015-04-02\"\n[6] \"2015-02-04\"\n\n\n\n# Available data types\ndataTypes &lt;- getFirebrowseDataTypes()\nhead(dataTypes)\n\n$`RNA sequencing`\n  Junction quantification       Exon quantification           Exon expression \n\"junction_quantification\"     \"exon_quantification\"         \"exon_expression\" \n      Junction expression                RSEM genes     RSEM genes normalized \n    \"junction_expression\"              \"RSEM_genes\"   \"RSEM_genes_normalized\" \n            RSEM isoforms                Preprocess \n          \"RSEM_isoforms\"              \"Preprocess\" \n\n\n\n\n\n\n\n\nNote\n\n\n\nTener en cuenta que también existe la opción de Gene expression (normalised by RSEM). Sin embargo, no recomiendan cargar los datos de expresión génica sin procesar, seguidos de filtrado y normalización como se demuestra a continuación.\n\n\nPara probar, vmaos a descargar y cargar la BBDD de cáncer de mama (BRCA). Primero cargamos los datos de trabajo:\n\n# Set download folder\nfolder &lt;- getDownloadsFolder()\n\n# Download and load most recent junction quantification and clinical data from\n# TCGA/FireBrowse for Breast Cancer\ndata &lt;- loadFirebrowseData(folder=folder,\n                           cohort=\"BRCA\",\n                           data=c(\"clinical\", \"junction_quantification\",\n                                  \"RSEM_genes\"),\n                           date=\"2016-01-28\")\n\nWarning in fread(file, sep = delim, header = FALSE, data.table = FALSE, :\nDiscarded single-line footer: &lt;&lt;chr1:207010368:+,chr1:207013195:+ 0 0 0 0 0 2 0\n0 0 0 0 9 0 0 0 0 0 0 10 0 0 0 0 8 0 6 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 21 0 5\n0 0 0 0 0 2170 0 0 0 7 5 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 2 0 0 8 0 0 0 0 0 52 0\n0 0 0 0 0 0 0 7 31 0 0 0 0 0 0 0 0 0 7 34 0 0 11 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n0 0 0 0 0 27 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 5 0 7 0 0 2 5 0 0 0 0 0 0 0 0 7 0 0\n9 0 45 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 0 0 6 9 0 0 0 110 5 0 0 0 107 0 0 0 0 0\n0 0 0 0 0 4 10 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 &gt;&gt;\n\n\nWarning in parseFile(format, file, ..., verbose = verbose): Discarded 1 row\nwith duplicated rownames.\n\n\nWarning in fread(file, sep = delim, header = FALSE, data.table = FALSE, :\nDiscarded single-line footer: &lt;&lt;ADD1|118 11623.00 0.00011818936474762\nuc003gfn.2,uc003gfo.2,uc003gfp.2,uc003gfq.2,uc003gfr.2,uc003gfs.2,uc003gft.3,uc003gfu.2,uc010ico.1\n8143.00 0.000125304907059489\nuc003gfn.2,uc003gfo.2,uc003gfp.2,uc003gfq.2,uc003gfr.2,uc003gfs.2,uc003gft.3,uc003gfu.2,uc010ico.1\n3817.00 9.3820132107878e-05\nuc003gfn.2,uc003gfo.2,uc003gfp.2,uc003gfq.2,uc003gfr.2,uc003gfs.2,uc003gft.3,uc003gfu.2,uc010ico.1\n13995.00 0.000146276412898295\nuc003gfn.2,uc003gfo.2,uc003gfp.2,uc003gfq.2,uc003gfr.2,uc003gfs.2,uc003gft.3,u&gt;&gt;\n\nnames(data) \n\n[1] \"Breast invasive carcinoma NA\"\n\n#Nos devolverá:\n#[1] \"Breast invasive carcinoma NA\"\n\nnames(data[[1]])\n\n[1] \"Clinical data\"                           \n[2] \"Junction quantification (Illumina HiSeq)\"\n[3] \"Gene expression (Illumina HiSeq)\"        \n[4] \"Sample metadata\"                         \n\n#Nos devuelve:\n#[1] \"Clinical data\"                            \"Junction quantification (Illumina HiSeq)\"\n#[3] \"Gene expression (Illumina HiSeq)\"         \"Sample metadata\"  \n\n#Recuperamos la información en variables para utilizarlas posteriormente:\n\nclinical      &lt;- data[[1]]$`Clinical data`\nsampleInfo    &lt;- data[[1]]$`Sample metadata`\njunctionQuant &lt;- data[[1]]$`Junction quantification (Illumina HiSeq)`\ngeneExpr      &lt;- data[[1]]$`Gene expression`\n\nLos datos sólo se descargan si los archivos no están presentes en la carpeta dada. En otras palabras, si los archivos ya se descargaron, la función sólo cargará los archivos, por lo que es posible reutilizar el código anterior sólo para cargar los archivos solicitados.\n\n\n\n\n\n\nMétodos para cargar datos desde distintos repositorios\n\n\n\nLos propios autores de este fantástico paquete contemplan la posibilidad de subir datos propios así como datos desde otros repositorios. Está muy bien explicado en el siguiente enlace\n\n\n\n\n3.1.2 Filtrar y normalizar expresión génica\nComo este paquete no se centra en el análisis de la expresión génica, sugerimos leer la sección RNA-seq de la guía de usuario de limma. No obstante, presentamos los siguientes comandos para filtrar y normalizar rápidamente la expresión génica:\n\n# Chequeamos que los genes tengan al menos 10 count en al menos en 15 o más muestras\n# del total de muestras\n\nfilter &lt;- filterGeneExpr(geneExpr, minCounts=10, minTotalCounts=15)\n\ngeneExprNorm &lt;- normaliseGeneExpression(geneExpr,\n                                        geneFilter=filter,\n                                        method=\"TMM\",\n                                        log2transform=TRUE)\n\n\n\n\n\n\n\nQué hace normaliseGeneExpression()\n\n\n\n\nFiltra la expresión génica basándose en su argumento geneFilter\nNormaliza la expresión génica con edgeR::calcNormFactors (internamente) usando el método de media recortada de valores M (TMM) (por defecto)\nCalcula log2-cuentas por millón (logCPM)\n\n\n\n\n\n3.1.3 Cuantificación de splicing altenativo\nTras cargar los datos clínicos y de junction quantification de splicing alternativo de TCGA, cuantifique el splicing alternativo haciendo clic en el panel verde Cuantificación de splicing alternativo.\nComo se ha mencionado anteriormente, el splicing alternativo se cuantifica a partir de la cuantificación de uniones previamente cargada y de un archivo de anotación de splicing alternativo. Para comprobar los archivos de anotación disponibles:\n\nannotList &lt;- listSplicingAnnotations()\nannotList\n\n                                           Human hg19 (2016-10-11) \n                                                         \"AH51461\" \n                                           Human hg19 (2017-10-20) \n                                                         \"AH60272\" \n                                           Human hg38 (2018-04-30) \n                                                         \"AH63657\" \n                           Human hg19 from VAST-TOOLS (2021-06-15) \n                                                         \"AH95569\" \n                           Human hg38 from VAST-TOOLS (2021-06-15) \n                                                         \"AH95570\" \n                     Mus musculus mm9 from VAST-TOOLS (2021-06-15) \n                                                         \"AH95571\" \n                    Mus musculus mm10 from VAST-TOOLS (2021-06-15) \n                                                         \"AH95572\" \n                   Bos taurus bosTau6 from VAST-TOOLS (2021-06-15) \n                                                         \"AH95573\" \n                Gallus gallus galGal3 from VAST-TOOLS (2021-06-15) \n                                                         \"AH95574\" \n                Gallus gallus galGal4 from VAST-TOOLS (2021-06-15) \n                                                         \"AH95575\" \n           Xenopus tropicalis xenTro3 from VAST-TOOLS (2021-06-15) \n                                                         \"AH95576\" \n                 Danio rerio danRer10 from VAST-TOOLS (2021-06-15) \n                                                         \"AH95577\" \n    Branchiostoma lanceolatum braLan2 from VAST-TOOLS (2021-06-15) \n                                                         \"AH95578\" \nStrongylocentrotus purpuratus strPur4 from VAST-TOOLS (2021-06-15) \n                                                         \"AH95579\" \n          Drosophila melanogaster dm6 from VAST-TOOLS (2021-06-15) \n                                                         \"AH95580\" \n           Strigamia maritima strMar1 from VAST-TOOLS (2021-06-15) \n                                                         \"AH95581\" \n          Caenorhabditis elegans ce11 from VAST-TOOLS (2021-06-15) \n                                                         \"AH95582\" \n      Schmidtea mediterranea schMed31 from VAST-TOOLS (2021-06-15) \n                                                         \"AH95583\" \n       Nematostella vectensis nemVec1 from VAST-TOOLS (2021-06-15) \n                                                         \"AH95584\" \n        Arabidopsis thaliana araTha10 from VAST-TOOLS (2021-06-15) \n                                                         \"AH95585\" \n\n\n\n\n\n\n\n\nCustom splicing annotation\n\n\n\nSe pueden preparar anotaciones adicionales de splicing alternativo para psichomics analizando la anotación de programas como VAST-TOOLS, MISO, SUPPA y rMATS. Tener en cuenta que SUPPA y rMATS son capaces de crear su anotación de splicing basándose en la anotación del transcrito. Por favor, lea Preparación de anotaciones de splicing alternativo.\n\n\nVamos a cargar las anotaciones de la versión hg19 del genoma (porque es la que usan en el ejemplo):\n\nhg19 &lt;- listSplicingAnnotations(assembly=\"hg19\")[[1]]\nannotation &lt;- loadAnnotation(hg19)\n\nloading from cache\n\n\nUna vez quemos cargado la anotación, podemos ver los tipos de eventos que se han cargado:\n\ngetSplicingEventTypes()\n\n                                         Skipped exon \n                                                 \"SE\" \n                              Mutually exclusive exon \n                                                \"MXE\" \n                           Alternative 5' splice site \n                                               \"A5SS\" \n                           Alternative 3' splice site \n                                               \"A3SS\" \n                               Alternative first exon \n                                                \"AFE\" \n                                Alternative last exon \n                                                \"ALE\" \nAlternative first exon (exon-centred - less reliable) \n                                           \"AFE_exon\" \n Alternative last exon (exon-centred - less reliable) \n                                           \"ALE_exon\" \n\n\nDe igual manera que para la expresión génica, se filtrarán aquellos elementos que no tengan un mínimo de reads\n\nminReads &lt;- 10 # default\n\npsi &lt;- quantifySplicing(annotation, junctionQuant, minReads=minReads)\n\nLos eventos tienen el siguiente formato:\n\nevents &lt;- rownames(psi)\nhead(events)\n\n[1] \"SE_1_-_15796_15038_14970_14829_WASH7P\"\n[2] \"SE_1_-_17915_17742_17606_17368_WASH7P\"\n[3] \"SE_1_-_24738_18366_18268_18061_WASH7P\"\n[4] \"SE_1_-_24738_18369_18268_18061_WASH7P\"\n[5] \"SE_1_-_24738_18379_18268_18061_WASH7P\"\n[6] \"SE_1_-_24738_18554_18501_18369_WASH7P\"\n\n\nDónde, por ejemplo, el elemento SE_1_-_2125078_2124414_2124284_2121220_C1orf86 está compuesto de: - SE. Refiere al tpo de evento. -1. Cromosoma --. Strand (no se a qué se refiere) - Cohordenadas del evento. -C1orf86`. Gen en el que ha ocurrido el evento.\n\n\n3.1.4 Creación de grupos de comparación\nVamos a crear grupos basados en los tipos de muestras disponibles (es decir, Metastásico, Tumor sólido primario y Tejido sólido normal) y en los estadios tumorales. Como los estadios tumorales se dividen en subestadios, fusionaremos los subestadios para tener sólo muestras tumorales de los estadios I, II, III y IV (las muestras del estadio X se descartan porque son muestras tumorales no caracterizadas).\n\n# Agrupamos las muestras en función de si son normales o tumorales\ntypes  &lt;- createGroupByAttribute(\"Sample types\", sampleInfo)\nnormal &lt;- types$`Solid Tissue Normal`\ntumour &lt;- types$`Primary solid Tumor`\n\n# Agrupamos en función de si son normales o de algún estadío tumoral\nstages &lt;- createGroupByAttribute(\n    \"patient.stage_event.pathologic_stage_tumor_stage\", clinical)\ngroups &lt;- list()\nfor (i in c(\"i\", \"ii\", \"iii\", \"iv\")) {\n    stage &lt;- Reduce(union,\n           stages[grep(sprintf(\"stage %s[a|b|c]{0,1}$\", i), names(stages))])\n    # Incluimos solo las muestras tumorales\n    stageTumour &lt;- names(getSubjectFromSample(tumour, stage))\n    elem &lt;- list(stageTumour)\n    names(elem) &lt;- paste(\"Tumour Stage\", toupper(i))\n    groups &lt;- c(groups, elem)\n}\ngroups &lt;- c(groups, Normal=list(normal))\n\n\n\n\n\n\n\nExplicación del código paso a paso\n\n\n\n\n\n\nCreación de grupos (en una lista) en función de etapas tumorales:\n\n\nstages &lt;- createGroupByAttribute(\"patient.stage_event.pathologic_stage_tumor_stage\", clinical)\n\n#vamosa a visualizarlo\nhead(stages)\n\n$`NA`\n[1] \"TCGA-A8-A08Z\" \"TCGA-B6-A0RP\" \"TCGA-BH-A1F6\" \"TCGA-D8-A13Z\" \"TCGA-D8-A141\"\n[6] \"TCGA-D8-A147\" \"TCGA-D8-A1JA\" \"TCGA-EW-A1J2\"\n\n$`stage i`\n [1] \"TCGA-A7-A0CD\" \"TCGA-AR-A2LR\" \"TCGA-BH-A0B6\" \"TCGA-BH-A0DO\" \"TCGA-E2-A15O\"\n [6] \"TCGA-GM-A2DD\" \"TCGA-GM-A2DO\" \"TCGA-A1-A0SB\" \"TCGA-A1-A0SE\" \"TCGA-A2-A0EP\"\n[11] \"TCGA-A2-A0YF\" \"TCGA-A2-A0YI\" \"TCGA-A2-A259\" \"TCGA-A2-A3XZ\" \"TCGA-A7-A3IY\"\n[16] \"TCGA-A8-A06O\" \"TCGA-A8-A08A\" \"TCGA-A8-A095\" \"TCGA-A8-A0AD\" \"TCGA-AO-A03M\"\n[21] \"TCGA-AO-A03U\" \"TCGA-AO-A03V\" \"TCGA-AR-A1AJ\" \"TCGA-AR-A1AK\" \"TCGA-AR-A1AP\"\n[26] \"TCGA-AR-A1AX\" \"TCGA-AR-A1AY\" \"TCGA-AR-A24N\" \"TCGA-AR-A24P\" \"TCGA-AR-A24S\"\n[31] \"TCGA-AR-A252\" \"TCGA-AR-A255\" \"TCGA-AR-A2LE\" \"TCGA-B6-A0X0\" \"TCGA-B6-A1KI\"\n[36] \"TCGA-B6-A402\" \"TCGA-B6-A40B\" \"TCGA-BH-A0AV\" \"TCGA-BH-A0B0\" \"TCGA-BH-A0B8\"\n[41] \"TCGA-BH-A0BG\" \"TCGA-BH-A0BL\" \"TCGA-BH-A0BO\" \"TCGA-BH-A0BP\" \"TCGA-BH-A0BQ\"\n[46] \"TCGA-BH-A0BR\" \"TCGA-BH-A0BW\" \"TCGA-BH-A0C3\" \"TCGA-BH-A0DX\" \"TCGA-BH-A0H3\"\n[51] \"TCGA-BH-A0H5\" \"TCGA-BH-A0H6\" \"TCGA-BH-A0HA\" \"TCGA-BH-A0HY\" \"TCGA-BH-A0W7\"\n[56] \"TCGA-BH-A0WA\" \"TCGA-BH-A18K\" \"TCGA-BH-A18P\" \"TCGA-BH-A18S\" \"TCGA-BH-A1ET\"\n[61] \"TCGA-BH-A1EU\" \"TCGA-BH-A1FD\" \"TCGA-BH-A1FG\" \"TCGA-BH-A209\" \"TCGA-E2-A14S\"\n[66] \"TCGA-E2-A14U\" \"TCGA-E2-A14Z\" \"TCGA-E2-A152\" \"TCGA-E2-A154\" \"TCGA-E2-A156\"\n[71] \"TCGA-E2-A15C\" \"TCGA-E2-A15F\" \"TCGA-E2-A15J\" \"TCGA-E2-A1IF\" \"TCGA-E2-A1IH\"\n[76] \"TCGA-E2-A1II\" \"TCGA-E2-A1IJ\" \"TCGA-E2-A1IN\" \"TCGA-E2-A1IO\" \"TCGA-E2-A1LH\"\n[81] \"TCGA-EW-A1IY\" \"TCGA-EW-A1J6\" \"TCGA-GM-A2D9\" \"TCGA-GM-A2DH\" \"TCGA-GM-A2DI\"\n[86] \"TCGA-GM-A2DK\" \"TCGA-GM-A2DL\" \"TCGA-OL-A66J\" \"TCGA-S3-AA14\" \"TCGA-Z7-A8R6\"\n\n$`stage ia`\n [1] \"TCGA-A2-A0CQ\" \"TCGA-A7-A26F\" \"TCGA-A7-A3J1\" \"TCGA-BH-A18H\" \"TCGA-BH-A8FY\"\n [6] \"TCGA-E2-A1BC\" \"TCGA-LL-A440\" \"TCGA-LL-A740\" \"TCGA-3C-AALK\" \"TCGA-A2-A04N\"\n[11] \"TCGA-A2-A04Q\" \"TCGA-A2-A04R\" \"TCGA-A2-A0CP\" \"TCGA-A2-A0D3\" \"TCGA-A2-A0EM\"\n[16] \"TCGA-A2-A0EO\" \"TCGA-A2-A0EU\" \"TCGA-A2-A0EV\" \"TCGA-A2-A0SX\" \"TCGA-A7-A0DC\"\n[21] \"TCGA-AC-A3QQ\" \"TCGA-AC-A8OP\" \"TCGA-AC-A8OR\" \"TCGA-AN-A0FF\" \"TCGA-AN-A0FN\"\n[26] \"TCGA-AN-A0FS\" \"TCGA-AN-A0FY\" \"TCGA-AO-A0J2\" \"TCGA-AO-A0J4\" \"TCGA-B6-A0I2\"\n[31] \"TCGA-B6-A0IP\" \"TCGA-B6-A0RN\" \"TCGA-B6-A0RU\" \"TCGA-BH-A0B9\" \"TCGA-BH-A0E6\"\n[36] \"TCGA-BH-A0EB\" \"TCGA-BH-A0H0\" \"TCGA-BH-A0HB\" \"TCGA-BH-A0HF\" \"TCGA-BH-A0HI\"\n[41] \"TCGA-BH-A0HN\" \"TCGA-BH-A0HU\" \"TCGA-BH-A0HW\" \"TCGA-BH-A18G\" \"TCGA-BH-A1FU\"\n[46] \"TCGA-BH-A201\" \"TCGA-BH-A5J0\" \"TCGA-BH-A8FZ\" \"TCGA-C8-A3M8\" \"TCGA-D8-A13Y\"\n[51] \"TCGA-D8-A1J9\" \"TCGA-D8-A1JH\" \"TCGA-D8-A1JP\" \"TCGA-D8-A1JS\" \"TCGA-D8-A1JU\"\n[56] \"TCGA-D8-A1XA\" \"TCGA-D8-A1XM\" \"TCGA-D8-A1XU\" \"TCGA-D8-A27E\" \"TCGA-D8-A27M\"\n[61] \"TCGA-D8-A27P\" \"TCGA-D8-A4Z1\" \"TCGA-E2-A15P\" \"TCGA-E2-A1IU\" \"TCGA-E2-A1LS\"\n[66] \"TCGA-E2-A573\" \"TCGA-E2-A576\" \"TCGA-E9-A1R4\" \"TCGA-E9-A1R5\" \"TCGA-E9-A1RA\"\n[71] \"TCGA-E9-A229\" \"TCGA-E9-A22B\" \"TCGA-E9-A247\" \"TCGA-E9-A54X\" \"TCGA-EW-A1J3\"\n[76] \"TCGA-EW-A1PF\" \"TCGA-LD-A9QF\" \"TCGA-LL-A441\" \"TCGA-LL-A5YO\" \"TCGA-LL-A73Y\"\n[81] \"TCGA-OL-A5RX\" \"TCGA-OL-A5RZ\" \"TCGA-OL-A66L\" \"TCGA-OL-A6VO\" \"TCGA-OL-A6VR\"\n[86] \"TCGA-WT-AB44\"\n\n$`stage ib`\n[1] \"TCGA-AC-A5EI\" \"TCGA-A2-A0ER\" \"TCGA-A2-A0T3\" \"TCGA-BH-A42V\" \"TCGA-E2-A106\"\n[6] \"TCGA-E2-A570\" \"TCGA-OL-A66H\"\n\n$`stage ii`\n[1] \"TCGA-AR-A2LM\" \"TCGA-B6-A0WZ\" \"TCGA-BH-A202\" \"TCGA-EW-A6SA\" \"TCGA-EW-A6SB\"\n[6] \"TCGA-OK-A5Q2\"\n\n$`stage iia`\n  [1] \"TCGA-A1-A0SP\" \"TCGA-A2-A04V\" \"TCGA-A2-A25A\" \"TCGA-A7-A13G\" \"TCGA-A7-A26H\"\n  [6] \"TCGA-A7-A26I\" \"TCGA-A8-A08S\" \"TCGA-A8-A091\" \"TCGA-A8-A093\" \"TCGA-A8-A09I\"\n [11] \"TCGA-A8-A09K\" \"TCGA-AC-A3W5\" \"TCGA-AC-A5XS\" \"TCGA-AC-A62X\" \"TCGA-AO-A0JI\"\n [16] \"TCGA-AO-A1KT\" \"TCGA-AQ-A54N\" \"TCGA-AQ-A54O\" \"TCGA-AR-A5QM\" \"TCGA-BH-A0EA\"\n [21] \"TCGA-BH-A1F5\" \"TCGA-D8-A146\" \"TCGA-E2-A158\" \"TCGA-E2-A1LG\" \"TCGA-EW-A1P3\"\n [26] \"TCGA-LL-A442\" \"TCGA-LL-A50Y\" \"TCGA-OL-A5RU\" \"TCGA-W8-A86G\" \"TCGA-5T-A9QA\"\n [31] \"TCGA-A1-A0SD\" \"TCGA-A1-A0SF\" \"TCGA-A1-A0SH\" \"TCGA-A1-A0SK\" \"TCGA-A1-A0SM\"\n [36] \"TCGA-A1-A0SN\" \"TCGA-A2-A04T\" \"TCGA-A2-A04U\" \"TCGA-A2-A04X\" \"TCGA-A2-A0CM\"\n [41] \"TCGA-A2-A0CT\" \"TCGA-A2-A0CU\" \"TCGA-A2-A0CX\" \"TCGA-A2-A0CZ\" \"TCGA-A2-A0D0\"\n [46] \"TCGA-A2-A0D1\" \"TCGA-A2-A0D2\" \"TCGA-A2-A0EN\" \"TCGA-A2-A0EQ\" \"TCGA-A2-A0ES\"\n [51] \"TCGA-A2-A0ST\" \"TCGA-A2-A0SU\" \"TCGA-A2-A0T4\" \"TCGA-A2-A0T5\" \"TCGA-A2-A0T7\"\n [56] \"TCGA-A2-A0YK\" \"TCGA-A2-A0YM\" \"TCGA-A2-A1FZ\" \"TCGA-A2-A25F\" \"TCGA-A2-A3XV\"\n [61] \"TCGA-A2-A3XX\" \"TCGA-A2-A4RX\" \"TCGA-A2-A4S0\" \"TCGA-A2-A4S1\" \"TCGA-A7-A0CE\"\n [66] \"TCGA-A7-A0CG\" \"TCGA-A7-A0CH\" \"TCGA-A7-A0CJ\" \"TCGA-A7-A0D9\" \"TCGA-A7-A0DA\"\n [71] \"TCGA-A7-A0DB\" \"TCGA-A7-A13D\" \"TCGA-A7-A26G\" \"TCGA-A7-A26J\" \"TCGA-A7-A3IZ\"\n [76] \"TCGA-A7-A3J0\" \"TCGA-A7-A3RF\" \"TCGA-A7-A4SD\" \"TCGA-A7-A4SE\" \"TCGA-A7-A4SF\"\n [81] \"TCGA-A7-A56D\" \"TCGA-A7-A5ZV\" \"TCGA-A7-A5ZW\" \"TCGA-A7-A6VV\" \"TCGA-A7-A6VW\"\n [86] \"TCGA-A7-A6VX\" \"TCGA-A8-A06Y\" \"TCGA-A8-A076\" \"TCGA-A8-A07B\" \"TCGA-A8-A07C\"\n [91] \"TCGA-A8-A07G\" \"TCGA-A8-A07O\" \"TCGA-A8-A07S\" \"TCGA-A8-A07Z\" \"TCGA-A8-A081\"\n [96] \"TCGA-A8-A086\" \"TCGA-A8-A08B\" \"TCGA-A8-A08C\" \"TCGA-A8-A08G\" \"TCGA-A8-A08H\"\n[101] \"TCGA-A8-A08I\" \"TCGA-A8-A090\" \"TCGA-A8-A094\" \"TCGA-A8-A096\" \"TCGA-A8-A09V\"\n[106] \"TCGA-A8-A0A1\" \"TCGA-A8-A0A2\" \"TCGA-A8-A0A4\" \"TCGA-A8-A0A9\" \"TCGA-A8-A0AB\"\n[111] \"TCGA-AC-A23G\" \"TCGA-AC-A23H\" \"TCGA-AC-A2FB\" \"TCGA-AC-A3YJ\" \"TCGA-AC-A6IW\"\n[116] \"TCGA-AC-A7VB\" \"TCGA-AC-A8OS\" \"TCGA-AN-A03X\" \"TCGA-AN-A03Y\" \"TCGA-AN-A046\"\n[121] \"TCGA-AN-A049\" \"TCGA-AN-A0AK\" \"TCGA-AN-A0AM\" \"TCGA-AN-A0AR\" \"TCGA-AN-A0AT\"\n[126] \"TCGA-AN-A0FD\" \"TCGA-AN-A0FL\" \"TCGA-AN-A0FV\" \"TCGA-AN-A0FX\" \"TCGA-AN-A0G0\"\n[131] \"TCGA-AN-A0XL\" \"TCGA-AN-A0XU\" \"TCGA-AO-A03O\" \"TCGA-AO-A0J6\" \"TCGA-AO-A0J8\"\n[136] \"TCGA-AO-A0JC\" \"TCGA-AO-A0JF\" \"TCGA-AO-A124\" \"TCGA-AO-A125\" \"TCGA-AO-A126\"\n[141] \"TCGA-AO-A128\" \"TCGA-AO-A12A\" \"TCGA-AO-A12B\" \"TCGA-AO-A12D\" \"TCGA-AO-A12F\"\n[146] \"TCGA-AO-A12G\" \"TCGA-AO-A12H\" \"TCGA-AO-A1KP\" \"TCGA-AO-A1KR\" \"TCGA-AO-A1KS\"\n[151] \"TCGA-AQ-A04J\" \"TCGA-AQ-A04L\" \"TCGA-AR-A0TP\" \"TCGA-AR-A0TU\" \"TCGA-AR-A0TV\"\n[156] \"TCGA-AR-A0TX\" \"TCGA-AR-A0TY\" \"TCGA-AR-A0U4\" \"TCGA-AR-A1AI\" \"TCGA-AR-A1AN\"\n[161] \"TCGA-AR-A1AO\" \"TCGA-AR-A1AQ\" \"TCGA-AR-A1AT\" \"TCGA-AR-A1AW\" \"TCGA-AR-A24H\"\n[166] \"TCGA-AR-A24K\" \"TCGA-AR-A24U\" \"TCGA-AR-A24X\" \"TCGA-AR-A24Z\" \"TCGA-AR-A250\"\n[171] \"TCGA-AR-A256\" \"TCGA-AR-A2LN\" \"TCGA-B6-A0I1\" \"TCGA-B6-A0I6\" \"TCGA-B6-A0IA\"\n[176] \"TCGA-B6-A0IO\" \"TCGA-B6-A0RH\" \"TCGA-B6-A0RL\" \"TCGA-B6-A0RS\" \"TCGA-B6-A2IU\"\n[181] \"TCGA-B6-A401\" \"TCGA-BH-A0AU\" \"TCGA-BH-A0AW\" \"TCGA-BH-A0AY\" \"TCGA-BH-A0BD\"\n[186] \"TCGA-BH-A0BT\" \"TCGA-BH-A0C0\" \"TCGA-BH-A0DE\" \"TCGA-BH-A0DG\" \"TCGA-BH-A0DK\"\n[191] \"TCGA-BH-A0DL\" \"TCGA-BH-A0DT\" \"TCGA-BH-A0EI\" \"TCGA-BH-A0GY\" \"TCGA-BH-A0GZ\"\n[196] \"TCGA-BH-A0H9\" \"TCGA-BH-A0HO\" \"TCGA-BH-A0HQ\" \"TCGA-BH-A0RX\" \"TCGA-BH-A0W3\"\n[201] \"TCGA-BH-A0W4\" \"TCGA-BH-A0W5\" \"TCGA-BH-A18F\" \"TCGA-BH-A18I\" \"TCGA-BH-A18N\"\n[206] \"TCGA-BH-A18R\" \"TCGA-BH-A18T\" \"TCGA-BH-A1EN\" \"TCGA-BH-A1EO\" \"TCGA-BH-A1EW\"\n[211] \"TCGA-BH-A1EY\" \"TCGA-BH-A1F0\" \"TCGA-BH-A1FC\" \"TCGA-BH-A1FN\" \"TCGA-BH-A2L8\"\n[216] \"TCGA-BH-A42T\" \"TCGA-BH-A42U\" \"TCGA-BH-A6R8\" \"TCGA-BH-A6R9\" \"TCGA-C8-A12L\"\n[221] \"TCGA-C8-A12M\" \"TCGA-C8-A12N\" \"TCGA-C8-A12O\" \"TCGA-C8-A12T\" \"TCGA-C8-A12V\"\n[226] \"TCGA-C8-A134\" \"TCGA-C8-A1HE\" \"TCGA-C8-A1HF\" \"TCGA-C8-A1HG\" \"TCGA-C8-A1HJ\"\n[231] \"TCGA-C8-A1HM\" \"TCGA-C8-A1HN\" \"TCGA-C8-A26X\" \"TCGA-C8-A26Y\" \"TCGA-C8-A26Z\"\n[236] \"TCGA-C8-A274\" \"TCGA-C8-A275\" \"TCGA-D8-A143\" \"TCGA-D8-A145\" \"TCGA-D8-A1JE\"\n[241] \"TCGA-D8-A1JG\" \"TCGA-D8-A1JI\" \"TCGA-D8-A1JJ\" \"TCGA-D8-A1JK\" \"TCGA-D8-A1JL\"\n[246] \"TCGA-D8-A1JT\" \"TCGA-D8-A1X7\" \"TCGA-D8-A1XF\" \"TCGA-D8-A1XQ\" \"TCGA-D8-A1XT\"\n[251] \"TCGA-D8-A1XV\" \"TCGA-D8-A1XW\" \"TCGA-D8-A1XY\" \"TCGA-D8-A1Y2\" \"TCGA-D8-A27F\"\n[256] \"TCGA-D8-A27G\" \"TCGA-D8-A27H\" \"TCGA-D8-A27V\" \"TCGA-D8-A73U\" \"TCGA-D8-A73X\"\n[261] \"TCGA-E2-A105\" \"TCGA-E2-A109\" \"TCGA-E2-A10E\" \"TCGA-E2-A10F\" \"TCGA-E2-A14R\"\n[266] \"TCGA-E2-A14T\" \"TCGA-E2-A14W\" \"TCGA-E2-A14Y\" \"TCGA-E2-A150\" \"TCGA-E2-A159\"\n[271] \"TCGA-E2-A15D\" \"TCGA-E2-A15E\" \"TCGA-E2-A15G\" \"TCGA-E2-A15H\" \"TCGA-E2-A15I\"\n[276] \"TCGA-E2-A15L\" \"TCGA-E2-A15M\" \"TCGA-E2-A15R\" \"TCGA-E2-A15T\" \"TCGA-E2-A1B5\"\n[281] \"TCGA-E2-A1B6\" \"TCGA-E2-A1BD\" \"TCGA-E2-A1IK\" \"TCGA-E2-A1IL\" \"TCGA-E2-A1L6\"\n[286] \"TCGA-E2-A1L9\" \"TCGA-E2-A1LA\" \"TCGA-E2-A574\" \"TCGA-E9-A1N8\" \"TCGA-E9-A1N9\"\n[291] \"TCGA-E9-A1NA\" \"TCGA-E9-A1NF\" \"TCGA-E9-A1NG\" \"TCGA-E9-A1NI\" \"TCGA-E9-A1QZ\"\n[296] \"TCGA-E9-A1R0\" \"TCGA-E9-A1R6\" \"TCGA-E9-A1R7\" \"TCGA-E9-A1RB\" \"TCGA-E9-A1RD\"\n[301] \"TCGA-E9-A1RH\" \"TCGA-E9-A22A\" \"TCGA-E9-A22D\" \"TCGA-E9-A22G\" \"TCGA-E9-A243\"\n[306] \"TCGA-E9-A244\" \"TCGA-E9-A248\" \"TCGA-E9-A249\" \"TCGA-E9-A24A\" \"TCGA-E9-A295\"\n[311] \"TCGA-E9-A2JT\" \"TCGA-E9-A3HO\" \"TCGA-E9-A3QA\" \"TCGA-E9-A5UO\" \"TCGA-E9-A5UP\"\n[316] \"TCGA-EW-A1IX\" \"TCGA-EW-A1OW\" \"TCGA-EW-A1OX\" \"TCGA-EW-A1OY\" \"TCGA-EW-A1OZ\"\n[321] \"TCGA-EW-A1P4\" \"TCGA-EW-A1P7\" \"TCGA-EW-A1PD\" \"TCGA-EW-A1PE\" \"TCGA-EW-A1PH\"\n[326] \"TCGA-EW-A2FW\" \"TCGA-EW-A423\" \"TCGA-EW-A6S9\" \"TCGA-EW-A6SC\" \"TCGA-GM-A2DB\"\n[331] \"TCGA-GM-A2DC\" \"TCGA-GM-A2DF\" \"TCGA-GM-A2DM\" \"TCGA-GM-A2DN\" \"TCGA-GM-A3NW\"\n[336] \"TCGA-GM-A3XL\" \"TCGA-HN-A2NL\" \"TCGA-JL-A3YX\" \"TCGA-LL-A5YN\" \"TCGA-LL-A6FP\"\n[341] \"TCGA-LL-A6FR\" \"TCGA-LL-A8F5\" \"TCGA-OL-A5D6\" \"TCGA-OL-A5D7\" \"TCGA-OL-A5DA\"\n[346] \"TCGA-OL-A5RW\" \"TCGA-OL-A5RY\" \"TCGA-OL-A66I\" \"TCGA-OL-A66K\" \"TCGA-OL-A66P\"\n[351] \"TCGA-OL-A6VQ\" \"TCGA-PE-A5DD\" \"TCGA-PE-A5DE\" \"TCGA-S3-A6ZF\" \"TCGA-S3-AA10\"\n[356] \"TCGA-S3-AA11\" \"TCGA-UL-AAZ6\"\n\n\n\ncreateGroupByAttribute es una función que crea grupos a partir de una variable de atributo. En este caso, la variable es \"patient.stage_event.pathologic_stage_tumor_stage\", que es la variable de los datos clínicos cargados de las etapas tumorales de los pacientes. stages contendrá grupos de muestras en función de estas etapas tumorales.\n\n\nCreación de la variable groups, que será una lista donde se almacenarán los grupos de muestras.\n\n\ngroups &lt;- list()\n\n\nBucle de selección de etapa tumoral:\n\n\nfor (i in c(\"i\", \"ii\", \"iii\", \"iv\")) {\n    stage &lt;- Reduce(union,\n           stages[grep(sprintf(\"stage %s[a|b|c]{0,1}$\", i), names(stages))])\n    # Incluimos solo las muestras tumorales\n    stageTumour &lt;- names(getSubjectFromSample(tumour, stage))\n    elem &lt;- list(stageTumour)\n    names(elem) &lt;- paste(\"Tumour Stage\", toupper(i))\n    groups &lt;- c(groups, elem)\n}\n\n\n\n\n\n\n\nDesglosando el punto 3\n\n\n\n\n\n3.1. Abrimos el bucle para cada una de las posibles etapas tumorales (que estén dentro de la variable clínica, hay que saber bien qué datos tenemos para así poder hacer distintas agrupaciones en función de los datos clínicos):\n\nfor (i in c(\"i\", \"ii\", \"iii\", \"iv\")) {\n\n3.2 Para cada valor de i se va a comenzar definiendo stage como\n\nstage &lt;- Reduce(union, stages[grep(sprintf(\"stage %s[a|b|c]{0,1}$\", i), names(stages))])\n\n\nsprintf(\"stage %s[a|b|c]{0,1}$\", i): Esta línea crea un patrón de búsqueda utilizando sprintf. El patrón será como \"stage ia[a|b|c]{0,1}\\$\" para el valor de \"i\", \"stage iia[a|b|c]{0,1}\\$\" para la etapa \"ii\", y así sucesivamente. El patrón permite que se encuentren coincidencias que contienen una sola letra opcional “a”, “b” o “c” al final de la etapa.\ngrep(..., names(stages)): grep busca el valor actual de i en los nombres de las etapas (names(stages)), que se obtienen de la variable stages.\nstages[grep(...)]: Esto devuelve las etapas que coinciden con el patrón de búsqueda. Por ejemplo, si el valor es “i”, esto devolverá todas las etapas que coincidan con “stage ia”, “stage ib”, “stage ic”, etc.\nReduce(union, ...): La función Reduce se utiliza para combinar todas las etapas que coincidieron con el patrón en una sola. union es una función que combina conjuntos, por lo que Reduce(union, ...) crea un conjunto que contiene todas las muestras de las etapas correspondientes a la etapa actual.\n\n3.3. Filtrado de muestras tumorales: Se filtran las muestras tumorales del valor stage. getSubjectFromSample obtiene los sujetos asociados con las muestras, y names(...) devuelve los nombres de las muestras tumorales de ese valor.\n\nstageTumour &lt;- names(getSubjectFromSample(tumour, stage))\n\n3.4. Creación de un elemento de grupo y asignación de nombre: Se crea un elemento de lista elem que contiene las muestras tumorales de la etapa. Luego, se le asigna un nombre basado en la etapa (“Tumour Stage i”, “Tumour Stage ii”, etc.). Como utilizamos la función toupper(i) nos devolverá el valor de i en mayúscula (no tiene nada que ver con tuppers, esta función literalmente es “to upper”, que significa “a mayúscula”):\n\nelem &lt;- list(stageTumour)\nnames(elem) &lt;- paste(\"Tumour Stage\", toupper(i))\n\n3.5. Agregación del elemento al grupo general: El elemento elem se agrega a la lista general groups, que almacena todos los grupos.\n\ngroups &lt;- c(groups, elem)\n\n3.6. Cerramos el bucle:\n\n}\n\n\n\n\n\nCreamos el grupo “normal” (no tumoral). Finalmente, se agrega un grupo llamado “Normal” que contiene las muestras no tumorales. El conjunto groups ahora contendrá todos los grupos creados, incluyendo las etapas tumorales y el grupo de muestras “normales”(no tumorales).\n\n\ngroups &lt;- c(groups, Normal=list(normal))\n\nVamos a visualizar los elementos que hay en groups:\n\nstr(groups)\n\nList of 5\n $ Tumour Stage I  : chr [1:181] \"TCGA-3C-AALK-01A-11R-A41B-07\" \"TCGA-A1-A0SB-01A-11R-A144-07\" \"TCGA-A1-A0SE-01A-11R-A084-07\" \"TCGA-A2-A04N-01A-11R-A115-07\" ...\n $ Tumour Stage II : chr [1:619] \"TCGA-3C-AALI-01A-11R-A41B-07\" \"TCGA-3C-AALJ-01A-31R-A41B-07\" \"TCGA-5T-A9QA-01A-11R-A41B-07\" \"TCGA-A1-A0SD-01A-11R-A115-07\" ...\n $ Tumour Stage III: chr [1:250] \"TCGA-4H-AAAK-01A-12R-A41B-07\" \"TCGA-A1-A0SJ-01A-11R-A084-07\" \"TCGA-A2-A04P-01A-31R-A034-07\" \"TCGA-A2-A0CK-01A-11R-A22K-07\" ...\n $ Tumour Stage IV : chr [1:20] \"TCGA-5L-AAT1-01A-12R-A41B-07\" \"TCGA-A2-A0CS-01A-11R-A115-07\" \"TCGA-A2-A0SV-01A-11R-A084-07\" \"TCGA-A2-A0SW-01A-11R-A084-07\" ...\n $ Normal          : chr [1:112] \"TCGA-A7-A0CE-11A-21R-A089-07\" \"TCGA-A7-A0CH-11A-32R-A089-07\" \"TCGA-A7-A0D9-11A-53R-A089-07\" \"TCGA-A7-A0DB-11A-33R-A089-07\" ...\n\n\n\n\n\nPara una mayor cosistencia en los fururos análisis vamos a preapar los colores para cada grupo\n\ncolours &lt;- c(\"#6D1F95\", \"#FF152C\", \"#00C7BA\", \"#FF964F\", \"#00C65A\")\nnames(colours) &lt;- names(groups)\nattr(groups, \"Colour\") &lt;- colours\n\nPreparamos una primera comparacion de muestras normales con respecto a las tumorales en estadío I:\n\nnormalVSstage1Tumour &lt;- groups[c(\"Tumour Stage I\", \"Normal\")]\nattr(normalVSstage1Tumour, \"Colour\") &lt;- attr(groups, \"Colour\")\n\nTambien vamos a preparar una segunda comparación de muestras normales con respecto a las tumorales\n\nnormalVStumour &lt;- list(Normal=normal, Tumour=tumour)\nattr(normalVStumour, \"Colour\") &lt;- c(Normal=\"#00C65A\", Tumour=\"#EFE35C\")\n\n\n\n3.1.5 Ejemplo\nVamos a juguetear un poco con los datos\n\n3.1.5.1 Differential splicing analysis\nPara hacer un análisis de expresión diferencial entre los pacientes normales vs. los tumorales en estadío 1 tenemos que usar el siguiente comando:\n\ndiffSplicing &lt;- diffAnalyses(psi, normalVSstage1Tumour)\n\nTime difference of 21.1 secs\n\n\nTime difference of 1.52 secs\n\n\nTime difference of 0.000689 secs\n\n\nTime difference of 0.00319 secs\n\n\nEn este análisis se realiza una comparación estadística mediantes Wilcoxon test, lo cual, al haber muchas muestras si es posible realizarlo. Vamos a realizar una serie de filtros:\n\ndeltaPSIthreshold &lt;- abs(diffSplicing$`∆ Median`) &gt; 0.1\npvalueThreshold   &lt;- diffSplicing$`Wilcoxon p-value (BH adjusted)` &lt; 0.01\neventsThreshold &lt;- diffSplicing[deltaPSIthreshold & pvalueThreshold, ]\nhead(eventsThreshold)\n\n                                                      Event type Chromosome\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2   Skipped exon (SE)          1\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2   Skipped exon (SE)          1\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65 Skipped exon (SE)          1\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6   Skipped exon (SE)          1\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1  Skipped exon (SE)          1\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1  Skipped exon (SE)          1\n                                               Strand    Gene\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2        -   CCNL2\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2        -   CCNL2\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65      - ANKRD65\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6        -   MEGF6\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1       -  CLSTN1\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1       -  CLSTN1\n                                               Survival by PSI cutoff\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2                     &lt;NA&gt;\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2                     &lt;NA&gt;\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65                   &lt;NA&gt;\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6                     &lt;NA&gt;\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1                    &lt;NA&gt;\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1                    &lt;NA&gt;\n                                               Optimal PSI cutoff\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2                 &lt;NA&gt;\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2                 &lt;NA&gt;\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65               &lt;NA&gt;\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6                 &lt;NA&gt;\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1                &lt;NA&gt;\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1                &lt;NA&gt;\n                                               Log-rank p-value\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2               &lt;NA&gt;\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2               &lt;NA&gt;\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65             &lt;NA&gt;\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6               &lt;NA&gt;\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1              &lt;NA&gt;\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1              &lt;NA&gt;\n                                               Samples (Normal)\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2                112\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2                112\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65               55\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6                 85\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1               112\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1               112\n                                               Samples (Tumour Stage I)\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2                        181\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2                        181\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65                       30\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6                        127\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1                       180\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1                       164\n                                               T-test statistic\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2           5.413553\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2           4.868445\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65        -3.407048\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6           9.910658\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1         16.116164\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1         14.822930\n                                               T-test parameter T-test p-value\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2          289.68237   1.297916e-07\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2          288.79657   1.854528e-06\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65         57.41675   1.205548e-03\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6          196.99521   4.834255e-19\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1         168.54357   5.807634e-36\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1         155.97177   1.397799e-31\n                                               T-test p-value (BH adjusted)\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2                   1.711519e-06\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2                   1.972181e-05\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65                 6.177653e-03\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6                   2.812399e-17\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1                  1.148750e-33\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1                  1.843230e-29\n                                               T-test conf int1\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2         0.05124555\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2         0.04466433\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65      -0.37774693\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6         0.16600474\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1        0.28231553\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1        0.18489472\n                                               T-test conf int2\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2         0.10979423\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2         0.10528627\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65      -0.09810984\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6         0.24848160\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1        0.36113452\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1        0.24174886\n                                               T-test estimate1\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2          0.6453581\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2          0.6323658\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65        0.2700344\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6          0.7956907\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1         0.5231278\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1         0.3240677\n                                               T-test estimate2\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2          0.5648382\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2          0.5573905\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65        0.5079628\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6          0.5884475\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1         0.2014028\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1         0.1107459\n                                               T-test null value T-test stderr\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2                   0    0.01487376\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2                   0    0.01540025\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65                 0    0.06983418\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6                   0    0.02091114\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1                  0    0.01996288\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1                  0    0.01439134\n                                               T-test alternative\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2            two.sided\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2            two.sided\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65          two.sided\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6            two.sided\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1           two.sided\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1           two.sided\n                                                         T-test method\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2   Welch Two Sample t-test\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2   Welch Two Sample t-test\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65 Welch Two Sample t-test\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6   Welch Two Sample t-test\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1  Welch Two Sample t-test\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1  Welch Two Sample t-test\n                                                                   T-test data name\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2   vector[typeOne] and vector[!typeOne]\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2   vector[typeOne] and vector[!typeOne]\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65 vector[typeOne] and vector[!typeOne]\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6   vector[typeOne] and vector[!typeOne]\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1  vector[typeOne] and vector[!typeOne]\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1  vector[typeOne] and vector[!typeOne]\n                                               Wilcoxon statistic\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2              13961.0\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2              13656.5\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65              476.5\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6               9097.5\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1             19153.0\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1             17261.0\n                                               Wilcoxon p-value\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2       5.736556e-08\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2       5.891184e-07\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65     1.062821e-03\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6       2.858596e-17\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1      3.001272e-38\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1      2.456622e-35\n                                               Wilcoxon p-value (BH adjusted)\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2                     7.757647e-07\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2                     6.913677e-06\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65                   5.155060e-03\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6                     1.268968e-15\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1                    1.532149e-35\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1                    1.003285e-32\n                                               Wilcoxon null value\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2                     0\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2                     0\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65                   0\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6                     0\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1                    0\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1                    0\n                                               Wilcoxon alternative\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2              two.sided\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2              two.sided\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65            two.sided\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6              two.sided\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1             two.sided\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1             two.sided\n                                                                                 Wilcoxon method\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2   Wilcoxon rank sum test with continuity correction\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2   Wilcoxon rank sum test with continuity correction\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65 Wilcoxon rank sum test with continuity correction\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6   Wilcoxon rank sum test with continuity correction\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1  Wilcoxon rank sum test with continuity correction\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1  Wilcoxon rank sum test with continuity correction\n                                                                 Wilcoxon data name\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2   vector[typeOne] and vector[!typeOne]\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2   vector[typeOne] and vector[!typeOne]\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65 vector[typeOne] and vector[!typeOne]\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6   vector[typeOne] and vector[!typeOne]\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1  vector[typeOne] and vector[!typeOne]\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1  vector[typeOne] and vector[!typeOne]\n                                               Kruskal statistic\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2            29.45812\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2            24.95462\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65          10.74561\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6            71.45903\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1          167.23417\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1          153.90187\n                                               Kruskal parameter\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2                   1\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2                   1\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65                 1\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6                   1\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1                  1\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1                  1\n                                               Kruskal p-value\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2      5.713806e-08\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2      5.869566e-07\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65    1.045270e-03\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6      2.830754e-17\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1     2.973578e-38\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1     2.433181e-35\n                                               Kruskal p-value (BH adjusted)\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2                    7.726883e-07\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2                    6.888307e-06\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65                  5.082004e-03\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6                    1.256609e-15\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1                   1.518011e-35\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1                   9.937110e-33\n                                                             Kruskal method\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2   Kruskal-Wallis rank sum test\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2   Kruskal-Wallis rank sum test\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65 Kruskal-Wallis rank sum test\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6   Kruskal-Wallis rank sum test\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1  Kruskal-Wallis rank sum test\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1  Kruskal-Wallis rank sum test\n                                               Kruskal data name\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2    vector and group\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2    vector and group\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65  vector and group\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6    vector and group\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1   vector and group\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1   vector and group\n                                               Levene statistic Levene p-value\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2        14.86536805   1.421568e-04\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2        13.01905748   3.628415e-04\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65       0.03243927   8.575060e-01\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6         1.66626933   1.981782e-01\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1       13.91668044   2.298603e-04\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1       22.36367304   3.614964e-06\n                                               Levene p-value (BH adjusted)\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2                   1.891707e-03\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2                   4.104140e-03\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65                 9.276738e-01\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6                   4.254598e-01\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1                  2.836336e-03\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1                  9.813422e-05\n                                               Levene data name\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2   vector and group\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2   vector and group\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65 vector and group\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6   vector and group\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1  vector and group\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1  vector and group\n                                                                  Levene method\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2   Levene's test (using the median)\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2   Levene's test (using the median)\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65 Levene's test (using the median)\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6   Levene's test (using the median)\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1  Levene's test (using the median)\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1  Levene's test (using the median)\n                                               Fligner-Killeen statistic\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2                13.376860125\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2                12.251877392\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65               0.001988293\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6                 1.711987652\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1                8.764877346\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1               16.165062602\n                                               Fligner-Killeen parameter\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2                           1\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2                           1\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65                         1\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6                           1\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1                          1\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1                          1\n                                               Fligner-Killeen p-value\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2              2.547478e-04\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2              4.647903e-04\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65            9.644339e-01\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6              1.907277e-01\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1             3.070867e-03\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1             5.805506e-05\n                                               Fligner-Killeen p-value (BH adjusted)\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2                            0.0022550723\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2                            0.0036678800\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65                          0.9863258074\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6                            0.3747036646\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1                           0.0180701901\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1                           0.0006566672\n                                                                         Fligner-Killeen method\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2   Fligner-Killeen test of homogeneity of variances\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2   Fligner-Killeen test of homogeneity of variances\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65 Fligner-Killeen test of homogeneity of variances\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6   Fligner-Killeen test of homogeneity of variances\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1  Fligner-Killeen test of homogeneity of variances\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1  Fligner-Killeen test of homogeneity of variances\n                                               Fligner-Killeen data name\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2            vector and group\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2            vector and group\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65          vector and group\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6            vector and group\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1           vector and group\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1           vector and group\n                                               Variance (Normal)\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2          0.01026297\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2          0.01125922\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65        0.08914357\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6          0.01954585\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1         0.03550055\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1         0.01930300\n                                               Variance (Tumour Stage I)\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2                 0.023456720\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2                 0.024731670\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65               0.097680631\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6                 0.026330235\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1                0.014678516\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1                0.005701029\n                                               Median (Normal)\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2         0.6621547\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2         0.6579629\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65       0.2400000\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6         0.8113208\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1        0.4597045\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1        0.2885843\n                                               Median (Tumour Stage I)\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2                 0.5541401\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2                 0.5533981\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65               0.5000000\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6                 0.6000000\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1                0.1841544\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1                0.1025085\n                                                 ∆ Variance   ∆ Median\nSE_1_-_1328776_1328183_1328059_1326245_CCNL2   -0.013193753  0.1080146\nSE_1_-_1328776_1328183_1328170_1326245_CCNL2   -0.013472446  0.1045649\nSE_1_-_1356177_1355972_1355432_1354929_ANKRD65 -0.008537066 -0.2600000\nSE_1_-_3413797_3413683_3413552_3413347_MEGF6   -0.006784386  0.2113208\nSE_1_-_9801152_9797612_9797556_9796100_CLSTN1   0.020822033  0.2755501\nSE_1_-_9833330_9816568_9816539_9815367_CLSTN1   0.013601972  0.1860759\n\n\nY vamos a realizar trambien una representación volcano de los valores ajustados por BH\n\nggplot(diffSplicing, aes(`∆ Median`, \n                         -log10(`Wilcoxon p-value (BH adjusted)`))) +\n    geom_point(data=eventsThreshold,\n               colour=\"orange\", alpha=0.5, size=3) + \n    geom_point(data=diffSplicing[!deltaPSIthreshold | !pvalueThreshold, ],\n               colour=\"gray\", alpha=0.5, size=3) + \n    theme_light(16) +\n    ylab(\"-log10(q-value)\")\n\n\n\n\n\n\n3.1.5.2 Differential inclusion of one event\nComprobemos si existe una diferencia significativa en la inclusión del exón 12 de NUMB entre las muestras de mama tumorales y normales del TCGA. Para ello:\n\nASevents &lt;- rownames(psi)\n(tmp     &lt;- grep(\"SRRM1\", ASevents, value=TRUE))\n\n[1] \"SE_1_+_24979523_24980797_24980834_24981346_SRRM1\"\n[2] \"SE_1_+_24989295_24989674_24989715_24993306_SRRM1\"\n[3] \"A3SS_1_+_24976577_24977990_24977900_SRRM1\"       \n[4] \"A5SS_1_+_24981614_24981620_24987210_SRRM1\"       \n\n\nVamoss a imprimir el primer evento:\n\nSRRM1 &lt;- tmp[2]\nplotSplicingEvent(SRRM1)\n\n\n  \n  24989295\n  \n  24989674\n  24989715\n  41 nts\n  \n  24993306\n  \n  \n  \n\n\n\nTambién podemos ver la distribución de los PSI de las muestras dentro para los grupos de la comparación:\n\nplotDistribution(psi[SRRM1, ], normalVStumour)\n\n\n\n\n\n\n\nKaplan-Meier de un evento de splicing\n\n\n# Survival curves based on optimal PSI cutoff\nlibrary(survival)\n\n# Assign alternative splicing quantification to patients based on their samples\nsamples &lt;- colnames(psi)\nmatch &lt;- getSubjectFromSample(samples, clinical, sampleInfo=sampleInfo)\n\neventPSI &lt;- assignValuePerSubject(psi[SRRM1, ], match, clinical,                          samples=unlist(tumour))\n\nopt &lt;- optimalSurvivalCutoff(clinical, eventPSI, censoring=\"right\", \n                             event=\"days_to_death\", timeStart=\"days_to_death\")\n(optimalCutoff &lt;- opt$par)    # Optimal exon inclusion level\n\n[1] 0.6092694\n\n(optimalPvalue &lt;- opt$value)  # Respective p-value\n\n[1] 0.0545\n\nlabel     &lt;- labelBasedOnCutoff(eventPSI, round(optimalCutoff, 2), \n                                label=\"PSI values\")\nsurvTerms &lt;- processSurvTerms(clinical, censoring=\"right\",\n                              event=\"days_to_death\", timeStart=\"days_to_death\",\n                              group=label, scale=\"years\")\nsurv &lt;- survfit(survTerms)\npvalue &lt;- testSurvival(survTerms)\nplotSurvivalCurves(surv, pvalue=pvalue, mark=FALSE)\n\n\n\n\n\n\n\nCorrelación de un evento de splicing con la expresion de un gen\n\nPodemos ver la correlación de este evento con la expressión de algún gen de interés (vamos a usar “ADARB1” porque me acaba de venir a la cabeza)\n\ngenes &lt;- rownames(geneExprNorm)\n(tmp  &lt;- grep(\"ADARB1\", genes, value=TRUE))\n\n[1] \"ADARB1|104\"\n\n\n\nADARB1   &lt;- tmp[1]\nplotDistribution(geneExprNorm[ADARB1, ], normalVStumour, psi=FALSE)\n\n\n\n\n\n\nY podemos ver si existe correlación entre estos dos valores (expresión de ADARB1 e inclusión del evento en SRRM1).\n\nplotCorrelation(correlateGEandAS(\n    geneExprNorm, psi, ADARB1, SRRM1, method=\"spearman\"))\n\n$`SE_1_+_24989295_24989674_24989715_24993306_SRRM1`\n$`SE_1_+_24989295_24989674_24989715_24993306_SRRM1`$`ADARB1|104`\n\n\n\n\n\n\nKaplan-Meier de múltiples eventos de splicing\n\nEste análisis va a realizar los análisis para todos los eventos que determinemos (en este caso he definido que sean los 4 eventos de SRRM1 que estaban guardados en la variable tmp que calculamos con aterioridad), y luego representaremos el evento que queramos (en este caso he representado el evento nº2 como se puede ver en la última línea del código, que corresponde al mismo evento que el caso anterior y así podemos ver que el cálculo es el mismo que en el caso anterior)\n\ntmp     &lt;- grep(\"SRRM1\", ASevents, value=TRUE)\n\nSRRM1_events&lt;-tmp[1:4]\n# Survival curves based on optimal PSI cutoff\nlibrary(survival)\n\n# Assign alternative splicing quantification to patients based on their samples\nsamples &lt;- colnames(psi)\nmatch &lt;- getSubjectFromSample(samples, clinical, sampleInfo=sampleInfo)\n\nsurvPlots &lt;- list()\nfor (event in SRRM1_events) {\n    # Find optimal cutoff for the event\n    eventPSI &lt;- assignValuePerSubject(psi[event, ], match, clinical,\n                                      samples=unlist(tumour))\n    opt &lt;- optimalSurvivalCutoff(clinical, eventPSI, censoring=\"right\", \n                                 event=\"days_to_death\", \n                                 timeStart=\"days_to_death\")\n    (optimalCutoff &lt;- opt$par)    # Optimal exon inclusion level\n    (optimalPvalue &lt;- opt$value)  # Respective p-value\n    \n    label     &lt;- labelBasedOnCutoff(eventPSI, round(optimalCutoff, 2), \n                                    label=\"PSI values\")\n    survTerms &lt;- processSurvTerms(clinical, censoring=\"right\",\n                                  event=\"days_to_death\", \n                                  timeStart=\"days_to_death\",\n                                  group=label, scale=\"years\")\n    surv &lt;- survival::survfit(survTerms)\n    pvalue &lt;- testSurvival(survTerms)\n    survPlots[[event]] &lt;- plotSurvivalCurves(surv, pvalue=pvalue, mark=FALSE)\n}\n\n# Now print the survival plot of a specific event\nsurvPlots[[ SRRM1_events[[2]] ]]\n\n\n\n\n\n\n\n\n3.1.5.3 Differential gene expression\nLas alteraciones detectadas en el splicing alternativo pueden ser simplemente un reflejo de los cambios en los niveles de expresión génica. Por lo tanto, para desentrañar estos dos efectos, también debería realizarse un análisis de expresión diferencial entre el estadio tumoral I y las muestras normales. Para ello:\n\n\n\n\n\n\nNote\n\n\n\nEsto está bien para una exploración inicial pero no se puede comparar a una exploración con el análisis completo como hicimos en el apartado de RNAseq. Aún así es útil y también aprendemos a utilizar las kaplan-Meier.\n\n\n\n# Prepare groups of samples to analyse and further filter unavailable samples in\n# selected groups for gene expression\nge           &lt;- geneExprNorm[ , unlist(normalVSstage1Tumour), drop=FALSE]\nisFromGroup1 &lt;- colnames(ge) %in% normalVSstage1Tumour[[1]]\ndesign       &lt;- cbind(1, ifelse(isFromGroup1, 0, 1))\n\n# Fit a gene-wise linear model based on selected groups\nlibrary(limma)\nfit &lt;- lmFit(as.matrix(ge), design)\n\n# Calculate moderated t-statistics and DE log-odds using limma::eBayes\nebayesFit &lt;- eBayes(fit, trend=TRUE)\n\n# Prepare data summary\npvalueAdjust &lt;- \"BH\" # Benjamini-Hochberg p-value adjustment (FDR)\nsummary &lt;- topTable(ebayesFit, number=nrow(fit), coef=2, sort.by=\"none\",\n                    adjust.method=pvalueAdjust, confint=TRUE)\nnames(summary) &lt;- c(\"log2 Fold-Change\", \"CI (low)\", \"CI (high)\", \n                    \"Average expression\", \"moderated t-statistics\", \"p-value\", \n                    paste0(\"p-value (\", pvalueAdjust, \" adjusted)\"),\n                    \"B-statistics\")\nattr(summary, \"groups\") &lt;- normalVSstage1Tumour\n\n# Calculate basic statistics\nstats &lt;- diffAnalyses(ge, normalVSstage1Tumour, \"basicStats\", \n                      pvalueAdjust=NULL)\nfinal &lt;- cbind(stats, summary)\n\n# Differential gene expression between breast tumour stage I and normal samples\nlibrary(ggplot2)\nlibrary(ggrepel)\ncognateGenes &lt;- unlist(parseSplicingEvent(events)$gene)\nlogFCthreshold  &lt;- abs(final$`log2 Fold-Change`) &gt; 1\npvalueThreshold &lt;- final$`p-value (BH adjusted)` &lt; 0.01\n\nfinal$genes &lt;- gsub(\"\\\\|.*$\", \"\\\\1\", rownames(final))\nggplot(final, aes(`log2 Fold-Change`, \n                  -log10(`p-value (BH adjusted)`))) +\n    geom_point(data=final[logFCthreshold & pvalueThreshold, ],\n               colour=\"orange\", alpha=0.5, size=3) + \n    geom_point(data=final[!logFCthreshold | !pvalueThreshold, ],\n               colour=\"gray\", alpha=0.5, size=3) + \n    geom_text_repel(data=final[cognateGenes, ], aes(label=genes),\n                    box.padding=0.4, size=5) +\n    theme_light(16) +\n    ylab(\"-log10(q-value)\")\n\n\n\n\n\nDistribución de la expresión de un gen\n\n\nplotDistribution(geneExprNorm[\"ACOT7\", ], normalVSstage1Tumour)\n\n\n\n\n\n\n\nKaplan-Meier de la expresión de un gen\n\nVoy a utilizar para probar este código uno de los genes que sale desregulados:\n\nACOT7ge &lt;- assignValuePerSubject(geneExprNorm[\"ACOT7\", ], match, clinical, \n                                 samples=unlist(tumour))\n\n# Survival curves based on optimal gene expression cutoff\nopt &lt;- optimalSurvivalCutoff(clinical, ACOT7ge, censoring=\"right\",\n                             event=\"days_to_death\", timeStart=\"days_to_death\")\n(optimalCutoff &lt;- opt$par)    # Optimal exon inclusion level\n\n[1] 9.39236\n\n(optimalPvalue &lt;- opt$value)  # Respective p-value\n\n[1] 0.063\n\n# Process again after rounding the cutoff\nroundedCutoff &lt;- round(optimalCutoff, 2)\nlabel     &lt;- labelBasedOnCutoff(ACOT7ge, roundedCutoff, label=\"Gene expression\")\nsurvTerms &lt;- processSurvTerms(clinical, censoring=\"right\",\n                              event=\"days_to_death\", timeStart=\"days_to_death\",\n                              group=label, scale=\"years\")\nsurv   &lt;- survfit(survTerms)\npvalue &lt;- testSurvival(survTerms)\nplotSurvivalCurves(surv, pvalue=pvalue, mark=FALSE)"
  },
  {
    "objectID": "AS_Analysis.html#analisis-de-enriquecimiento-de-differenctial-splicing",
    "href": "AS_Analysis.html#analisis-de-enriquecimiento-de-differenctial-splicing",
    "title": "Alternative Splicing",
    "section": "2.7 Analisis de Enriquecimiento de Differenctial Splicing",
    "text": "2.7 Analisis de Enriquecimiento de Differenctial Splicing\n\n2.7.1 Paquete 1: NEASE (Network Enrichment method for Alternative Splicing Events)\nEl paquete NEASE (Network-based Enrichment method for Alternative Splicing Events) detecta primero las características de las proteínas afectadas por AS, como dominios, motivos y residuos. A continuación, NEASE utiliza interacciones proteína-proteína integradas con interacciones dominio-dominio, nivel de residuo e interacciones dominio-motivo para identificar socios de interacción probablemente afectados por AS.\nA continuación, NEASE realiza un análisis de sobrerrepresentación de conjuntos de genes e identifica vías enriquecidas en función de los bordes afectados. Además, dado que el enfoque estadístico está basado en redes, también prioriza genes empalmados (diferencialmente) y encuentra nuevos biomarcadores de enfermedades candidatos en caso de empalmes aberrantes.\nDejo también el enlace al tutorial\n\nLouadi, Z., Elkjaer, M.L., Klug, M. et al. Functional enrichment of alternative splicing events with NEASE reveals insights into tissue identity and diseases. Genome Biol 22, 327 (2021). https://doi.org/10.1186/s13059-021-02538-1\n\n\n\n\n\n\n\nPython\n\n\n\n\n\n\nPara instalarlo tenemos que usar los sigueintes comandos:\n\npip install nease\n\n\n\n\n\n\n\nNo fucinona por un fallo sintáctico de código de los desarrolladores, lo dejo aquí hasta nuevo aviso\n\n\n\nSe podría modificar desde local pero no estoy para desaprovechar el tiempo (probablemente surjan más problemas con eso y el lenguaje es python así que agilidad no va a haber para resolverlo por mi parte). He dejado un report del Issue en el GitHub de los desarrolladores para ver si lo solucionan.\n\n\n\n\n2.7.2 Paquete 2: PEGASAS (Pathway Enrichment-Guided Activity Study of Alternative splicing)\nSe trata de una herramienta que busca, como dice su nombre, realizar un enriquecimiento de enventos de splicing y la desregulación del mismo en pathways asociadas al cáncer mediante la correlación de las firmas transcripcionales de 50 vías diferentes impulsoras del cáncer con estos eventos de splicing alternativo. La guía de esta herramienta está en el siguiente enlace al GitHub. Cita del artículo\n\nPhillips, J. W., Pan, Y., Tsai, B. L., Xie, Z., Demirdjian, L., Xiao, W., Yang, H. T., Zhang, Y., Lin, C. H., Cheng, D., Hu, Q., Liu, S., Black, D. L., Witte, O. N., & Xing, Y. (2020). Pathway-guided analysis identifies Myc-dependent alternative pre-mRNA splicing in aggressive prostate cancers. Proceedings of the National Academy of Sciences of the United States of America, 117(10), 5269–5279. https://doi.org/10.1073/pnas.1915975117\n\nTiene web interactiva.\n\n\n\n\n\n\nPython\n\n\n\n\n\n\nPara instalarlo tenemos que tener instaladas las siguientes dependencias: - En python 2.7:\n\n#primero tenemos que instalar pip, que es un instalador de funciones para phyton\n\nsudo apt install python-pip\n\n#Función número 1\npip install numpy\n\n#Función número 2\npip install scipy\n\n#Función número 3\npip install matplotlib\n\n\nEn R:\n\n\ninstall.packages(\"LSD\")\n\ninstall.packages(\"data.table\") \n\ninstall.packages(\"ggplot2\")\n\nque utilizar los siguientes comandos:\n\ngit clone https://github.com/Xinglab/PEGASAS.git\n\ncd PEGASAS\n\npython setup.py install\n\n\n\n\n\n\n\nNo me fucinonaba y no se por qué, lo dejo aquí hasta nuevo aviso"
  },
  {
    "objectID": "Multimomic_Data_Integration.html",
    "href": "Multimomic_Data_Integration.html",
    "title": "Multiomic Data Integration",
    "section": "",
    "text": "1 MOFA"
  }
]